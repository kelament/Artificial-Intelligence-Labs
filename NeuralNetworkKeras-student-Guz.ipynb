{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network with [Keras](https://keras.io/losses/)"
   ]
  },
  {
   "attachments": {
    "keras-logo-2018-large-1200.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![keras-logo-2018-large-1200.png](attachment:keras-logo-2018-large-1200.png)\n",
    "\n",
    "\n",
    "Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.\n",
    "\n",
    "Use Keras if you need a deep learning library that:\n",
    "\n",
    "- Allows for easy and fast prototyping (through user friendliness, modularity, and extensibility).\n",
    "- Supports both convolutional networks and recurrent networks, as well as combinations of the two.\n",
    "- Runs seamlessly on CPU and GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network for binary classficiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: Parkinsons Disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Oxford Parkinson's Disease Detection Dataset__\n",
    "\n",
    "This dataset is composed of a range of biomedical voice measurements from \n",
    "31 people, 23 with Parkinson's disease (PD). Each column in the table is a \n",
    "particular voice measure, and each row corresponds one of 195 voice \n",
    "recording from these individuals (\"name\" column). The main aim of the data \n",
    "is to discriminate healthy people from those with PD, according to \"status\" \n",
    "column which is set to 0 for healthy and 1 for PD.\n",
    "\n",
    "The data is in ASCII CSV format. The rows of the CSV file contain an \n",
    "instance corresponding to one voice recording. There are around six \n",
    "recordings per patient, the name of the patient is identified in the first \n",
    "column.For further information or to pass on comments, please contact Max \n",
    "Little (littlem '@' robots.ox.ac.uk).\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "Matrix column entries (attributes):\n",
    "- name - ASCII subject name and recording number\n",
    "- MDVP:Fo(Hz) - Average vocal fundamental frequency\n",
    "- MDVP:Fhi(Hz) - Maximum vocal fundamental frequency\n",
    "- MDVP:Flo(Hz) - Minimum vocal fundamental frequency\n",
    "- MDVP:Jitter(%),MDVP:Jitter(Abs),MDVP:RAP,MDVP:PPQ,Jitter:DDP - Several \n",
    "measures of variation in fundamental frequency\n",
    "- MDVP:Shimmer,MDVP:Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,MDVP:APQ,Shimmer:DDA - Several measures of variation in amplitude\n",
    "- NHR,HNR - Two measures of ratio of noise to tonal components in the voice\n",
    "- status - Health status of the subject (one) - Parkinson's, (zero) - healthy\n",
    "- RPDE,D2 - Two nonlinear dynamical complexity measures\n",
    "- DFA - Signal fractal scaling exponent\n",
    "- spread1,spread2,PPE - Three nonlinear measures of fundamental frequency variation \n",
    "\n",
    "dataset: https://archive.ics.uci.edu/ml/machine-learning-databases/parkinsons/parkinsons.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "from keras.layers import Dropout\n",
    "\n",
    "#set seed for reproduction purpose\n",
    "from numpy.random import seed\n",
    "seed(1) \n",
    "\n",
    "# tf.set_random_seed(2)\n",
    "tf.random.set_seed(2)\n",
    "\n",
    "import random as rn\n",
    "rn.seed(12345)\n",
    "\n",
    "# tf.set_random_seed(1234) - not working\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "#import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and standarise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/parkinsons/parkinsons.data\"\n",
    "\n",
    "names = [\"name\",\"MDVP:Fo(Hz)\",\"MDVP:Fhi(Hz)\",\"MDVP:Flo(Hz)\",\"MDVP:Jitter(%)\",\"MDVP:Jitter(Abs)\",\"MDVP:RAP\",\"MDVP:PPQ\",\n",
    "         \"Jitter:DDP\",\"MDVP:Shimmer\",\"MDVP:Shimmer(dB)\",\"Shimmer:APQ3\",\"Shimmer:APQ5\",\"MDVP:APQ\",\"Shimmer:DDA\",\n",
    "         \"NHR\",\"HNR\",\"status\",\"RPDE\",\"DFA\",\"spread1\",\"spread2\",\"D2\",\"PPE\"]\n",
    "\n",
    "parkinson_df = pd.read_csv(url, names=names) #load CVS data\n",
    "\n",
    "#load Pandas Dataframe into numpy arrays\n",
    "data = parkinson_df.loc[1:,[\"MDVP:Fo(Hz)\",\"MDVP:Fhi(Hz)\",\"MDVP:Flo(Hz)\",\"MDVP:Jitter(%)\",\"MDVP:Jitter(Abs)\",\"MDVP:RAP\",\"MDVP:PPQ\",\n",
    "         \"Jitter:DDP\",\"MDVP:Shimmer\",\"MDVP:Shimmer(dB)\",\"Shimmer:APQ3\",\"Shimmer:APQ5\",\"MDVP:APQ\",\"Shimmer:DDA\",\n",
    "         \"NHR\",\"HNR\",\"RPDE\",\"DFA\",\"spread1\",\"spread2\",\"D2\",\"PPE\"]].values.astype(np.float)\n",
    "target = parkinson_df.loc[1:, ['status']].values.astype(np.float)\n",
    "\n",
    "#standarise data\n",
    "data = StandardScaler().fit_transform(data)\n",
    "\n",
    "data_train, data_test, target_train, target_test = \\\n",
    "train_test_split(data, target, test_size=0.3, random_state=545)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build neural network with Keras using [Sequential model](https://keras.io/getting-started/sequential-model-guide/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 2)                 46        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 49\n",
      "Trainable params: 49\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "neural_model = Sequential([\n",
    "    Dense(2, input_shape=(22,), activation=\"relu\"), #why 22 inputs?\n",
    "  #  Dense(2, activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "#show summary of a model\n",
    "neural_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training neural model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 136 samples, validate on 59 samples\n",
      "Epoch 1/4000\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.6522 - accuracy: 0.6397 - val_loss: 0.6790 - val_accuracy: 0.6441\n",
      "Epoch 2/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.6468 - accuracy: 0.6618 - val_loss: 0.6751 - val_accuracy: 0.6610\n",
      "Epoch 3/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.6415 - accuracy: 0.6618 - val_loss: 0.6715 - val_accuracy: 0.6610\n",
      "Epoch 4/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.6366 - accuracy: 0.6765 - val_loss: 0.6679 - val_accuracy: 0.6780\n",
      "Epoch 5/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.6319 - accuracy: 0.6765 - val_loss: 0.6645 - val_accuracy: 0.6780\n",
      "Epoch 6/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.6273 - accuracy: 0.6838 - val_loss: 0.6611 - val_accuracy: 0.6780\n",
      "Epoch 7/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.6228 - accuracy: 0.6985 - val_loss: 0.6578 - val_accuracy: 0.6780\n",
      "Epoch 8/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.6185 - accuracy: 0.6985 - val_loss: 0.6545 - val_accuracy: 0.6780\n",
      "Epoch 9/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.6143 - accuracy: 0.6985 - val_loss: 0.6513 - val_accuracy: 0.6780\n",
      "Epoch 10/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.6104 - accuracy: 0.6912 - val_loss: 0.6482 - val_accuracy: 0.6780\n",
      "Epoch 11/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.6066 - accuracy: 0.6912 - val_loss: 0.6452 - val_accuracy: 0.6780\n",
      "Epoch 12/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.6028 - accuracy: 0.6985 - val_loss: 0.6422 - val_accuracy: 0.6780\n",
      "Epoch 13/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.5992 - accuracy: 0.6912 - val_loss: 0.6393 - val_accuracy: 0.6780\n",
      "Epoch 14/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.5955 - accuracy: 0.6985 - val_loss: 0.6365 - val_accuracy: 0.6780\n",
      "Epoch 15/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.5920 - accuracy: 0.6985 - val_loss: 0.6337 - val_accuracy: 0.6949\n",
      "Epoch 16/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.5886 - accuracy: 0.6985 - val_loss: 0.6311 - val_accuracy: 0.6949\n",
      "Epoch 17/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.5853 - accuracy: 0.6985 - val_loss: 0.6284 - val_accuracy: 0.6949\n",
      "Epoch 18/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.5820 - accuracy: 0.6985 - val_loss: 0.6260 - val_accuracy: 0.6949\n",
      "Epoch 19/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.5788 - accuracy: 0.7059 - val_loss: 0.6236 - val_accuracy: 0.7119\n",
      "Epoch 20/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.5757 - accuracy: 0.6912 - val_loss: 0.6213 - val_accuracy: 0.6949\n",
      "Epoch 21/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.5727 - accuracy: 0.6912 - val_loss: 0.6192 - val_accuracy: 0.6949\n",
      "Epoch 22/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.5697 - accuracy: 0.6912 - val_loss: 0.6171 - val_accuracy: 0.6949\n",
      "Epoch 23/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.5669 - accuracy: 0.6912 - val_loss: 0.6150 - val_accuracy: 0.7119\n",
      "Epoch 24/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.5641 - accuracy: 0.6912 - val_loss: 0.6130 - val_accuracy: 0.7119\n",
      "Epoch 25/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.5613 - accuracy: 0.6912 - val_loss: 0.6110 - val_accuracy: 0.7119\n",
      "Epoch 26/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.5586 - accuracy: 0.6985 - val_loss: 0.6090 - val_accuracy: 0.6949\n",
      "Epoch 27/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.5560 - accuracy: 0.6912 - val_loss: 0.6071 - val_accuracy: 0.6949\n",
      "Epoch 28/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.5535 - accuracy: 0.6912 - val_loss: 0.6052 - val_accuracy: 0.6780\n",
      "Epoch 29/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.5510 - accuracy: 0.7059 - val_loss: 0.6033 - val_accuracy: 0.6780\n",
      "Epoch 30/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.5485 - accuracy: 0.7059 - val_loss: 0.6015 - val_accuracy: 0.6949\n",
      "Epoch 31/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.5461 - accuracy: 0.7132 - val_loss: 0.5997 - val_accuracy: 0.6949\n",
      "Epoch 32/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.5437 - accuracy: 0.7279 - val_loss: 0.5980 - val_accuracy: 0.7288\n",
      "Epoch 33/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.5413 - accuracy: 0.7279 - val_loss: 0.5962 - val_accuracy: 0.7458\n",
      "Epoch 34/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.5391 - accuracy: 0.7279 - val_loss: 0.5946 - val_accuracy: 0.7458\n",
      "Epoch 35/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.5368 - accuracy: 0.7132 - val_loss: 0.5929 - val_accuracy: 0.7627\n",
      "Epoch 36/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.5347 - accuracy: 0.7132 - val_loss: 0.5912 - val_accuracy: 0.7627\n",
      "Epoch 37/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.5325 - accuracy: 0.7132 - val_loss: 0.5895 - val_accuracy: 0.7627\n",
      "Epoch 38/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.5304 - accuracy: 0.7132 - val_loss: 0.5879 - val_accuracy: 0.7627\n",
      "Epoch 39/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.5283 - accuracy: 0.7132 - val_loss: 0.5864 - val_accuracy: 0.7627\n",
      "Epoch 40/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.5263 - accuracy: 0.7206 - val_loss: 0.5848 - val_accuracy: 0.7627\n",
      "Epoch 41/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.5243 - accuracy: 0.7206 - val_loss: 0.5833 - val_accuracy: 0.7627\n",
      "Epoch 42/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.5224 - accuracy: 0.7279 - val_loss: 0.5818 - val_accuracy: 0.7627\n",
      "Epoch 43/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.5204 - accuracy: 0.7353 - val_loss: 0.5803 - val_accuracy: 0.7627\n",
      "Epoch 44/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.5185 - accuracy: 0.7353 - val_loss: 0.5789 - val_accuracy: 0.7627\n",
      "Epoch 45/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.5167 - accuracy: 0.7500 - val_loss: 0.5775 - val_accuracy: 0.7627\n",
      "Epoch 46/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.5149 - accuracy: 0.7574 - val_loss: 0.5761 - val_accuracy: 0.7627\n",
      "Epoch 47/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.5132 - accuracy: 0.7647 - val_loss: 0.5747 - val_accuracy: 0.7627\n",
      "Epoch 48/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.5114 - accuracy: 0.7721 - val_loss: 0.5734 - val_accuracy: 0.7627\n",
      "Epoch 49/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.5097 - accuracy: 0.7721 - val_loss: 0.5721 - val_accuracy: 0.7627\n",
      "Epoch 50/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.5080 - accuracy: 0.7721 - val_loss: 0.5708 - val_accuracy: 0.7627\n",
      "Epoch 51/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.5064 - accuracy: 0.7721 - val_loss: 0.5696 - val_accuracy: 0.7627\n",
      "Epoch 52/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.5047 - accuracy: 0.7721 - val_loss: 0.5684 - val_accuracy: 0.7627\n",
      "Epoch 53/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.5031 - accuracy: 0.7721 - val_loss: 0.5672 - val_accuracy: 0.7627\n",
      "Epoch 54/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.5014 - accuracy: 0.7868 - val_loss: 0.5660 - val_accuracy: 0.7627\n",
      "Epoch 55/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4999 - accuracy: 0.7868 - val_loss: 0.5649 - val_accuracy: 0.7627\n",
      "Epoch 56/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4983 - accuracy: 0.7941 - val_loss: 0.5637 - val_accuracy: 0.7458\n",
      "Epoch 57/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4967 - accuracy: 0.7868 - val_loss: 0.5626 - val_accuracy: 0.7288\n",
      "Epoch 58/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4952 - accuracy: 0.7941 - val_loss: 0.5615 - val_accuracy: 0.7288\n",
      "Epoch 59/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4937 - accuracy: 0.7941 - val_loss: 0.5604 - val_accuracy: 0.7288\n",
      "Epoch 60/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4922 - accuracy: 0.8015 - val_loss: 0.5594 - val_accuracy: 0.7458\n",
      "Epoch 61/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4907 - accuracy: 0.8015 - val_loss: 0.5584 - val_accuracy: 0.7458\n",
      "Epoch 62/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4893 - accuracy: 0.8015 - val_loss: 0.5574 - val_accuracy: 0.7627\n",
      "Epoch 63/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4878 - accuracy: 0.8015 - val_loss: 0.5564 - val_accuracy: 0.7627\n",
      "Epoch 64/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4864 - accuracy: 0.8015 - val_loss: 0.5554 - val_accuracy: 0.7627\n",
      "Epoch 65/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4851 - accuracy: 0.8015 - val_loss: 0.5545 - val_accuracy: 0.7458\n",
      "Epoch 66/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4838 - accuracy: 0.8015 - val_loss: 0.5535 - val_accuracy: 0.7458\n",
      "Epoch 67/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4825 - accuracy: 0.8015 - val_loss: 0.5526 - val_accuracy: 0.7458\n",
      "Epoch 68/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4813 - accuracy: 0.8088 - val_loss: 0.5516 - val_accuracy: 0.7458\n",
      "Epoch 69/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4801 - accuracy: 0.8162 - val_loss: 0.5507 - val_accuracy: 0.7458\n",
      "Epoch 70/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4789 - accuracy: 0.8162 - val_loss: 0.5498 - val_accuracy: 0.7458\n",
      "Epoch 71/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4777 - accuracy: 0.8162 - val_loss: 0.5489 - val_accuracy: 0.7458\n",
      "Epoch 72/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.4765 - accuracy: 0.8162 - val_loss: 0.5480 - val_accuracy: 0.7458\n",
      "Epoch 73/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.4754 - accuracy: 0.8162 - val_loss: 0.5471 - val_accuracy: 0.7458\n",
      "Epoch 74/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.4742 - accuracy: 0.8162 - val_loss: 0.5462 - val_accuracy: 0.7458\n",
      "Epoch 75/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4731 - accuracy: 0.8162 - val_loss: 0.5453 - val_accuracy: 0.7458\n",
      "Epoch 76/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.4720 - accuracy: 0.8309 - val_loss: 0.5445 - val_accuracy: 0.7458\n",
      "Epoch 77/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4709 - accuracy: 0.8309 - val_loss: 0.5436 - val_accuracy: 0.7458\n",
      "Epoch 78/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4698 - accuracy: 0.8309 - val_loss: 0.5428 - val_accuracy: 0.7458\n",
      "Epoch 79/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4688 - accuracy: 0.8309 - val_loss: 0.5420 - val_accuracy: 0.7458\n",
      "Epoch 80/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4677 - accuracy: 0.8309 - val_loss: 0.5412 - val_accuracy: 0.7458\n",
      "Epoch 81/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4667 - accuracy: 0.8235 - val_loss: 0.5403 - val_accuracy: 0.7458\n",
      "Epoch 82/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.4657 - accuracy: 0.8235 - val_loss: 0.5396 - val_accuracy: 0.7458\n",
      "Epoch 83/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4647 - accuracy: 0.8235 - val_loss: 0.5388 - val_accuracy: 0.7627\n",
      "Epoch 84/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4638 - accuracy: 0.8309 - val_loss: 0.5380 - val_accuracy: 0.7627\n",
      "Epoch 85/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.4628 - accuracy: 0.8309 - val_loss: 0.5372 - val_accuracy: 0.7627\n",
      "Epoch 86/4000\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.4523 - accuracy: 0.87 - 0s 59us/step - loss: 0.4619 - accuracy: 0.8309 - val_loss: 0.5365 - val_accuracy: 0.7627\n",
      "Epoch 87/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4610 - accuracy: 0.8309 - val_loss: 0.5357 - val_accuracy: 0.7627\n",
      "Epoch 88/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4600 - accuracy: 0.8309 - val_loss: 0.5350 - val_accuracy: 0.7627\n",
      "Epoch 89/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4591 - accuracy: 0.8309 - val_loss: 0.5343 - val_accuracy: 0.7627\n",
      "Epoch 90/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4582 - accuracy: 0.8309 - val_loss: 0.5336 - val_accuracy: 0.7627\n",
      "Epoch 91/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4573 - accuracy: 0.8309 - val_loss: 0.5328 - val_accuracy: 0.7627\n",
      "Epoch 92/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.4564 - accuracy: 0.8382 - val_loss: 0.5321 - val_accuracy: 0.7627\n",
      "Epoch 93/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4556 - accuracy: 0.8382 - val_loss: 0.5314 - val_accuracy: 0.7627\n",
      "Epoch 94/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4547 - accuracy: 0.8382 - val_loss: 0.5307 - val_accuracy: 0.7627\n",
      "Epoch 95/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4539 - accuracy: 0.8382 - val_loss: 0.5300 - val_accuracy: 0.7627\n",
      "Epoch 96/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.4530 - accuracy: 0.8382 - val_loss: 0.5293 - val_accuracy: 0.7627\n",
      "Epoch 97/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4522 - accuracy: 0.8382 - val_loss: 0.5286 - val_accuracy: 0.7627\n",
      "Epoch 98/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.4513 - accuracy: 0.8382 - val_loss: 0.5280 - val_accuracy: 0.7627\n",
      "Epoch 99/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4505 - accuracy: 0.8382 - val_loss: 0.5273 - val_accuracy: 0.7797\n",
      "Epoch 100/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4497 - accuracy: 0.8309 - val_loss: 0.5266 - val_accuracy: 0.7797\n",
      "Epoch 101/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4488 - accuracy: 0.8309 - val_loss: 0.5260 - val_accuracy: 0.7797\n",
      "Epoch 102/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.4480 - accuracy: 0.8309 - val_loss: 0.5254 - val_accuracy: 0.7797\n",
      "Epoch 103/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.4472 - accuracy: 0.8309 - val_loss: 0.5247 - val_accuracy: 0.7797\n",
      "Epoch 104/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4464 - accuracy: 0.8309 - val_loss: 0.5241 - val_accuracy: 0.7797\n",
      "Epoch 105/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4457 - accuracy: 0.8309 - val_loss: 0.5235 - val_accuracy: 0.7797\n",
      "Epoch 106/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4449 - accuracy: 0.8309 - val_loss: 0.5228 - val_accuracy: 0.7797\n",
      "Epoch 107/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.4441 - accuracy: 0.8309 - val_loss: 0.5222 - val_accuracy: 0.7797\n",
      "Epoch 108/4000\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.4343 - accuracy: 0.87 - 0s 52us/step - loss: 0.4434 - accuracy: 0.8309 - val_loss: 0.5216 - val_accuracy: 0.7797\n",
      "Epoch 109/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.4426 - accuracy: 0.8309 - val_loss: 0.5209 - val_accuracy: 0.7797\n",
      "Epoch 110/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.4419 - accuracy: 0.8309 - val_loss: 0.5203 - val_accuracy: 0.7797\n",
      "Epoch 111/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4412 - accuracy: 0.8309 - val_loss: 0.5197 - val_accuracy: 0.7797\n",
      "Epoch 112/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4404 - accuracy: 0.8382 - val_loss: 0.5191 - val_accuracy: 0.7797\n",
      "Epoch 113/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4397 - accuracy: 0.8309 - val_loss: 0.5185 - val_accuracy: 0.7797\n",
      "Epoch 114/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4390 - accuracy: 0.8309 - val_loss: 0.5179 - val_accuracy: 0.7797\n",
      "Epoch 115/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4382 - accuracy: 0.8309 - val_loss: 0.5173 - val_accuracy: 0.7797\n",
      "Epoch 116/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.4375 - accuracy: 0.8309 - val_loss: 0.5167 - val_accuracy: 0.7797\n",
      "Epoch 117/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4368 - accuracy: 0.8309 - val_loss: 0.5161 - val_accuracy: 0.7797\n",
      "Epoch 118/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.4361 - accuracy: 0.8309 - val_loss: 0.5155 - val_accuracy: 0.7797\n",
      "Epoch 119/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4354 - accuracy: 0.8309 - val_loss: 0.5149 - val_accuracy: 0.7797\n",
      "Epoch 120/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4347 - accuracy: 0.8235 - val_loss: 0.5143 - val_accuracy: 0.7797\n",
      "Epoch 121/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.4340 - accuracy: 0.8235 - val_loss: 0.5137 - val_accuracy: 0.7797\n",
      "Epoch 122/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4333 - accuracy: 0.8309 - val_loss: 0.5131 - val_accuracy: 0.7797\n",
      "Epoch 123/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4326 - accuracy: 0.8309 - val_loss: 0.5125 - val_accuracy: 0.7797\n",
      "Epoch 124/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.4320 - accuracy: 0.8309 - val_loss: 0.5119 - val_accuracy: 0.7797\n",
      "Epoch 125/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4313 - accuracy: 0.8309 - val_loss: 0.5114 - val_accuracy: 0.7797\n",
      "Epoch 126/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4307 - accuracy: 0.8309 - val_loss: 0.5108 - val_accuracy: 0.7797\n",
      "Epoch 127/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4300 - accuracy: 0.8382 - val_loss: 0.5102 - val_accuracy: 0.7797\n",
      "Epoch 128/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4294 - accuracy: 0.8456 - val_loss: 0.5097 - val_accuracy: 0.7797\n",
      "Epoch 129/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.4287 - accuracy: 0.8603 - val_loss: 0.5091 - val_accuracy: 0.7797\n",
      "Epoch 130/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4281 - accuracy: 0.8603 - val_loss: 0.5086 - val_accuracy: 0.7797\n",
      "Epoch 131/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4274 - accuracy: 0.8603 - val_loss: 0.5080 - val_accuracy: 0.7797\n",
      "Epoch 132/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4268 - accuracy: 0.8603 - val_loss: 0.5075 - val_accuracy: 0.7797\n",
      "Epoch 133/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4262 - accuracy: 0.8603 - val_loss: 0.5069 - val_accuracy: 0.7797\n",
      "Epoch 134/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4256 - accuracy: 0.8603 - val_loss: 0.5064 - val_accuracy: 0.7797\n",
      "Epoch 135/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.4250 - accuracy: 0.8603 - val_loss: 0.5059 - val_accuracy: 0.7797\n",
      "Epoch 136/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4244 - accuracy: 0.8603 - val_loss: 0.5053 - val_accuracy: 0.7797\n",
      "Epoch 137/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4238 - accuracy: 0.8603 - val_loss: 0.5048 - val_accuracy: 0.7797\n",
      "Epoch 138/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4232 - accuracy: 0.8603 - val_loss: 0.5043 - val_accuracy: 0.7797\n",
      "Epoch 139/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4226 - accuracy: 0.8603 - val_loss: 0.5038 - val_accuracy: 0.7797\n",
      "Epoch 140/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.4220 - accuracy: 0.8603 - val_loss: 0.5032 - val_accuracy: 0.7797\n",
      "Epoch 141/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4214 - accuracy: 0.8603 - val_loss: 0.5027 - val_accuracy: 0.7797\n",
      "Epoch 142/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.4208 - accuracy: 0.8603 - val_loss: 0.5022 - val_accuracy: 0.7797\n",
      "Epoch 143/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4202 - accuracy: 0.8603 - val_loss: 0.5017 - val_accuracy: 0.7966\n",
      "Epoch 144/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4196 - accuracy: 0.8603 - val_loss: 0.5012 - val_accuracy: 0.7966\n",
      "Epoch 145/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4191 - accuracy: 0.8603 - val_loss: 0.5007 - val_accuracy: 0.7966\n",
      "Epoch 146/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4185 - accuracy: 0.8603 - val_loss: 0.5002 - val_accuracy: 0.7966\n",
      "Epoch 147/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4180 - accuracy: 0.8603 - val_loss: 0.4997 - val_accuracy: 0.7966\n",
      "Epoch 148/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4174 - accuracy: 0.8603 - val_loss: 0.4993 - val_accuracy: 0.7966\n",
      "Epoch 149/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4168 - accuracy: 0.8603 - val_loss: 0.4988 - val_accuracy: 0.7966\n",
      "Epoch 150/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.4163 - accuracy: 0.8603 - val_loss: 0.4983 - val_accuracy: 0.7966\n",
      "Epoch 151/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.4157 - accuracy: 0.8603 - val_loss: 0.4978 - val_accuracy: 0.7966\n",
      "Epoch 152/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.4152 - accuracy: 0.8603 - val_loss: 0.4973 - val_accuracy: 0.7966\n",
      "Epoch 153/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4146 - accuracy: 0.8603 - val_loss: 0.4968 - val_accuracy: 0.7966\n",
      "Epoch 154/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4141 - accuracy: 0.8603 - val_loss: 0.4963 - val_accuracy: 0.7966\n",
      "Epoch 155/4000\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.4049 - accuracy: 0.87 - 0s 51us/step - loss: 0.4135 - accuracy: 0.8603 - val_loss: 0.4958 - val_accuracy: 0.7966\n",
      "Epoch 156/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4130 - accuracy: 0.8603 - val_loss: 0.4954 - val_accuracy: 0.7966\n",
      "Epoch 157/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4124 - accuracy: 0.8603 - val_loss: 0.4949 - val_accuracy: 0.7966\n",
      "Epoch 158/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.4119 - accuracy: 0.8603 - val_loss: 0.4944 - val_accuracy: 0.7966\n",
      "Epoch 159/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4114 - accuracy: 0.8603 - val_loss: 0.4939 - val_accuracy: 0.7966\n",
      "Epoch 160/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.4108 - accuracy: 0.8603 - val_loss: 0.4935 - val_accuracy: 0.7966\n",
      "Epoch 161/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4103 - accuracy: 0.8603 - val_loss: 0.4930 - val_accuracy: 0.7966\n",
      "Epoch 162/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4098 - accuracy: 0.8603 - val_loss: 0.4925 - val_accuracy: 0.7966\n",
      "Epoch 163/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4093 - accuracy: 0.8603 - val_loss: 0.4920 - val_accuracy: 0.7966\n",
      "Epoch 164/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4087 - accuracy: 0.8603 - val_loss: 0.4915 - val_accuracy: 0.7966\n",
      "Epoch 165/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.4082 - accuracy: 0.8603 - val_loss: 0.4911 - val_accuracy: 0.7966\n",
      "Epoch 166/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4076 - accuracy: 0.8603 - val_loss: 0.4906 - val_accuracy: 0.7966\n",
      "Epoch 167/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4071 - accuracy: 0.8603 - val_loss: 0.4901 - val_accuracy: 0.7966\n",
      "Epoch 168/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4066 - accuracy: 0.8603 - val_loss: 0.4897 - val_accuracy: 0.7966\n",
      "Epoch 169/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4061 - accuracy: 0.8603 - val_loss: 0.4892 - val_accuracy: 0.7966\n",
      "Epoch 170/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.4055 - accuracy: 0.8603 - val_loss: 0.4887 - val_accuracy: 0.7966\n",
      "Epoch 171/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4050 - accuracy: 0.8603 - val_loss: 0.4883 - val_accuracy: 0.7966\n",
      "Epoch 172/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4045 - accuracy: 0.8603 - val_loss: 0.4878 - val_accuracy: 0.7966\n",
      "Epoch 173/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4040 - accuracy: 0.8603 - val_loss: 0.4874 - val_accuracy: 0.7966\n",
      "Epoch 174/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4035 - accuracy: 0.8603 - val_loss: 0.4870 - val_accuracy: 0.7966\n",
      "Epoch 175/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4030 - accuracy: 0.8603 - val_loss: 0.4865 - val_accuracy: 0.7966\n",
      "Epoch 176/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.4025 - accuracy: 0.8603 - val_loss: 0.4861 - val_accuracy: 0.7966\n",
      "Epoch 177/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.4020 - accuracy: 0.8676 - val_loss: 0.4857 - val_accuracy: 0.7966\n",
      "Epoch 178/4000\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.3936 - accuracy: 0.87 - 0s 59us/step - loss: 0.4015 - accuracy: 0.8676 - val_loss: 0.4853 - val_accuracy: 0.7966\n",
      "Epoch 179/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.4010 - accuracy: 0.8676 - val_loss: 0.4848 - val_accuracy: 0.7966\n",
      "Epoch 180/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4005 - accuracy: 0.8676 - val_loss: 0.4844 - val_accuracy: 0.7966\n",
      "Epoch 181/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.4001 - accuracy: 0.8676 - val_loss: 0.4840 - val_accuracy: 0.7966\n",
      "Epoch 182/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3996 - accuracy: 0.8676 - val_loss: 0.4836 - val_accuracy: 0.7966\n",
      "Epoch 183/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3991 - accuracy: 0.8676 - val_loss: 0.4832 - val_accuracy: 0.7966\n",
      "Epoch 184/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3986 - accuracy: 0.8676 - val_loss: 0.4828 - val_accuracy: 0.7966\n",
      "Epoch 185/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3981 - accuracy: 0.8676 - val_loss: 0.4823 - val_accuracy: 0.7966\n",
      "Epoch 186/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3977 - accuracy: 0.8676 - val_loss: 0.4819 - val_accuracy: 0.7966\n",
      "Epoch 187/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.3972 - accuracy: 0.8676 - val_loss: 0.4815 - val_accuracy: 0.7966\n",
      "Epoch 188/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3967 - accuracy: 0.8676 - val_loss: 0.4811 - val_accuracy: 0.7966\n",
      "Epoch 189/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.3963 - accuracy: 0.8676 - val_loss: 0.4807 - val_accuracy: 0.7966\n",
      "Epoch 190/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3958 - accuracy: 0.8676 - val_loss: 0.4804 - val_accuracy: 0.7966\n",
      "Epoch 191/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3953 - accuracy: 0.8676 - val_loss: 0.4800 - val_accuracy: 0.7966\n",
      "Epoch 192/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3949 - accuracy: 0.8676 - val_loss: 0.4796 - val_accuracy: 0.7966\n",
      "Epoch 193/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.3944 - accuracy: 0.8676 - val_loss: 0.4792 - val_accuracy: 0.7966\n",
      "Epoch 194/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3940 - accuracy: 0.8676 - val_loss: 0.4788 - val_accuracy: 0.7966\n",
      "Epoch 195/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3936 - accuracy: 0.8676 - val_loss: 0.4785 - val_accuracy: 0.7966\n",
      "Epoch 196/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3931 - accuracy: 0.8676 - val_loss: 0.4781 - val_accuracy: 0.7966\n",
      "Epoch 197/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3927 - accuracy: 0.8676 - val_loss: 0.4777 - val_accuracy: 0.7966\n",
      "Epoch 198/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3922 - accuracy: 0.8676 - val_loss: 0.4773 - val_accuracy: 0.7966\n",
      "Epoch 199/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3918 - accuracy: 0.8676 - val_loss: 0.4770 - val_accuracy: 0.7966\n",
      "Epoch 200/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.3914 - accuracy: 0.8676 - val_loss: 0.4766 - val_accuracy: 0.7966\n",
      "Epoch 201/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3909 - accuracy: 0.8676 - val_loss: 0.4762 - val_accuracy: 0.7966\n",
      "Epoch 202/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3905 - accuracy: 0.8676 - val_loss: 0.4759 - val_accuracy: 0.7966\n",
      "Epoch 203/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3901 - accuracy: 0.8676 - val_loss: 0.4755 - val_accuracy: 0.7966\n",
      "Epoch 204/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3897 - accuracy: 0.8676 - val_loss: 0.4752 - val_accuracy: 0.7966\n",
      "Epoch 205/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3892 - accuracy: 0.8676 - val_loss: 0.4748 - val_accuracy: 0.7966\n",
      "Epoch 206/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3888 - accuracy: 0.8676 - val_loss: 0.4745 - val_accuracy: 0.7966\n",
      "Epoch 207/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3884 - accuracy: 0.8676 - val_loss: 0.4741 - val_accuracy: 0.7966\n",
      "Epoch 208/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3880 - accuracy: 0.8676 - val_loss: 0.4738 - val_accuracy: 0.7966\n",
      "Epoch 209/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3876 - accuracy: 0.8676 - val_loss: 0.4734 - val_accuracy: 0.7966\n",
      "Epoch 210/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3872 - accuracy: 0.8676 - val_loss: 0.4731 - val_accuracy: 0.7966\n",
      "Epoch 211/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3868 - accuracy: 0.8676 - val_loss: 0.4727 - val_accuracy: 0.7966\n",
      "Epoch 212/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3864 - accuracy: 0.8676 - val_loss: 0.4724 - val_accuracy: 0.7966\n",
      "Epoch 213/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3860 - accuracy: 0.8676 - val_loss: 0.4720 - val_accuracy: 0.7966\n",
      "Epoch 214/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3856 - accuracy: 0.8676 - val_loss: 0.4717 - val_accuracy: 0.7966\n",
      "Epoch 215/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3852 - accuracy: 0.8676 - val_loss: 0.4714 - val_accuracy: 0.7966\n",
      "Epoch 216/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3847 - accuracy: 0.8676 - val_loss: 0.4710 - val_accuracy: 0.7966\n",
      "Epoch 217/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.3843 - accuracy: 0.8676 - val_loss: 0.4707 - val_accuracy: 0.7966\n",
      "Epoch 218/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3839 - accuracy: 0.8676 - val_loss: 0.4703 - val_accuracy: 0.7966\n",
      "Epoch 219/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3834 - accuracy: 0.8676 - val_loss: 0.4700 - val_accuracy: 0.7966\n",
      "Epoch 220/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3830 - accuracy: 0.8750 - val_loss: 0.4696 - val_accuracy: 0.7966\n",
      "Epoch 221/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3826 - accuracy: 0.8750 - val_loss: 0.4693 - val_accuracy: 0.7966\n",
      "Epoch 222/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3822 - accuracy: 0.8750 - val_loss: 0.4690 - val_accuracy: 0.7966\n",
      "Epoch 223/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3818 - accuracy: 0.8750 - val_loss: 0.4686 - val_accuracy: 0.7966\n",
      "Epoch 224/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3814 - accuracy: 0.8750 - val_loss: 0.4683 - val_accuracy: 0.7966\n",
      "Epoch 225/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3810 - accuracy: 0.8750 - val_loss: 0.4680 - val_accuracy: 0.7966\n",
      "Epoch 226/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3806 - accuracy: 0.8750 - val_loss: 0.4676 - val_accuracy: 0.7966\n",
      "Epoch 227/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3802 - accuracy: 0.8750 - val_loss: 0.4673 - val_accuracy: 0.7966\n",
      "Epoch 228/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3797 - accuracy: 0.8750 - val_loss: 0.4670 - val_accuracy: 0.7966\n",
      "Epoch 229/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3793 - accuracy: 0.8750 - val_loss: 0.4666 - val_accuracy: 0.7966\n",
      "Epoch 230/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3789 - accuracy: 0.8750 - val_loss: 0.4663 - val_accuracy: 0.7966\n",
      "Epoch 231/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3784 - accuracy: 0.8750 - val_loss: 0.4659 - val_accuracy: 0.7966\n",
      "Epoch 232/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3780 - accuracy: 0.8750 - val_loss: 0.4656 - val_accuracy: 0.7966\n",
      "Epoch 233/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3776 - accuracy: 0.8750 - val_loss: 0.4652 - val_accuracy: 0.7966\n",
      "Epoch 234/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3771 - accuracy: 0.8750 - val_loss: 0.4649 - val_accuracy: 0.7966\n",
      "Epoch 235/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3767 - accuracy: 0.8750 - val_loss: 0.4646 - val_accuracy: 0.7966\n",
      "Epoch 236/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3763 - accuracy: 0.8750 - val_loss: 0.4642 - val_accuracy: 0.7966\n",
      "Epoch 237/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3758 - accuracy: 0.8750 - val_loss: 0.4639 - val_accuracy: 0.7966\n",
      "Epoch 238/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3754 - accuracy: 0.8750 - val_loss: 0.4636 - val_accuracy: 0.7966\n",
      "Epoch 239/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3750 - accuracy: 0.8750 - val_loss: 0.4632 - val_accuracy: 0.7966\n",
      "Epoch 240/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3746 - accuracy: 0.8750 - val_loss: 0.4629 - val_accuracy: 0.7966\n",
      "Epoch 241/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3741 - accuracy: 0.8750 - val_loss: 0.4626 - val_accuracy: 0.7966\n",
      "Epoch 242/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3737 - accuracy: 0.8750 - val_loss: 0.4623 - val_accuracy: 0.7966\n",
      "Epoch 243/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3733 - accuracy: 0.8750 - val_loss: 0.4619 - val_accuracy: 0.7966\n",
      "Epoch 244/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.3729 - accuracy: 0.8750 - val_loss: 0.4616 - val_accuracy: 0.7966\n",
      "Epoch 245/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3725 - accuracy: 0.8750 - val_loss: 0.4613 - val_accuracy: 0.7966\n",
      "Epoch 246/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.3721 - accuracy: 0.8750 - val_loss: 0.4610 - val_accuracy: 0.7966\n",
      "Epoch 247/4000\n",
      "136/136 [==============================] - 0s 73us/step - loss: 0.3717 - accuracy: 0.8750 - val_loss: 0.4607 - val_accuracy: 0.7966\n",
      "Epoch 248/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3713 - accuracy: 0.8750 - val_loss: 0.4604 - val_accuracy: 0.7966\n",
      "Epoch 249/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3709 - accuracy: 0.8750 - val_loss: 0.4600 - val_accuracy: 0.7966\n",
      "Epoch 250/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3705 - accuracy: 0.8750 - val_loss: 0.4597 - val_accuracy: 0.7966\n",
      "Epoch 251/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3701 - accuracy: 0.8750 - val_loss: 0.4594 - val_accuracy: 0.7966\n",
      "Epoch 252/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3697 - accuracy: 0.8750 - val_loss: 0.4591 - val_accuracy: 0.7966\n",
      "Epoch 253/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3693 - accuracy: 0.8750 - val_loss: 0.4588 - val_accuracy: 0.7966\n",
      "Epoch 254/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3690 - accuracy: 0.8750 - val_loss: 0.4585 - val_accuracy: 0.7966\n",
      "Epoch 255/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3686 - accuracy: 0.8750 - val_loss: 0.4582 - val_accuracy: 0.7966\n",
      "Epoch 256/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3682 - accuracy: 0.8750 - val_loss: 0.4579 - val_accuracy: 0.7966\n",
      "Epoch 257/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3678 - accuracy: 0.8750 - val_loss: 0.4576 - val_accuracy: 0.7966\n",
      "Epoch 258/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3674 - accuracy: 0.8750 - val_loss: 0.4572 - val_accuracy: 0.7966\n",
      "Epoch 259/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3669 - accuracy: 0.8750 - val_loss: 0.4569 - val_accuracy: 0.7966\n",
      "Epoch 260/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3665 - accuracy: 0.8750 - val_loss: 0.4565 - val_accuracy: 0.7966\n",
      "Epoch 261/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.3661 - accuracy: 0.8750 - val_loss: 0.4562 - val_accuracy: 0.7966\n",
      "Epoch 262/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3656 - accuracy: 0.8750 - val_loss: 0.4559 - val_accuracy: 0.7966\n",
      "Epoch 263/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3652 - accuracy: 0.8750 - val_loss: 0.4555 - val_accuracy: 0.7966\n",
      "Epoch 264/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3647 - accuracy: 0.8750 - val_loss: 0.4552 - val_accuracy: 0.7966\n",
      "Epoch 265/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3643 - accuracy: 0.8750 - val_loss: 0.4549 - val_accuracy: 0.7966\n",
      "Epoch 266/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3639 - accuracy: 0.8750 - val_loss: 0.4545 - val_accuracy: 0.7966\n",
      "Epoch 267/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3635 - accuracy: 0.8676 - val_loss: 0.4541 - val_accuracy: 0.7966\n",
      "Epoch 268/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3631 - accuracy: 0.8676 - val_loss: 0.4538 - val_accuracy: 0.7966\n",
      "Epoch 269/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3627 - accuracy: 0.8676 - val_loss: 0.4533 - val_accuracy: 0.7966\n",
      "Epoch 270/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3622 - accuracy: 0.8676 - val_loss: 0.4529 - val_accuracy: 0.7966\n",
      "Epoch 271/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3617 - accuracy: 0.8676 - val_loss: 0.4525 - val_accuracy: 0.7966\n",
      "Epoch 272/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3612 - accuracy: 0.8676 - val_loss: 0.4521 - val_accuracy: 0.7966\n",
      "Epoch 273/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3608 - accuracy: 0.8676 - val_loss: 0.4518 - val_accuracy: 0.7966\n",
      "Epoch 274/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3603 - accuracy: 0.8676 - val_loss: 0.4514 - val_accuracy: 0.7966\n",
      "Epoch 275/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3599 - accuracy: 0.8676 - val_loss: 0.4510 - val_accuracy: 0.7966\n",
      "Epoch 276/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3594 - accuracy: 0.8676 - val_loss: 0.4506 - val_accuracy: 0.7966\n",
      "Epoch 277/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3590 - accuracy: 0.8676 - val_loss: 0.4502 - val_accuracy: 0.7966\n",
      "Epoch 278/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3585 - accuracy: 0.8676 - val_loss: 0.4499 - val_accuracy: 0.7966\n",
      "Epoch 279/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3581 - accuracy: 0.8676 - val_loss: 0.4495 - val_accuracy: 0.7966\n",
      "Epoch 280/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3576 - accuracy: 0.8676 - val_loss: 0.4491 - val_accuracy: 0.7966\n",
      "Epoch 281/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3572 - accuracy: 0.8676 - val_loss: 0.4488 - val_accuracy: 0.7966\n",
      "Epoch 282/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3568 - accuracy: 0.8676 - val_loss: 0.4484 - val_accuracy: 0.7966\n",
      "Epoch 283/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3563 - accuracy: 0.8676 - val_loss: 0.4480 - val_accuracy: 0.7966\n",
      "Epoch 284/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3559 - accuracy: 0.8676 - val_loss: 0.4477 - val_accuracy: 0.7966\n",
      "Epoch 285/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3555 - accuracy: 0.8676 - val_loss: 0.4473 - val_accuracy: 0.7966\n",
      "Epoch 286/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3550 - accuracy: 0.8676 - val_loss: 0.4470 - val_accuracy: 0.7966\n",
      "Epoch 287/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3546 - accuracy: 0.8676 - val_loss: 0.4466 - val_accuracy: 0.7966\n",
      "Epoch 288/4000\n",
      "136/136 [==============================] - 0s 42us/step - loss: 0.3542 - accuracy: 0.8676 - val_loss: 0.4463 - val_accuracy: 0.7966\n",
      "Epoch 289/4000\n",
      "136/136 [==============================] - 0s 77us/step - loss: 0.3538 - accuracy: 0.8676 - val_loss: 0.4459 - val_accuracy: 0.7966\n",
      "Epoch 290/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3534 - accuracy: 0.8676 - val_loss: 0.4456 - val_accuracy: 0.7966\n",
      "Epoch 291/4000\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.3507 - accuracy: 0.87 - 0s 59us/step - loss: 0.3529 - accuracy: 0.8676 - val_loss: 0.4453 - val_accuracy: 0.7966\n",
      "Epoch 292/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3525 - accuracy: 0.8676 - val_loss: 0.4449 - val_accuracy: 0.7966\n",
      "Epoch 293/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3521 - accuracy: 0.8676 - val_loss: 0.4446 - val_accuracy: 0.7966\n",
      "Epoch 294/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.3517 - accuracy: 0.8676 - val_loss: 0.4443 - val_accuracy: 0.7966\n",
      "Epoch 295/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3513 - accuracy: 0.8676 - val_loss: 0.4440 - val_accuracy: 0.7966\n",
      "Epoch 296/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3509 - accuracy: 0.8676 - val_loss: 0.4437 - val_accuracy: 0.7966\n",
      "Epoch 297/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3505 - accuracy: 0.8676 - val_loss: 0.4433 - val_accuracy: 0.7966\n",
      "Epoch 298/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3501 - accuracy: 0.8676 - val_loss: 0.4430 - val_accuracy: 0.7966\n",
      "Epoch 299/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3497 - accuracy: 0.8676 - val_loss: 0.4427 - val_accuracy: 0.7966\n",
      "Epoch 300/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3493 - accuracy: 0.8676 - val_loss: 0.4424 - val_accuracy: 0.7966\n",
      "Epoch 301/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3489 - accuracy: 0.8676 - val_loss: 0.4421 - val_accuracy: 0.7966\n",
      "Epoch 302/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3486 - accuracy: 0.8676 - val_loss: 0.4418 - val_accuracy: 0.7966\n",
      "Epoch 303/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3482 - accuracy: 0.8676 - val_loss: 0.4415 - val_accuracy: 0.7966\n",
      "Epoch 304/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3478 - accuracy: 0.8676 - val_loss: 0.4413 - val_accuracy: 0.7966\n",
      "Epoch 305/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3474 - accuracy: 0.8676 - val_loss: 0.4410 - val_accuracy: 0.7966\n",
      "Epoch 306/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3470 - accuracy: 0.8676 - val_loss: 0.4407 - val_accuracy: 0.7966\n",
      "Epoch 307/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3466 - accuracy: 0.8676 - val_loss: 0.4404 - val_accuracy: 0.8136\n",
      "Epoch 308/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3462 - accuracy: 0.8676 - val_loss: 0.4401 - val_accuracy: 0.8136\n",
      "Epoch 309/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3459 - accuracy: 0.8676 - val_loss: 0.4398 - val_accuracy: 0.8136\n",
      "Epoch 310/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3455 - accuracy: 0.8676 - val_loss: 0.4395 - val_accuracy: 0.8136\n",
      "Epoch 311/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3451 - accuracy: 0.8676 - val_loss: 0.4392 - val_accuracy: 0.8136\n",
      "Epoch 312/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3447 - accuracy: 0.8676 - val_loss: 0.4390 - val_accuracy: 0.8136\n",
      "Epoch 313/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3444 - accuracy: 0.8676 - val_loss: 0.4387 - val_accuracy: 0.8136\n",
      "Epoch 314/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3440 - accuracy: 0.8676 - val_loss: 0.4384 - val_accuracy: 0.8136\n",
      "Epoch 315/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3436 - accuracy: 0.8676 - val_loss: 0.4381 - val_accuracy: 0.8136\n",
      "Epoch 316/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3433 - accuracy: 0.8676 - val_loss: 0.4379 - val_accuracy: 0.8136\n",
      "Epoch 317/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3429 - accuracy: 0.8750 - val_loss: 0.4376 - val_accuracy: 0.8136\n",
      "Epoch 318/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3425 - accuracy: 0.8750 - val_loss: 0.4373 - val_accuracy: 0.8136\n",
      "Epoch 319/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3422 - accuracy: 0.8750 - val_loss: 0.4371 - val_accuracy: 0.8136\n",
      "Epoch 320/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.3418 - accuracy: 0.8750 - val_loss: 0.4368 - val_accuracy: 0.8136\n",
      "Epoch 321/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3415 - accuracy: 0.8750 - val_loss: 0.4365 - val_accuracy: 0.8136\n",
      "Epoch 322/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3411 - accuracy: 0.8750 - val_loss: 0.4363 - val_accuracy: 0.8136\n",
      "Epoch 323/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3407 - accuracy: 0.8750 - val_loss: 0.4360 - val_accuracy: 0.8136\n",
      "Epoch 324/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.3404 - accuracy: 0.8750 - val_loss: 0.4357 - val_accuracy: 0.8136\n",
      "Epoch 325/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3400 - accuracy: 0.8750 - val_loss: 0.4355 - val_accuracy: 0.8136\n",
      "Epoch 326/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.3397 - accuracy: 0.8750 - val_loss: 0.4352 - val_accuracy: 0.8136\n",
      "Epoch 327/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3393 - accuracy: 0.8750 - val_loss: 0.4349 - val_accuracy: 0.8136\n",
      "Epoch 328/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3390 - accuracy: 0.8750 - val_loss: 0.4347 - val_accuracy: 0.8136\n",
      "Epoch 329/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3386 - accuracy: 0.8750 - val_loss: 0.4344 - val_accuracy: 0.8136\n",
      "Epoch 330/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3383 - accuracy: 0.8750 - val_loss: 0.4342 - val_accuracy: 0.8136\n",
      "Epoch 331/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3379 - accuracy: 0.8750 - val_loss: 0.4339 - val_accuracy: 0.8136\n",
      "Epoch 332/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3376 - accuracy: 0.8750 - val_loss: 0.4337 - val_accuracy: 0.8136\n",
      "Epoch 333/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3373 - accuracy: 0.8750 - val_loss: 0.4334 - val_accuracy: 0.8136\n",
      "Epoch 334/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.3369 - accuracy: 0.8750 - val_loss: 0.4332 - val_accuracy: 0.8136\n",
      "Epoch 335/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.3366 - accuracy: 0.8750 - val_loss: 0.4329 - val_accuracy: 0.8136\n",
      "Epoch 336/4000\n",
      "136/136 [==============================] - 0s 73us/step - loss: 0.3362 - accuracy: 0.8750 - val_loss: 0.4327 - val_accuracy: 0.8136\n",
      "Epoch 337/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3359 - accuracy: 0.8750 - val_loss: 0.4324 - val_accuracy: 0.8136\n",
      "Epoch 338/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3356 - accuracy: 0.8824 - val_loss: 0.4322 - val_accuracy: 0.8136\n",
      "Epoch 339/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.3352 - accuracy: 0.8824 - val_loss: 0.4320 - val_accuracy: 0.8136\n",
      "Epoch 340/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.3349 - accuracy: 0.8824 - val_loss: 0.4317 - val_accuracy: 0.8136\n",
      "Epoch 341/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.3346 - accuracy: 0.8824 - val_loss: 0.4315 - val_accuracy: 0.8136\n",
      "Epoch 342/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3342 - accuracy: 0.8824 - val_loss: 0.4312 - val_accuracy: 0.8136\n",
      "Epoch 343/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3339 - accuracy: 0.8824 - val_loss: 0.4310 - val_accuracy: 0.8136\n",
      "Epoch 344/4000\n",
      "136/136 [==============================] - 0s 73us/step - loss: 0.3336 - accuracy: 0.8897 - val_loss: 0.4308 - val_accuracy: 0.8136\n",
      "Epoch 345/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3332 - accuracy: 0.8897 - val_loss: 0.4305 - val_accuracy: 0.8136\n",
      "Epoch 346/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.3329 - accuracy: 0.8897 - val_loss: 0.4303 - val_accuracy: 0.8136\n",
      "Epoch 347/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3326 - accuracy: 0.8897 - val_loss: 0.4300 - val_accuracy: 0.8136\n",
      "Epoch 348/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3322 - accuracy: 0.8897 - val_loss: 0.4298 - val_accuracy: 0.8136\n",
      "Epoch 349/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3319 - accuracy: 0.8897 - val_loss: 0.4296 - val_accuracy: 0.8136\n",
      "Epoch 350/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3316 - accuracy: 0.8897 - val_loss: 0.4293 - val_accuracy: 0.8136\n",
      "Epoch 351/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3313 - accuracy: 0.8897 - val_loss: 0.4291 - val_accuracy: 0.8136\n",
      "Epoch 352/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3310 - accuracy: 0.8897 - val_loss: 0.4289 - val_accuracy: 0.8136\n",
      "Epoch 353/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.3306 - accuracy: 0.8897 - val_loss: 0.4287 - val_accuracy: 0.8136\n",
      "Epoch 354/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3303 - accuracy: 0.8897 - val_loss: 0.4284 - val_accuracy: 0.8136\n",
      "Epoch 355/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3300 - accuracy: 0.8897 - val_loss: 0.4282 - val_accuracy: 0.8136\n",
      "Epoch 356/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3297 - accuracy: 0.8897 - val_loss: 0.4280 - val_accuracy: 0.8136\n",
      "Epoch 357/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3294 - accuracy: 0.8897 - val_loss: 0.4278 - val_accuracy: 0.8136\n",
      "Epoch 358/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3291 - accuracy: 0.8897 - val_loss: 0.4275 - val_accuracy: 0.8136\n",
      "Epoch 359/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3287 - accuracy: 0.8897 - val_loss: 0.4273 - val_accuracy: 0.8136\n",
      "Epoch 360/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.3284 - accuracy: 0.8897 - val_loss: 0.4271 - val_accuracy: 0.8136\n",
      "Epoch 361/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3281 - accuracy: 0.8897 - val_loss: 0.4269 - val_accuracy: 0.8136\n",
      "Epoch 362/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3278 - accuracy: 0.8897 - val_loss: 0.4267 - val_accuracy: 0.8136\n",
      "Epoch 363/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.3275 - accuracy: 0.8897 - val_loss: 0.4264 - val_accuracy: 0.8136\n",
      "Epoch 364/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3272 - accuracy: 0.8897 - val_loss: 0.4262 - val_accuracy: 0.8136\n",
      "Epoch 365/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.3269 - accuracy: 0.8897 - val_loss: 0.4260 - val_accuracy: 0.8136\n",
      "Epoch 366/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3266 - accuracy: 0.8897 - val_loss: 0.4258 - val_accuracy: 0.8136\n",
      "Epoch 367/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3263 - accuracy: 0.8897 - val_loss: 0.4256 - val_accuracy: 0.8136\n",
      "Epoch 368/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3260 - accuracy: 0.8897 - val_loss: 0.4254 - val_accuracy: 0.8136\n",
      "Epoch 369/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3257 - accuracy: 0.8897 - val_loss: 0.4252 - val_accuracy: 0.8136\n",
      "Epoch 370/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3254 - accuracy: 0.8897 - val_loss: 0.4249 - val_accuracy: 0.8136\n",
      "Epoch 371/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3251 - accuracy: 0.8897 - val_loss: 0.4247 - val_accuracy: 0.8136\n",
      "Epoch 372/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3248 - accuracy: 0.8897 - val_loss: 0.4245 - val_accuracy: 0.8136\n",
      "Epoch 373/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3246 - accuracy: 0.8897 - val_loss: 0.4243 - val_accuracy: 0.8136\n",
      "Epoch 374/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3243 - accuracy: 0.8897 - val_loss: 0.4241 - val_accuracy: 0.8136\n",
      "Epoch 375/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3240 - accuracy: 0.8897 - val_loss: 0.4239 - val_accuracy: 0.8136\n",
      "Epoch 376/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.3237 - accuracy: 0.8897 - val_loss: 0.4237 - val_accuracy: 0.8136\n",
      "Epoch 377/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3234 - accuracy: 0.8897 - val_loss: 0.4235 - val_accuracy: 0.8136\n",
      "Epoch 378/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3231 - accuracy: 0.8897 - val_loss: 0.4233 - val_accuracy: 0.8136\n",
      "Epoch 379/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.3228 - accuracy: 0.8897 - val_loss: 0.4231 - val_accuracy: 0.8136\n",
      "Epoch 380/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3226 - accuracy: 0.8897 - val_loss: 0.4229 - val_accuracy: 0.8136\n",
      "Epoch 381/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3223 - accuracy: 0.8897 - val_loss: 0.4227 - val_accuracy: 0.8136\n",
      "Epoch 382/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3220 - accuracy: 0.8897 - val_loss: 0.4225 - val_accuracy: 0.8136\n",
      "Epoch 383/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3217 - accuracy: 0.8897 - val_loss: 0.4223 - val_accuracy: 0.8136\n",
      "Epoch 384/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3214 - accuracy: 0.8897 - val_loss: 0.4221 - val_accuracy: 0.8136\n",
      "Epoch 385/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3212 - accuracy: 0.8897 - val_loss: 0.4219 - val_accuracy: 0.8136\n",
      "Epoch 386/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.3209 - accuracy: 0.8897 - val_loss: 0.4217 - val_accuracy: 0.8136\n",
      "Epoch 387/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3206 - accuracy: 0.8897 - val_loss: 0.4215 - val_accuracy: 0.8136\n",
      "Epoch 388/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3204 - accuracy: 0.8897 - val_loss: 0.4213 - val_accuracy: 0.8136\n",
      "Epoch 389/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3201 - accuracy: 0.8897 - val_loss: 0.4211 - val_accuracy: 0.8136\n",
      "Epoch 390/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.3198 - accuracy: 0.8897 - val_loss: 0.4209 - val_accuracy: 0.8136\n",
      "Epoch 391/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3195 - accuracy: 0.8897 - val_loss: 0.4208 - val_accuracy: 0.8136\n",
      "Epoch 392/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3193 - accuracy: 0.8897 - val_loss: 0.4206 - val_accuracy: 0.8136\n",
      "Epoch 393/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.3190 - accuracy: 0.8897 - val_loss: 0.4204 - val_accuracy: 0.8136\n",
      "Epoch 394/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3187 - accuracy: 0.8897 - val_loss: 0.4202 - val_accuracy: 0.8136\n",
      "Epoch 395/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3185 - accuracy: 0.8897 - val_loss: 0.4200 - val_accuracy: 0.8136\n",
      "Epoch 396/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3182 - accuracy: 0.8897 - val_loss: 0.4198 - val_accuracy: 0.8136\n",
      "Epoch 397/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3179 - accuracy: 0.8897 - val_loss: 0.4196 - val_accuracy: 0.8136\n",
      "Epoch 398/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3177 - accuracy: 0.8897 - val_loss: 0.4195 - val_accuracy: 0.8136\n",
      "Epoch 399/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3174 - accuracy: 0.8897 - val_loss: 0.4193 - val_accuracy: 0.8136\n",
      "Epoch 400/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3171 - accuracy: 0.8897 - val_loss: 0.4191 - val_accuracy: 0.8136\n",
      "Epoch 401/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.3168 - accuracy: 0.8897 - val_loss: 0.4189 - val_accuracy: 0.8136\n",
      "Epoch 402/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3165 - accuracy: 0.8897 - val_loss: 0.4187 - val_accuracy: 0.8136\n",
      "Epoch 403/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3163 - accuracy: 0.8897 - val_loss: 0.4185 - val_accuracy: 0.8136\n",
      "Epoch 404/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3160 - accuracy: 0.8897 - val_loss: 0.4183 - val_accuracy: 0.8136\n",
      "Epoch 405/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3157 - accuracy: 0.8897 - val_loss: 0.4181 - val_accuracy: 0.8136\n",
      "Epoch 406/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3154 - accuracy: 0.8897 - val_loss: 0.4180 - val_accuracy: 0.8136\n",
      "Epoch 407/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3151 - accuracy: 0.8897 - val_loss: 0.4178 - val_accuracy: 0.8136\n",
      "Epoch 408/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3148 - accuracy: 0.8897 - val_loss: 0.4176 - val_accuracy: 0.8136\n",
      "Epoch 409/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.3146 - accuracy: 0.8897 - val_loss: 0.4174 - val_accuracy: 0.8136\n",
      "Epoch 410/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3143 - accuracy: 0.8897 - val_loss: 0.4172 - val_accuracy: 0.8305\n",
      "Epoch 411/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3140 - accuracy: 0.8897 - val_loss: 0.4171 - val_accuracy: 0.8305\n",
      "Epoch 412/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3137 - accuracy: 0.8897 - val_loss: 0.4169 - val_accuracy: 0.8305\n",
      "Epoch 413/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3135 - accuracy: 0.8897 - val_loss: 0.4167 - val_accuracy: 0.8305\n",
      "Epoch 414/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3132 - accuracy: 0.8897 - val_loss: 0.4165 - val_accuracy: 0.8305\n",
      "Epoch 415/4000\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.3095 - accuracy: 0.87 - 0s 51us/step - loss: 0.3129 - accuracy: 0.8897 - val_loss: 0.4164 - val_accuracy: 0.8305\n",
      "Epoch 416/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.3127 - accuracy: 0.8897 - val_loss: 0.4162 - val_accuracy: 0.8305\n",
      "Epoch 417/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3124 - accuracy: 0.8897 - val_loss: 0.4160 - val_accuracy: 0.8305\n",
      "Epoch 418/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3121 - accuracy: 0.8897 - val_loss: 0.4158 - val_accuracy: 0.8305\n",
      "Epoch 419/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3118 - accuracy: 0.8897 - val_loss: 0.4157 - val_accuracy: 0.8305\n",
      "Epoch 420/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3116 - accuracy: 0.8897 - val_loss: 0.4155 - val_accuracy: 0.8305\n",
      "Epoch 421/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3113 - accuracy: 0.8897 - val_loss: 0.4153 - val_accuracy: 0.8305\n",
      "Epoch 422/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3111 - accuracy: 0.8897 - val_loss: 0.4152 - val_accuracy: 0.8305\n",
      "Epoch 423/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3108 - accuracy: 0.8897 - val_loss: 0.4150 - val_accuracy: 0.8305\n",
      "Epoch 424/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3105 - accuracy: 0.8897 - val_loss: 0.4149 - val_accuracy: 0.8305\n",
      "Epoch 425/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3103 - accuracy: 0.8971 - val_loss: 0.4147 - val_accuracy: 0.8305\n",
      "Epoch 426/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3100 - accuracy: 0.8971 - val_loss: 0.4146 - val_accuracy: 0.8305\n",
      "Epoch 427/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3097 - accuracy: 0.8971 - val_loss: 0.4144 - val_accuracy: 0.8305\n",
      "Epoch 428/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3095 - accuracy: 0.8971 - val_loss: 0.4142 - val_accuracy: 0.8305\n",
      "Epoch 429/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.3092 - accuracy: 0.8971 - val_loss: 0.4140 - val_accuracy: 0.8305\n",
      "Epoch 430/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3090 - accuracy: 0.8971 - val_loss: 0.4138 - val_accuracy: 0.8305\n",
      "Epoch 431/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3087 - accuracy: 0.8971 - val_loss: 0.4136 - val_accuracy: 0.8305\n",
      "Epoch 432/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3084 - accuracy: 0.8971 - val_loss: 0.4134 - val_accuracy: 0.8305\n",
      "Epoch 433/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3082 - accuracy: 0.8971 - val_loss: 0.4132 - val_accuracy: 0.8305\n",
      "Epoch 434/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3079 - accuracy: 0.8971 - val_loss: 0.4130 - val_accuracy: 0.8305\n",
      "Epoch 435/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3077 - accuracy: 0.8971 - val_loss: 0.4128 - val_accuracy: 0.8305\n",
      "Epoch 436/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.3074 - accuracy: 0.8971 - val_loss: 0.4126 - val_accuracy: 0.8305\n",
      "Epoch 437/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.3072 - accuracy: 0.8971 - val_loss: 0.4125 - val_accuracy: 0.8305\n",
      "Epoch 438/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3069 - accuracy: 0.8971 - val_loss: 0.4123 - val_accuracy: 0.8305\n",
      "Epoch 439/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3067 - accuracy: 0.8971 - val_loss: 0.4121 - val_accuracy: 0.8305\n",
      "Epoch 440/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3064 - accuracy: 0.8971 - val_loss: 0.4119 - val_accuracy: 0.8305\n",
      "Epoch 441/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3062 - accuracy: 0.8971 - val_loss: 0.4117 - val_accuracy: 0.8305\n",
      "Epoch 442/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3059 - accuracy: 0.8971 - val_loss: 0.4115 - val_accuracy: 0.8305\n",
      "Epoch 443/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3057 - accuracy: 0.8971 - val_loss: 0.4113 - val_accuracy: 0.8305\n",
      "Epoch 444/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3054 - accuracy: 0.8971 - val_loss: 0.4111 - val_accuracy: 0.8305\n",
      "Epoch 445/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3052 - accuracy: 0.8971 - val_loss: 0.4109 - val_accuracy: 0.8305\n",
      "Epoch 446/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3049 - accuracy: 0.8971 - val_loss: 0.4107 - val_accuracy: 0.8305\n",
      "Epoch 447/4000\n",
      "136/136 [==============================] - 0s 95us/step - loss: 0.3047 - accuracy: 0.8971 - val_loss: 0.4106 - val_accuracy: 0.8305\n",
      "Epoch 448/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3044 - accuracy: 0.8971 - val_loss: 0.4104 - val_accuracy: 0.8305\n",
      "Epoch 449/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.3042 - accuracy: 0.8971 - val_loss: 0.4102 - val_accuracy: 0.8305\n",
      "Epoch 450/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3039 - accuracy: 0.8971 - val_loss: 0.4100 - val_accuracy: 0.8305\n",
      "Epoch 451/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3037 - accuracy: 0.8971 - val_loss: 0.4098 - val_accuracy: 0.8305\n",
      "Epoch 452/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3034 - accuracy: 0.8971 - val_loss: 0.4096 - val_accuracy: 0.8305\n",
      "Epoch 453/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3032 - accuracy: 0.8971 - val_loss: 0.4094 - val_accuracy: 0.8305\n",
      "Epoch 454/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.3030 - accuracy: 0.8971 - val_loss: 0.4092 - val_accuracy: 0.8305\n",
      "Epoch 455/4000\n",
      "136/136 [==============================] - 0s 88us/step - loss: 0.3027 - accuracy: 0.8971 - val_loss: 0.4090 - val_accuracy: 0.8305\n",
      "Epoch 456/4000\n",
      "136/136 [==============================] - 0s 81us/step - loss: 0.3025 - accuracy: 0.8971 - val_loss: 0.4088 - val_accuracy: 0.8305\n",
      "Epoch 457/4000\n",
      "136/136 [==============================] - 0s 88us/step - loss: 0.3022 - accuracy: 0.8971 - val_loss: 0.4086 - val_accuracy: 0.8305\n",
      "Epoch 458/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.3020 - accuracy: 0.8971 - val_loss: 0.4084 - val_accuracy: 0.8305\n",
      "Epoch 459/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.3018 - accuracy: 0.8971 - val_loss: 0.4082 - val_accuracy: 0.8305\n",
      "Epoch 460/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3015 - accuracy: 0.8971 - val_loss: 0.4080 - val_accuracy: 0.8305\n",
      "Epoch 461/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3013 - accuracy: 0.8971 - val_loss: 0.4078 - val_accuracy: 0.8305\n",
      "Epoch 462/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3010 - accuracy: 0.8971 - val_loss: 0.4076 - val_accuracy: 0.8305\n",
      "Epoch 463/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.3008 - accuracy: 0.8971 - val_loss: 0.4074 - val_accuracy: 0.8305\n",
      "Epoch 464/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.3006 - accuracy: 0.8971 - val_loss: 0.4072 - val_accuracy: 0.8305\n",
      "Epoch 465/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.3003 - accuracy: 0.8971 - val_loss: 0.4071 - val_accuracy: 0.8305\n",
      "Epoch 466/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.3001 - accuracy: 0.8971 - val_loss: 0.4069 - val_accuracy: 0.8305\n",
      "Epoch 467/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2999 - accuracy: 0.9044 - val_loss: 0.4067 - val_accuracy: 0.8305\n",
      "Epoch 468/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2997 - accuracy: 0.9044 - val_loss: 0.4065 - val_accuracy: 0.8305\n",
      "Epoch 469/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2994 - accuracy: 0.9044 - val_loss: 0.4063 - val_accuracy: 0.8305\n",
      "Epoch 470/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2992 - accuracy: 0.9044 - val_loss: 0.4062 - val_accuracy: 0.8305\n",
      "Epoch 471/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2990 - accuracy: 0.9044 - val_loss: 0.4060 - val_accuracy: 0.8305\n",
      "Epoch 472/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2988 - accuracy: 0.9044 - val_loss: 0.4058 - val_accuracy: 0.8305\n",
      "Epoch 473/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2985 - accuracy: 0.9044 - val_loss: 0.4057 - val_accuracy: 0.8305\n",
      "Epoch 474/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2983 - accuracy: 0.9044 - val_loss: 0.4055 - val_accuracy: 0.8305\n",
      "Epoch 475/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2981 - accuracy: 0.9044 - val_loss: 0.4054 - val_accuracy: 0.8305\n",
      "Epoch 476/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2979 - accuracy: 0.9044 - val_loss: 0.4052 - val_accuracy: 0.8305\n",
      "Epoch 477/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2977 - accuracy: 0.9044 - val_loss: 0.4050 - val_accuracy: 0.8305\n",
      "Epoch 478/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2975 - accuracy: 0.9044 - val_loss: 0.4049 - val_accuracy: 0.8305\n",
      "Epoch 479/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2972 - accuracy: 0.9044 - val_loss: 0.4047 - val_accuracy: 0.8305\n",
      "Epoch 480/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2970 - accuracy: 0.9044 - val_loss: 0.4046 - val_accuracy: 0.8305\n",
      "Epoch 481/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2968 - accuracy: 0.9044 - val_loss: 0.4044 - val_accuracy: 0.8305\n",
      "Epoch 482/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2966 - accuracy: 0.9044 - val_loss: 0.4043 - val_accuracy: 0.8305\n",
      "Epoch 483/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2964 - accuracy: 0.9044 - val_loss: 0.4041 - val_accuracy: 0.8305\n",
      "Epoch 484/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2962 - accuracy: 0.9044 - val_loss: 0.4039 - val_accuracy: 0.8305\n",
      "Epoch 485/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2959 - accuracy: 0.9044 - val_loss: 0.4038 - val_accuracy: 0.8305\n",
      "Epoch 486/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2957 - accuracy: 0.9044 - val_loss: 0.4036 - val_accuracy: 0.8305\n",
      "Epoch 487/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2955 - accuracy: 0.9044 - val_loss: 0.4035 - val_accuracy: 0.8305\n",
      "Epoch 488/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2953 - accuracy: 0.9044 - val_loss: 0.4033 - val_accuracy: 0.8305\n",
      "Epoch 489/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2951 - accuracy: 0.9044 - val_loss: 0.4032 - val_accuracy: 0.8305\n",
      "Epoch 490/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2949 - accuracy: 0.9044 - val_loss: 0.4030 - val_accuracy: 0.8305\n",
      "Epoch 491/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2947 - accuracy: 0.9044 - val_loss: 0.4029 - val_accuracy: 0.8305\n",
      "Epoch 492/4000\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.2903 - accuracy: 0.90 - 0s 52us/step - loss: 0.2945 - accuracy: 0.9044 - val_loss: 0.4027 - val_accuracy: 0.8305\n",
      "Epoch 493/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2943 - accuracy: 0.9044 - val_loss: 0.4026 - val_accuracy: 0.8305\n",
      "Epoch 494/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2941 - accuracy: 0.9044 - val_loss: 0.4024 - val_accuracy: 0.8305\n",
      "Epoch 495/4000\n",
      "136/136 [==============================] - 0s 73us/step - loss: 0.2939 - accuracy: 0.9044 - val_loss: 0.4023 - val_accuracy: 0.8305\n",
      "Epoch 496/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2937 - accuracy: 0.9044 - val_loss: 0.4021 - val_accuracy: 0.8305\n",
      "Epoch 497/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2934 - accuracy: 0.9044 - val_loss: 0.4020 - val_accuracy: 0.8305\n",
      "Epoch 498/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2932 - accuracy: 0.9044 - val_loss: 0.4018 - val_accuracy: 0.8305\n",
      "Epoch 499/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2930 - accuracy: 0.9044 - val_loss: 0.4017 - val_accuracy: 0.8305\n",
      "Epoch 500/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2928 - accuracy: 0.9044 - val_loss: 0.4016 - val_accuracy: 0.8305\n",
      "Epoch 501/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2926 - accuracy: 0.9044 - val_loss: 0.4014 - val_accuracy: 0.8305\n",
      "Epoch 502/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2924 - accuracy: 0.9044 - val_loss: 0.4013 - val_accuracy: 0.8305\n",
      "Epoch 503/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2922 - accuracy: 0.9044 - val_loss: 0.4011 - val_accuracy: 0.8305\n",
      "Epoch 504/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2920 - accuracy: 0.9044 - val_loss: 0.4010 - val_accuracy: 0.8305\n",
      "Epoch 505/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2918 - accuracy: 0.9044 - val_loss: 0.4008 - val_accuracy: 0.8305\n",
      "Epoch 506/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2916 - accuracy: 0.9044 - val_loss: 0.4007 - val_accuracy: 0.8305\n",
      "Epoch 507/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2914 - accuracy: 0.9044 - val_loss: 0.4006 - val_accuracy: 0.8305\n",
      "Epoch 508/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2912 - accuracy: 0.9044 - val_loss: 0.4004 - val_accuracy: 0.8305\n",
      "Epoch 509/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2911 - accuracy: 0.9044 - val_loss: 0.4003 - val_accuracy: 0.8305\n",
      "Epoch 510/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2909 - accuracy: 0.9044 - val_loss: 0.4002 - val_accuracy: 0.8305\n",
      "Epoch 511/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2907 - accuracy: 0.9044 - val_loss: 0.4000 - val_accuracy: 0.8305\n",
      "Epoch 512/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2905 - accuracy: 0.9044 - val_loss: 0.3999 - val_accuracy: 0.8305\n",
      "Epoch 513/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2903 - accuracy: 0.9044 - val_loss: 0.3998 - val_accuracy: 0.8305\n",
      "Epoch 514/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2901 - accuracy: 0.9044 - val_loss: 0.3996 - val_accuracy: 0.8305\n",
      "Epoch 515/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2899 - accuracy: 0.9044 - val_loss: 0.3995 - val_accuracy: 0.8305\n",
      "Epoch 516/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2897 - accuracy: 0.9044 - val_loss: 0.3994 - val_accuracy: 0.8305\n",
      "Epoch 517/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2895 - accuracy: 0.9044 - val_loss: 0.3993 - val_accuracy: 0.8305\n",
      "Epoch 518/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2893 - accuracy: 0.9044 - val_loss: 0.3991 - val_accuracy: 0.8305\n",
      "Epoch 519/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2891 - accuracy: 0.9044 - val_loss: 0.3990 - val_accuracy: 0.8305\n",
      "Epoch 520/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2889 - accuracy: 0.9044 - val_loss: 0.3989 - val_accuracy: 0.8305\n",
      "Epoch 521/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2887 - accuracy: 0.9044 - val_loss: 0.3987 - val_accuracy: 0.8305\n",
      "Epoch 522/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2886 - accuracy: 0.9044 - val_loss: 0.3986 - val_accuracy: 0.8305\n",
      "Epoch 523/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2884 - accuracy: 0.9044 - val_loss: 0.3985 - val_accuracy: 0.8305\n",
      "Epoch 524/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2882 - accuracy: 0.9044 - val_loss: 0.3983 - val_accuracy: 0.8305\n",
      "Epoch 525/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2880 - accuracy: 0.8971 - val_loss: 0.3982 - val_accuracy: 0.8305\n",
      "Epoch 526/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2877 - accuracy: 0.8971 - val_loss: 0.3981 - val_accuracy: 0.8305\n",
      "Epoch 527/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2875 - accuracy: 0.8971 - val_loss: 0.3979 - val_accuracy: 0.8305\n",
      "Epoch 528/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2873 - accuracy: 0.8971 - val_loss: 0.3978 - val_accuracy: 0.8305\n",
      "Epoch 529/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2871 - accuracy: 0.8971 - val_loss: 0.3977 - val_accuracy: 0.8305\n",
      "Epoch 530/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2869 - accuracy: 0.8971 - val_loss: 0.3975 - val_accuracy: 0.8305\n",
      "Epoch 531/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2867 - accuracy: 0.8971 - val_loss: 0.3974 - val_accuracy: 0.8305\n",
      "Epoch 532/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2865 - accuracy: 0.8971 - val_loss: 0.3973 - val_accuracy: 0.8305\n",
      "Epoch 533/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2863 - accuracy: 0.8971 - val_loss: 0.3971 - val_accuracy: 0.8305\n",
      "Epoch 534/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2861 - accuracy: 0.8971 - val_loss: 0.3970 - val_accuracy: 0.8305\n",
      "Epoch 535/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2859 - accuracy: 0.8971 - val_loss: 0.3969 - val_accuracy: 0.8305\n",
      "Epoch 536/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2857 - accuracy: 0.8971 - val_loss: 0.3968 - val_accuracy: 0.8305\n",
      "Epoch 537/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2855 - accuracy: 0.8971 - val_loss: 0.3966 - val_accuracy: 0.8305\n",
      "Epoch 538/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2853 - accuracy: 0.8971 - val_loss: 0.3965 - val_accuracy: 0.8305\n",
      "Epoch 539/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2851 - accuracy: 0.8971 - val_loss: 0.3964 - val_accuracy: 0.8305\n",
      "Epoch 540/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2849 - accuracy: 0.8971 - val_loss: 0.3963 - val_accuracy: 0.8305\n",
      "Epoch 541/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2847 - accuracy: 0.8971 - val_loss: 0.3961 - val_accuracy: 0.8305\n",
      "Epoch 542/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2845 - accuracy: 0.8971 - val_loss: 0.3960 - val_accuracy: 0.8305\n",
      "Epoch 543/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2843 - accuracy: 0.8971 - val_loss: 0.3959 - val_accuracy: 0.8305\n",
      "Epoch 544/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2841 - accuracy: 0.8971 - val_loss: 0.3958 - val_accuracy: 0.8305\n",
      "Epoch 545/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2839 - accuracy: 0.8971 - val_loss: 0.3957 - val_accuracy: 0.8305\n",
      "Epoch 546/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2837 - accuracy: 0.8971 - val_loss: 0.3955 - val_accuracy: 0.8305\n",
      "Epoch 547/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2835 - accuracy: 0.8971 - val_loss: 0.3954 - val_accuracy: 0.8305\n",
      "Epoch 548/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2833 - accuracy: 0.8971 - val_loss: 0.3953 - val_accuracy: 0.8305\n",
      "Epoch 549/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2832 - accuracy: 0.8971 - val_loss: 0.3952 - val_accuracy: 0.8305\n",
      "Epoch 550/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2830 - accuracy: 0.8971 - val_loss: 0.3951 - val_accuracy: 0.8305\n",
      "Epoch 551/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2828 - accuracy: 0.8971 - val_loss: 0.3950 - val_accuracy: 0.8305\n",
      "Epoch 552/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2826 - accuracy: 0.8971 - val_loss: 0.3949 - val_accuracy: 0.8305\n",
      "Epoch 553/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2824 - accuracy: 0.8971 - val_loss: 0.3948 - val_accuracy: 0.8305\n",
      "Epoch 554/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2822 - accuracy: 0.8971 - val_loss: 0.3946 - val_accuracy: 0.8305\n",
      "Epoch 555/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2820 - accuracy: 0.8971 - val_loss: 0.3945 - val_accuracy: 0.8305\n",
      "Epoch 556/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2818 - accuracy: 0.8971 - val_loss: 0.3944 - val_accuracy: 0.8305\n",
      "Epoch 557/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2817 - accuracy: 0.8971 - val_loss: 0.3943 - val_accuracy: 0.8305\n",
      "Epoch 558/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2815 - accuracy: 0.8971 - val_loss: 0.3942 - val_accuracy: 0.8305\n",
      "Epoch 559/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2813 - accuracy: 0.8971 - val_loss: 0.3941 - val_accuracy: 0.8305\n",
      "Epoch 560/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2811 - accuracy: 0.8971 - val_loss: 0.3940 - val_accuracy: 0.8305\n",
      "Epoch 561/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2809 - accuracy: 0.8971 - val_loss: 0.3939 - val_accuracy: 0.8305\n",
      "Epoch 562/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2807 - accuracy: 0.8971 - val_loss: 0.3938 - val_accuracy: 0.8305\n",
      "Epoch 563/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2806 - accuracy: 0.8971 - val_loss: 0.3937 - val_accuracy: 0.8305\n",
      "Epoch 564/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2804 - accuracy: 0.8971 - val_loss: 0.3936 - val_accuracy: 0.8305\n",
      "Epoch 565/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2802 - accuracy: 0.8971 - val_loss: 0.3935 - val_accuracy: 0.8305\n",
      "Epoch 566/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2800 - accuracy: 0.8971 - val_loss: 0.3934 - val_accuracy: 0.8305\n",
      "Epoch 567/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2798 - accuracy: 0.8971 - val_loss: 0.3933 - val_accuracy: 0.8305\n",
      "Epoch 568/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2797 - accuracy: 0.8971 - val_loss: 0.3932 - val_accuracy: 0.8305\n",
      "Epoch 569/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2795 - accuracy: 0.8971 - val_loss: 0.3931 - val_accuracy: 0.8305\n",
      "Epoch 570/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2793 - accuracy: 0.8971 - val_loss: 0.3930 - val_accuracy: 0.8305\n",
      "Epoch 571/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2791 - accuracy: 0.8971 - val_loss: 0.3929 - val_accuracy: 0.8305\n",
      "Epoch 572/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2790 - accuracy: 0.8971 - val_loss: 0.3928 - val_accuracy: 0.8305\n",
      "Epoch 573/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2788 - accuracy: 0.8971 - val_loss: 0.3927 - val_accuracy: 0.8305\n",
      "Epoch 574/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2786 - accuracy: 0.8971 - val_loss: 0.3927 - val_accuracy: 0.8305\n",
      "Epoch 575/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2784 - accuracy: 0.8971 - val_loss: 0.3926 - val_accuracy: 0.8305\n",
      "Epoch 576/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2783 - accuracy: 0.8971 - val_loss: 0.3925 - val_accuracy: 0.8305\n",
      "Epoch 577/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2781 - accuracy: 0.8971 - val_loss: 0.3924 - val_accuracy: 0.8305\n",
      "Epoch 578/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2779 - accuracy: 0.8971 - val_loss: 0.3923 - val_accuracy: 0.8305\n",
      "Epoch 579/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2777 - accuracy: 0.8971 - val_loss: 0.3922 - val_accuracy: 0.8305\n",
      "Epoch 580/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2776 - accuracy: 0.8971 - val_loss: 0.3921 - val_accuracy: 0.8305\n",
      "Epoch 581/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2774 - accuracy: 0.8971 - val_loss: 0.3920 - val_accuracy: 0.8305\n",
      "Epoch 582/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2772 - accuracy: 0.8971 - val_loss: 0.3919 - val_accuracy: 0.8305\n",
      "Epoch 583/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2770 - accuracy: 0.8971 - val_loss: 0.3918 - val_accuracy: 0.8305\n",
      "Epoch 584/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2769 - accuracy: 0.8971 - val_loss: 0.3917 - val_accuracy: 0.8305\n",
      "Epoch 585/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2767 - accuracy: 0.8971 - val_loss: 0.3917 - val_accuracy: 0.8305\n",
      "Epoch 586/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2765 - accuracy: 0.8971 - val_loss: 0.3916 - val_accuracy: 0.8305\n",
      "Epoch 587/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2764 - accuracy: 0.8971 - val_loss: 0.3915 - val_accuracy: 0.8305\n",
      "Epoch 588/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2762 - accuracy: 0.8971 - val_loss: 0.3914 - val_accuracy: 0.8305\n",
      "Epoch 589/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2760 - accuracy: 0.8971 - val_loss: 0.3913 - val_accuracy: 0.8305\n",
      "Epoch 590/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2759 - accuracy: 0.8971 - val_loss: 0.3912 - val_accuracy: 0.8305\n",
      "Epoch 591/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2757 - accuracy: 0.8971 - val_loss: 0.3911 - val_accuracy: 0.8305\n",
      "Epoch 592/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2755 - accuracy: 0.8971 - val_loss: 0.3911 - val_accuracy: 0.8305\n",
      "Epoch 593/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2753 - accuracy: 0.9044 - val_loss: 0.3910 - val_accuracy: 0.8305\n",
      "Epoch 594/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2752 - accuracy: 0.9044 - val_loss: 0.3909 - val_accuracy: 0.8305\n",
      "Epoch 595/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2750 - accuracy: 0.9044 - val_loss: 0.3908 - val_accuracy: 0.8305\n",
      "Epoch 596/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2748 - accuracy: 0.9044 - val_loss: 0.3907 - val_accuracy: 0.8305\n",
      "Epoch 597/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2747 - accuracy: 0.9044 - val_loss: 0.3907 - val_accuracy: 0.8305\n",
      "Epoch 598/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2745 - accuracy: 0.9044 - val_loss: 0.3906 - val_accuracy: 0.8305\n",
      "Epoch 599/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2744 - accuracy: 0.9044 - val_loss: 0.3905 - val_accuracy: 0.8305\n",
      "Epoch 600/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2742 - accuracy: 0.9044 - val_loss: 0.3904 - val_accuracy: 0.8305\n",
      "Epoch 601/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2740 - accuracy: 0.9044 - val_loss: 0.3903 - val_accuracy: 0.8305\n",
      "Epoch 602/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2739 - accuracy: 0.9044 - val_loss: 0.3903 - val_accuracy: 0.8305\n",
      "Epoch 603/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2737 - accuracy: 0.9044 - val_loss: 0.3902 - val_accuracy: 0.8305\n",
      "Epoch 604/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2735 - accuracy: 0.9044 - val_loss: 0.3901 - val_accuracy: 0.8305\n",
      "Epoch 605/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2734 - accuracy: 0.9044 - val_loss: 0.3900 - val_accuracy: 0.8305\n",
      "Epoch 606/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2732 - accuracy: 0.9044 - val_loss: 0.3900 - val_accuracy: 0.8305\n",
      "Epoch 607/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2731 - accuracy: 0.9044 - val_loss: 0.3899 - val_accuracy: 0.8305\n",
      "Epoch 608/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2729 - accuracy: 0.9044 - val_loss: 0.3898 - val_accuracy: 0.8305\n",
      "Epoch 609/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2727 - accuracy: 0.9044 - val_loss: 0.3897 - val_accuracy: 0.8305\n",
      "Epoch 610/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2726 - accuracy: 0.9044 - val_loss: 0.3897 - val_accuracy: 0.8305\n",
      "Epoch 611/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2724 - accuracy: 0.9044 - val_loss: 0.3896 - val_accuracy: 0.8305\n",
      "Epoch 612/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2723 - accuracy: 0.9044 - val_loss: 0.3895 - val_accuracy: 0.8305\n",
      "Epoch 613/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2721 - accuracy: 0.9044 - val_loss: 0.3894 - val_accuracy: 0.8305\n",
      "Epoch 614/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2719 - accuracy: 0.9044 - val_loss: 0.3894 - val_accuracy: 0.8305\n",
      "Epoch 615/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2718 - accuracy: 0.9044 - val_loss: 0.3893 - val_accuracy: 0.8305\n",
      "Epoch 616/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2716 - accuracy: 0.9044 - val_loss: 0.3892 - val_accuracy: 0.8305\n",
      "Epoch 617/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2715 - accuracy: 0.9044 - val_loss: 0.3891 - val_accuracy: 0.8305\n",
      "Epoch 618/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2713 - accuracy: 0.9044 - val_loss: 0.3891 - val_accuracy: 0.8305\n",
      "Epoch 619/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2711 - accuracy: 0.9044 - val_loss: 0.3890 - val_accuracy: 0.8305\n",
      "Epoch 620/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2710 - accuracy: 0.9044 - val_loss: 0.3889 - val_accuracy: 0.8305\n",
      "Epoch 621/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2708 - accuracy: 0.9044 - val_loss: 0.3889 - val_accuracy: 0.8305\n",
      "Epoch 622/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2707 - accuracy: 0.9044 - val_loss: 0.3888 - val_accuracy: 0.8305\n",
      "Epoch 623/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2705 - accuracy: 0.9044 - val_loss: 0.3887 - val_accuracy: 0.8305\n",
      "Epoch 624/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2704 - accuracy: 0.9044 - val_loss: 0.3887 - val_accuracy: 0.8305\n",
      "Epoch 625/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2702 - accuracy: 0.9044 - val_loss: 0.3886 - val_accuracy: 0.8305\n",
      "Epoch 626/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2701 - accuracy: 0.9044 - val_loss: 0.3885 - val_accuracy: 0.8305\n",
      "Epoch 627/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2699 - accuracy: 0.9044 - val_loss: 0.3884 - val_accuracy: 0.8305\n",
      "Epoch 628/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2697 - accuracy: 0.9044 - val_loss: 0.3884 - val_accuracy: 0.8305\n",
      "Epoch 629/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2696 - accuracy: 0.9044 - val_loss: 0.3883 - val_accuracy: 0.8305\n",
      "Epoch 630/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2694 - accuracy: 0.9044 - val_loss: 0.3882 - val_accuracy: 0.8305\n",
      "Epoch 631/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2693 - accuracy: 0.9044 - val_loss: 0.3882 - val_accuracy: 0.8305\n",
      "Epoch 632/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2691 - accuracy: 0.9044 - val_loss: 0.3881 - val_accuracy: 0.8305\n",
      "Epoch 633/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2690 - accuracy: 0.9044 - val_loss: 0.3880 - val_accuracy: 0.8305\n",
      "Epoch 634/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2688 - accuracy: 0.9044 - val_loss: 0.3880 - val_accuracy: 0.8305\n",
      "Epoch 635/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2687 - accuracy: 0.9044 - val_loss: 0.3879 - val_accuracy: 0.8305\n",
      "Epoch 636/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2685 - accuracy: 0.9044 - val_loss: 0.3878 - val_accuracy: 0.8305\n",
      "Epoch 637/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2684 - accuracy: 0.9044 - val_loss: 0.3878 - val_accuracy: 0.8305\n",
      "Epoch 638/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2682 - accuracy: 0.9044 - val_loss: 0.3877 - val_accuracy: 0.8305\n",
      "Epoch 639/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2681 - accuracy: 0.9044 - val_loss: 0.3876 - val_accuracy: 0.8305\n",
      "Epoch 640/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2679 - accuracy: 0.9044 - val_loss: 0.3876 - val_accuracy: 0.8305\n",
      "Epoch 641/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2677 - accuracy: 0.9044 - val_loss: 0.3875 - val_accuracy: 0.8305\n",
      "Epoch 642/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2676 - accuracy: 0.9044 - val_loss: 0.3875 - val_accuracy: 0.8305\n",
      "Epoch 643/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2674 - accuracy: 0.9044 - val_loss: 0.3874 - val_accuracy: 0.8305\n",
      "Epoch 644/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2673 - accuracy: 0.9044 - val_loss: 0.3873 - val_accuracy: 0.8305\n",
      "Epoch 645/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2671 - accuracy: 0.9044 - val_loss: 0.3873 - val_accuracy: 0.8305\n",
      "Epoch 646/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2670 - accuracy: 0.9044 - val_loss: 0.3872 - val_accuracy: 0.8305\n",
      "Epoch 647/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2669 - accuracy: 0.9044 - val_loss: 0.3871 - val_accuracy: 0.8305\n",
      "Epoch 648/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2667 - accuracy: 0.9044 - val_loss: 0.3871 - val_accuracy: 0.8305\n",
      "Epoch 649/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2666 - accuracy: 0.9044 - val_loss: 0.3870 - val_accuracy: 0.8305\n",
      "Epoch 650/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2664 - accuracy: 0.9044 - val_loss: 0.3870 - val_accuracy: 0.8305\n",
      "Epoch 651/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2663 - accuracy: 0.9044 - val_loss: 0.3869 - val_accuracy: 0.8305\n",
      "Epoch 652/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2661 - accuracy: 0.9044 - val_loss: 0.3868 - val_accuracy: 0.8305\n",
      "Epoch 653/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2660 - accuracy: 0.9044 - val_loss: 0.3868 - val_accuracy: 0.8305\n",
      "Epoch 654/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2658 - accuracy: 0.9044 - val_loss: 0.3867 - val_accuracy: 0.8305\n",
      "Epoch 655/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2657 - accuracy: 0.9044 - val_loss: 0.3867 - val_accuracy: 0.8305\n",
      "Epoch 656/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2655 - accuracy: 0.9044 - val_loss: 0.3866 - val_accuracy: 0.8305\n",
      "Epoch 657/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2654 - accuracy: 0.9044 - val_loss: 0.3866 - val_accuracy: 0.8305\n",
      "Epoch 658/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2652 - accuracy: 0.9044 - val_loss: 0.3865 - val_accuracy: 0.8305\n",
      "Epoch 659/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2651 - accuracy: 0.9044 - val_loss: 0.3865 - val_accuracy: 0.8305\n",
      "Epoch 660/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2649 - accuracy: 0.9044 - val_loss: 0.3864 - val_accuracy: 0.8305\n",
      "Epoch 661/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2648 - accuracy: 0.9044 - val_loss: 0.3864 - val_accuracy: 0.8305\n",
      "Epoch 662/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2647 - accuracy: 0.9044 - val_loss: 0.3863 - val_accuracy: 0.8305\n",
      "Epoch 663/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2645 - accuracy: 0.9044 - val_loss: 0.3863 - val_accuracy: 0.8305\n",
      "Epoch 664/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2644 - accuracy: 0.9044 - val_loss: 0.3862 - val_accuracy: 0.8305\n",
      "Epoch 665/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2642 - accuracy: 0.9044 - val_loss: 0.3862 - val_accuracy: 0.8305\n",
      "Epoch 666/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2641 - accuracy: 0.9044 - val_loss: 0.3861 - val_accuracy: 0.8305\n",
      "Epoch 667/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2639 - accuracy: 0.9044 - val_loss: 0.3861 - val_accuracy: 0.8305\n",
      "Epoch 668/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2638 - accuracy: 0.9044 - val_loss: 0.3860 - val_accuracy: 0.8305\n",
      "Epoch 669/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2637 - accuracy: 0.9044 - val_loss: 0.3860 - val_accuracy: 0.8305\n",
      "Epoch 670/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2635 - accuracy: 0.9044 - val_loss: 0.3860 - val_accuracy: 0.8305\n",
      "Epoch 671/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2634 - accuracy: 0.9044 - val_loss: 0.3859 - val_accuracy: 0.8305\n",
      "Epoch 672/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2632 - accuracy: 0.9044 - val_loss: 0.3859 - val_accuracy: 0.8305\n",
      "Epoch 673/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2631 - accuracy: 0.9044 - val_loss: 0.3858 - val_accuracy: 0.8305\n",
      "Epoch 674/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2630 - accuracy: 0.9044 - val_loss: 0.3858 - val_accuracy: 0.8305\n",
      "Epoch 675/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2628 - accuracy: 0.9044 - val_loss: 0.3857 - val_accuracy: 0.8305\n",
      "Epoch 676/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2627 - accuracy: 0.9044 - val_loss: 0.3857 - val_accuracy: 0.8305\n",
      "Epoch 677/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2625 - accuracy: 0.9044 - val_loss: 0.3856 - val_accuracy: 0.8305\n",
      "Epoch 678/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2624 - accuracy: 0.9044 - val_loss: 0.3856 - val_accuracy: 0.8305\n",
      "Epoch 679/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2623 - accuracy: 0.9044 - val_loss: 0.3856 - val_accuracy: 0.8305\n",
      "Epoch 680/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2621 - accuracy: 0.9044 - val_loss: 0.3855 - val_accuracy: 0.8305\n",
      "Epoch 681/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2620 - accuracy: 0.9044 - val_loss: 0.3855 - val_accuracy: 0.8305\n",
      "Epoch 682/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2619 - accuracy: 0.9044 - val_loss: 0.3854 - val_accuracy: 0.8305\n",
      "Epoch 683/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2617 - accuracy: 0.9044 - val_loss: 0.3854 - val_accuracy: 0.8305\n",
      "Epoch 684/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2616 - accuracy: 0.9044 - val_loss: 0.3854 - val_accuracy: 0.8305\n",
      "Epoch 685/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2615 - accuracy: 0.9044 - val_loss: 0.3853 - val_accuracy: 0.8305\n",
      "Epoch 686/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2613 - accuracy: 0.9044 - val_loss: 0.3853 - val_accuracy: 0.8305\n",
      "Epoch 687/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2612 - accuracy: 0.9044 - val_loss: 0.3852 - val_accuracy: 0.8305\n",
      "Epoch 688/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2610 - accuracy: 0.9044 - val_loss: 0.3852 - val_accuracy: 0.8305\n",
      "Epoch 689/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2609 - accuracy: 0.9044 - val_loss: 0.3852 - val_accuracy: 0.8305\n",
      "Epoch 690/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2608 - accuracy: 0.9044 - val_loss: 0.3851 - val_accuracy: 0.8305\n",
      "Epoch 691/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2606 - accuracy: 0.9044 - val_loss: 0.3851 - val_accuracy: 0.8305\n",
      "Epoch 692/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2605 - accuracy: 0.9044 - val_loss: 0.3851 - val_accuracy: 0.8305\n",
      "Epoch 693/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2604 - accuracy: 0.9044 - val_loss: 0.3850 - val_accuracy: 0.8305\n",
      "Epoch 694/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2602 - accuracy: 0.9044 - val_loss: 0.3850 - val_accuracy: 0.8305\n",
      "Epoch 695/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2601 - accuracy: 0.9044 - val_loss: 0.3849 - val_accuracy: 0.8305\n",
      "Epoch 696/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2600 - accuracy: 0.9044 - val_loss: 0.3849 - val_accuracy: 0.8305\n",
      "Epoch 697/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2598 - accuracy: 0.9044 - val_loss: 0.3849 - val_accuracy: 0.8305\n",
      "Epoch 698/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2597 - accuracy: 0.9044 - val_loss: 0.3848 - val_accuracy: 0.8305\n",
      "Epoch 699/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2596 - accuracy: 0.9044 - val_loss: 0.3848 - val_accuracy: 0.8305\n",
      "Epoch 700/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2594 - accuracy: 0.9044 - val_loss: 0.3848 - val_accuracy: 0.8305\n",
      "Epoch 701/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2593 - accuracy: 0.9044 - val_loss: 0.3847 - val_accuracy: 0.8305\n",
      "Epoch 702/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2592 - accuracy: 0.9044 - val_loss: 0.3847 - val_accuracy: 0.8305\n",
      "Epoch 703/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2590 - accuracy: 0.9044 - val_loss: 0.3846 - val_accuracy: 0.8305\n",
      "Epoch 704/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2589 - accuracy: 0.9044 - val_loss: 0.3846 - val_accuracy: 0.8305\n",
      "Epoch 705/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2588 - accuracy: 0.9044 - val_loss: 0.3846 - val_accuracy: 0.8305\n",
      "Epoch 706/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2587 - accuracy: 0.9044 - val_loss: 0.3845 - val_accuracy: 0.8305\n",
      "Epoch 707/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2585 - accuracy: 0.9044 - val_loss: 0.3845 - val_accuracy: 0.8305\n",
      "Epoch 708/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2584 - accuracy: 0.9044 - val_loss: 0.3845 - val_accuracy: 0.8305\n",
      "Epoch 709/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2583 - accuracy: 0.9044 - val_loss: 0.3844 - val_accuracy: 0.8475\n",
      "Epoch 710/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2581 - accuracy: 0.9044 - val_loss: 0.3844 - val_accuracy: 0.8475\n",
      "Epoch 711/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2580 - accuracy: 0.9044 - val_loss: 0.3844 - val_accuracy: 0.8475\n",
      "Epoch 712/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2579 - accuracy: 0.9044 - val_loss: 0.3843 - val_accuracy: 0.8475\n",
      "Epoch 713/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2577 - accuracy: 0.9044 - val_loss: 0.3843 - val_accuracy: 0.8475\n",
      "Epoch 714/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2576 - accuracy: 0.9044 - val_loss: 0.3843 - val_accuracy: 0.8475\n",
      "Epoch 715/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2575 - accuracy: 0.9044 - val_loss: 0.3842 - val_accuracy: 0.8475\n",
      "Epoch 716/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2574 - accuracy: 0.9044 - val_loss: 0.3842 - val_accuracy: 0.8475\n",
      "Epoch 717/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2572 - accuracy: 0.9044 - val_loss: 0.3842 - val_accuracy: 0.8475\n",
      "Epoch 718/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2571 - accuracy: 0.9044 - val_loss: 0.3841 - val_accuracy: 0.8475\n",
      "Epoch 719/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2570 - accuracy: 0.9044 - val_loss: 0.3841 - val_accuracy: 0.8475\n",
      "Epoch 720/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2568 - accuracy: 0.9044 - val_loss: 0.3841 - val_accuracy: 0.8475\n",
      "Epoch 721/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2567 - accuracy: 0.9044 - val_loss: 0.3841 - val_accuracy: 0.8475\n",
      "Epoch 722/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2566 - accuracy: 0.9044 - val_loss: 0.3840 - val_accuracy: 0.8475\n",
      "Epoch 723/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2565 - accuracy: 0.9044 - val_loss: 0.3840 - val_accuracy: 0.8475\n",
      "Epoch 724/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2563 - accuracy: 0.9044 - val_loss: 0.3840 - val_accuracy: 0.8475\n",
      "Epoch 725/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2562 - accuracy: 0.9044 - val_loss: 0.3839 - val_accuracy: 0.8475\n",
      "Epoch 726/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2561 - accuracy: 0.9044 - val_loss: 0.3839 - val_accuracy: 0.8475\n",
      "Epoch 727/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2560 - accuracy: 0.9044 - val_loss: 0.3839 - val_accuracy: 0.8475\n",
      "Epoch 728/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2558 - accuracy: 0.9044 - val_loss: 0.3838 - val_accuracy: 0.8475\n",
      "Epoch 729/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2557 - accuracy: 0.9044 - val_loss: 0.3838 - val_accuracy: 0.8475\n",
      "Epoch 730/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2556 - accuracy: 0.9044 - val_loss: 0.3838 - val_accuracy: 0.8475\n",
      "Epoch 731/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2555 - accuracy: 0.9044 - val_loss: 0.3838 - val_accuracy: 0.8475\n",
      "Epoch 732/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2553 - accuracy: 0.9044 - val_loss: 0.3837 - val_accuracy: 0.8475\n",
      "Epoch 733/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2552 - accuracy: 0.9044 - val_loss: 0.3837 - val_accuracy: 0.8475\n",
      "Epoch 734/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2551 - accuracy: 0.9044 - val_loss: 0.3837 - val_accuracy: 0.8475\n",
      "Epoch 735/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2550 - accuracy: 0.9044 - val_loss: 0.3837 - val_accuracy: 0.8475\n",
      "Epoch 736/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2548 - accuracy: 0.9044 - val_loss: 0.3836 - val_accuracy: 0.8475\n",
      "Epoch 737/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2547 - accuracy: 0.9044 - val_loss: 0.3836 - val_accuracy: 0.8475\n",
      "Epoch 738/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2546 - accuracy: 0.9044 - val_loss: 0.3836 - val_accuracy: 0.8475\n",
      "Epoch 739/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2545 - accuracy: 0.9044 - val_loss: 0.3835 - val_accuracy: 0.8475\n",
      "Epoch 740/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2544 - accuracy: 0.9044 - val_loss: 0.3835 - val_accuracy: 0.8475\n",
      "Epoch 741/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2542 - accuracy: 0.9044 - val_loss: 0.3835 - val_accuracy: 0.8475\n",
      "Epoch 742/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2541 - accuracy: 0.9044 - val_loss: 0.3835 - val_accuracy: 0.8475\n",
      "Epoch 743/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2540 - accuracy: 0.9044 - val_loss: 0.3834 - val_accuracy: 0.8475\n",
      "Epoch 744/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2539 - accuracy: 0.9044 - val_loss: 0.3834 - val_accuracy: 0.8475\n",
      "Epoch 745/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2538 - accuracy: 0.9044 - val_loss: 0.3834 - val_accuracy: 0.8475\n",
      "Epoch 746/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2536 - accuracy: 0.9044 - val_loss: 0.3834 - val_accuracy: 0.8475\n",
      "Epoch 747/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2535 - accuracy: 0.9044 - val_loss: 0.3834 - val_accuracy: 0.8475\n",
      "Epoch 748/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2534 - accuracy: 0.9044 - val_loss: 0.3833 - val_accuracy: 0.8475\n",
      "Epoch 749/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2533 - accuracy: 0.9044 - val_loss: 0.3833 - val_accuracy: 0.8475\n",
      "Epoch 750/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2532 - accuracy: 0.9044 - val_loss: 0.3833 - val_accuracy: 0.8475\n",
      "Epoch 751/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2530 - accuracy: 0.9044 - val_loss: 0.3833 - val_accuracy: 0.8475\n",
      "Epoch 752/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2529 - accuracy: 0.9044 - val_loss: 0.3833 - val_accuracy: 0.8475\n",
      "Epoch 753/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2528 - accuracy: 0.9044 - val_loss: 0.3832 - val_accuracy: 0.8475\n",
      "Epoch 754/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2527 - accuracy: 0.9044 - val_loss: 0.3832 - val_accuracy: 0.8475\n",
      "Epoch 755/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2526 - accuracy: 0.9044 - val_loss: 0.3832 - val_accuracy: 0.8475\n",
      "Epoch 756/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2525 - accuracy: 0.9044 - val_loss: 0.3832 - val_accuracy: 0.8475\n",
      "Epoch 757/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2523 - accuracy: 0.9044 - val_loss: 0.3832 - val_accuracy: 0.8475\n",
      "Epoch 758/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2522 - accuracy: 0.9044 - val_loss: 0.3832 - val_accuracy: 0.8475\n",
      "Epoch 759/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2521 - accuracy: 0.9044 - val_loss: 0.3831 - val_accuracy: 0.8475\n",
      "Epoch 760/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2520 - accuracy: 0.9044 - val_loss: 0.3831 - val_accuracy: 0.8475\n",
      "Epoch 761/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2519 - accuracy: 0.9044 - val_loss: 0.3831 - val_accuracy: 0.8475\n",
      "Epoch 762/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2518 - accuracy: 0.9044 - val_loss: 0.3831 - val_accuracy: 0.8475\n",
      "Epoch 763/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2516 - accuracy: 0.9044 - val_loss: 0.3831 - val_accuracy: 0.8475\n",
      "Epoch 764/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2515 - accuracy: 0.9044 - val_loss: 0.3831 - val_accuracy: 0.8475\n",
      "Epoch 765/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2514 - accuracy: 0.9044 - val_loss: 0.3830 - val_accuracy: 0.8475\n",
      "Epoch 766/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2513 - accuracy: 0.9044 - val_loss: 0.3830 - val_accuracy: 0.8475\n",
      "Epoch 767/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2512 - accuracy: 0.9044 - val_loss: 0.3830 - val_accuracy: 0.8475\n",
      "Epoch 768/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2511 - accuracy: 0.9044 - val_loss: 0.3830 - val_accuracy: 0.8475\n",
      "Epoch 769/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2510 - accuracy: 0.9044 - val_loss: 0.3830 - val_accuracy: 0.8475\n",
      "Epoch 770/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2508 - accuracy: 0.9044 - val_loss: 0.3830 - val_accuracy: 0.8475\n",
      "Epoch 771/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2507 - accuracy: 0.9044 - val_loss: 0.3830 - val_accuracy: 0.8475\n",
      "Epoch 772/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2506 - accuracy: 0.9044 - val_loss: 0.3829 - val_accuracy: 0.8475\n",
      "Epoch 773/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2505 - accuracy: 0.9044 - val_loss: 0.3829 - val_accuracy: 0.8475\n",
      "Epoch 774/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2504 - accuracy: 0.9044 - val_loss: 0.3829 - val_accuracy: 0.8475\n",
      "Epoch 775/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2503 - accuracy: 0.9044 - val_loss: 0.3829 - val_accuracy: 0.8475\n",
      "Epoch 776/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2502 - accuracy: 0.9044 - val_loss: 0.3829 - val_accuracy: 0.8475\n",
      "Epoch 777/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2500 - accuracy: 0.9044 - val_loss: 0.3829 - val_accuracy: 0.8475\n",
      "Epoch 778/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2499 - accuracy: 0.9044 - val_loss: 0.3829 - val_accuracy: 0.8475\n",
      "Epoch 779/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2498 - accuracy: 0.9044 - val_loss: 0.3829 - val_accuracy: 0.8475\n",
      "Epoch 780/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2497 - accuracy: 0.9044 - val_loss: 0.3829 - val_accuracy: 0.8305\n",
      "Epoch 781/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2496 - accuracy: 0.9044 - val_loss: 0.3828 - val_accuracy: 0.8305\n",
      "Epoch 782/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2495 - accuracy: 0.9044 - val_loss: 0.3828 - val_accuracy: 0.8305\n",
      "Epoch 783/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2494 - accuracy: 0.9044 - val_loss: 0.3828 - val_accuracy: 0.8305\n",
      "Epoch 784/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2493 - accuracy: 0.9044 - val_loss: 0.3828 - val_accuracy: 0.8305\n",
      "Epoch 785/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2492 - accuracy: 0.9044 - val_loss: 0.3828 - val_accuracy: 0.8305\n",
      "Epoch 786/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2490 - accuracy: 0.9044 - val_loss: 0.3828 - val_accuracy: 0.8305\n",
      "Epoch 787/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2489 - accuracy: 0.9044 - val_loss: 0.3828 - val_accuracy: 0.8305\n",
      "Epoch 788/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2488 - accuracy: 0.9044 - val_loss: 0.3828 - val_accuracy: 0.8305\n",
      "Epoch 789/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2487 - accuracy: 0.9044 - val_loss: 0.3828 - val_accuracy: 0.8305\n",
      "Epoch 790/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2486 - accuracy: 0.9118 - val_loss: 0.3828 - val_accuracy: 0.8305\n",
      "Epoch 791/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2485 - accuracy: 0.9118 - val_loss: 0.3828 - val_accuracy: 0.8305\n",
      "Epoch 792/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2484 - accuracy: 0.9118 - val_loss: 0.3828 - val_accuracy: 0.8305\n",
      "Epoch 793/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2483 - accuracy: 0.9118 - val_loss: 0.3827 - val_accuracy: 0.8305\n",
      "Epoch 794/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2482 - accuracy: 0.9118 - val_loss: 0.3827 - val_accuracy: 0.8305\n",
      "Epoch 795/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2481 - accuracy: 0.9118 - val_loss: 0.3827 - val_accuracy: 0.8305\n",
      "Epoch 796/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2480 - accuracy: 0.9118 - val_loss: 0.3827 - val_accuracy: 0.8305\n",
      "Epoch 797/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2479 - accuracy: 0.9118 - val_loss: 0.3827 - val_accuracy: 0.8305\n",
      "Epoch 798/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2477 - accuracy: 0.9118 - val_loss: 0.3827 - val_accuracy: 0.8305\n",
      "Epoch 799/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2476 - accuracy: 0.9118 - val_loss: 0.3826 - val_accuracy: 0.8305\n",
      "Epoch 800/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2475 - accuracy: 0.9118 - val_loss: 0.3826 - val_accuracy: 0.8305\n",
      "Epoch 801/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2474 - accuracy: 0.9118 - val_loss: 0.3826 - val_accuracy: 0.8305\n",
      "Epoch 802/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2473 - accuracy: 0.9118 - val_loss: 0.3826 - val_accuracy: 0.8305\n",
      "Epoch 803/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2472 - accuracy: 0.9118 - val_loss: 0.3825 - val_accuracy: 0.8305\n",
      "Epoch 804/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2471 - accuracy: 0.9118 - val_loss: 0.3825 - val_accuracy: 0.8305\n",
      "Epoch 805/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2470 - accuracy: 0.9118 - val_loss: 0.3825 - val_accuracy: 0.8305\n",
      "Epoch 806/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2469 - accuracy: 0.9118 - val_loss: 0.3825 - val_accuracy: 0.8305\n",
      "Epoch 807/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2468 - accuracy: 0.9118 - val_loss: 0.3825 - val_accuracy: 0.8305\n",
      "Epoch 808/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2467 - accuracy: 0.9118 - val_loss: 0.3824 - val_accuracy: 0.8305\n",
      "Epoch 809/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2466 - accuracy: 0.9118 - val_loss: 0.3824 - val_accuracy: 0.8305\n",
      "Epoch 810/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2465 - accuracy: 0.9118 - val_loss: 0.3824 - val_accuracy: 0.8305\n",
      "Epoch 811/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2464 - accuracy: 0.9118 - val_loss: 0.3824 - val_accuracy: 0.8305\n",
      "Epoch 812/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2463 - accuracy: 0.9118 - val_loss: 0.3824 - val_accuracy: 0.8305\n",
      "Epoch 813/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2462 - accuracy: 0.9118 - val_loss: 0.3824 - val_accuracy: 0.8305\n",
      "Epoch 814/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2461 - accuracy: 0.9118 - val_loss: 0.3823 - val_accuracy: 0.8305\n",
      "Epoch 815/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2460 - accuracy: 0.9118 - val_loss: 0.3823 - val_accuracy: 0.8305\n",
      "Epoch 816/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2459 - accuracy: 0.9118 - val_loss: 0.3823 - val_accuracy: 0.8305\n",
      "Epoch 817/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2458 - accuracy: 0.9118 - val_loss: 0.3823 - val_accuracy: 0.8305\n",
      "Epoch 818/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2457 - accuracy: 0.9118 - val_loss: 0.3822 - val_accuracy: 0.8305\n",
      "Epoch 819/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2456 - accuracy: 0.9118 - val_loss: 0.3822 - val_accuracy: 0.8305\n",
      "Epoch 820/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2455 - accuracy: 0.9118 - val_loss: 0.3822 - val_accuracy: 0.8305\n",
      "Epoch 821/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2454 - accuracy: 0.9118 - val_loss: 0.3822 - val_accuracy: 0.8305\n",
      "Epoch 822/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2453 - accuracy: 0.9118 - val_loss: 0.3822 - val_accuracy: 0.8305\n",
      "Epoch 823/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2452 - accuracy: 0.9118 - val_loss: 0.3821 - val_accuracy: 0.8305\n",
      "Epoch 824/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2451 - accuracy: 0.9118 - val_loss: 0.3821 - val_accuracy: 0.8305\n",
      "Epoch 825/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2450 - accuracy: 0.9118 - val_loss: 0.3821 - val_accuracy: 0.8305\n",
      "Epoch 826/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2449 - accuracy: 0.9118 - val_loss: 0.3821 - val_accuracy: 0.8305\n",
      "Epoch 827/4000\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.2402 - accuracy: 0.93 - 0s 51us/step - loss: 0.2448 - accuracy: 0.9118 - val_loss: 0.3821 - val_accuracy: 0.8305\n",
      "Epoch 828/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2447 - accuracy: 0.9118 - val_loss: 0.3821 - val_accuracy: 0.8305\n",
      "Epoch 829/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2446 - accuracy: 0.9118 - val_loss: 0.3820 - val_accuracy: 0.8305\n",
      "Epoch 830/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2445 - accuracy: 0.9118 - val_loss: 0.3820 - val_accuracy: 0.8305\n",
      "Epoch 831/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2444 - accuracy: 0.9118 - val_loss: 0.3820 - val_accuracy: 0.8305\n",
      "Epoch 832/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2443 - accuracy: 0.9118 - val_loss: 0.3820 - val_accuracy: 0.8305\n",
      "Epoch 833/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2442 - accuracy: 0.9118 - val_loss: 0.3820 - val_accuracy: 0.8305\n",
      "Epoch 834/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2441 - accuracy: 0.9118 - val_loss: 0.3820 - val_accuracy: 0.8305\n",
      "Epoch 835/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2440 - accuracy: 0.9118 - val_loss: 0.3819 - val_accuracy: 0.8305\n",
      "Epoch 836/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2439 - accuracy: 0.9118 - val_loss: 0.3819 - val_accuracy: 0.8305\n",
      "Epoch 837/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2438 - accuracy: 0.9118 - val_loss: 0.3819 - val_accuracy: 0.8305\n",
      "Epoch 838/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2437 - accuracy: 0.9118 - val_loss: 0.3819 - val_accuracy: 0.8305\n",
      "Epoch 839/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2436 - accuracy: 0.9118 - val_loss: 0.3819 - val_accuracy: 0.8305\n",
      "Epoch 840/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2435 - accuracy: 0.9118 - val_loss: 0.3819 - val_accuracy: 0.8305\n",
      "Epoch 841/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2434 - accuracy: 0.9118 - val_loss: 0.3818 - val_accuracy: 0.8305\n",
      "Epoch 842/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2433 - accuracy: 0.9118 - val_loss: 0.3818 - val_accuracy: 0.8305\n",
      "Epoch 843/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2432 - accuracy: 0.9118 - val_loss: 0.3818 - val_accuracy: 0.8305\n",
      "Epoch 844/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2431 - accuracy: 0.9118 - val_loss: 0.3818 - val_accuracy: 0.8305\n",
      "Epoch 845/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2431 - accuracy: 0.9118 - val_loss: 0.3818 - val_accuracy: 0.8305\n",
      "Epoch 846/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2430 - accuracy: 0.9118 - val_loss: 0.3818 - val_accuracy: 0.8305\n",
      "Epoch 847/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2429 - accuracy: 0.9118 - val_loss: 0.3818 - val_accuracy: 0.8305\n",
      "Epoch 848/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2428 - accuracy: 0.9118 - val_loss: 0.3818 - val_accuracy: 0.8305\n",
      "Epoch 849/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2427 - accuracy: 0.9118 - val_loss: 0.3817 - val_accuracy: 0.8305\n",
      "Epoch 850/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2426 - accuracy: 0.9118 - val_loss: 0.3817 - val_accuracy: 0.8305\n",
      "Epoch 851/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2425 - accuracy: 0.9118 - val_loss: 0.3817 - val_accuracy: 0.8305\n",
      "Epoch 852/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2424 - accuracy: 0.9118 - val_loss: 0.3817 - val_accuracy: 0.8305\n",
      "Epoch 853/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2423 - accuracy: 0.9118 - val_loss: 0.3817 - val_accuracy: 0.8305\n",
      "Epoch 854/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2422 - accuracy: 0.9118 - val_loss: 0.3817 - val_accuracy: 0.8305\n",
      "Epoch 855/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2421 - accuracy: 0.9118 - val_loss: 0.3817 - val_accuracy: 0.8305\n",
      "Epoch 856/4000\n",
      "136/136 [==============================] - 0s 73us/step - loss: 0.2420 - accuracy: 0.9118 - val_loss: 0.3817 - val_accuracy: 0.8305\n",
      "Epoch 857/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2419 - accuracy: 0.9118 - val_loss: 0.3817 - val_accuracy: 0.8305\n",
      "Epoch 858/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2418 - accuracy: 0.9118 - val_loss: 0.3816 - val_accuracy: 0.8305\n",
      "Epoch 859/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2418 - accuracy: 0.9118 - val_loss: 0.3816 - val_accuracy: 0.8305\n",
      "Epoch 860/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2417 - accuracy: 0.9118 - val_loss: 0.3816 - val_accuracy: 0.8305\n",
      "Epoch 861/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2416 - accuracy: 0.9118 - val_loss: 0.3816 - val_accuracy: 0.8305\n",
      "Epoch 862/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2415 - accuracy: 0.9118 - val_loss: 0.3816 - val_accuracy: 0.8305\n",
      "Epoch 863/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2414 - accuracy: 0.9118 - val_loss: 0.3816 - val_accuracy: 0.8305\n",
      "Epoch 864/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2413 - accuracy: 0.9118 - val_loss: 0.3816 - val_accuracy: 0.8305\n",
      "Epoch 865/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2412 - accuracy: 0.9118 - val_loss: 0.3816 - val_accuracy: 0.8305\n",
      "Epoch 866/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2411 - accuracy: 0.9118 - val_loss: 0.3816 - val_accuracy: 0.8305\n",
      "Epoch 867/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2410 - accuracy: 0.9118 - val_loss: 0.3816 - val_accuracy: 0.8305\n",
      "Epoch 868/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2410 - accuracy: 0.9118 - val_loss: 0.3815 - val_accuracy: 0.8305\n",
      "Epoch 869/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2409 - accuracy: 0.9118 - val_loss: 0.3815 - val_accuracy: 0.8305\n",
      "Epoch 870/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2408 - accuracy: 0.9118 - val_loss: 0.3815 - val_accuracy: 0.8305\n",
      "Epoch 871/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2407 - accuracy: 0.9118 - val_loss: 0.3815 - val_accuracy: 0.8305\n",
      "Epoch 872/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2406 - accuracy: 0.9118 - val_loss: 0.3815 - val_accuracy: 0.8305\n",
      "Epoch 873/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2405 - accuracy: 0.9118 - val_loss: 0.3815 - val_accuracy: 0.8305\n",
      "Epoch 874/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2404 - accuracy: 0.9118 - val_loss: 0.3815 - val_accuracy: 0.8305\n",
      "Epoch 875/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2403 - accuracy: 0.9118 - val_loss: 0.3815 - val_accuracy: 0.8305\n",
      "Epoch 876/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2403 - accuracy: 0.9118 - val_loss: 0.3815 - val_accuracy: 0.8305\n",
      "Epoch 877/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2402 - accuracy: 0.9118 - val_loss: 0.3815 - val_accuracy: 0.8305\n",
      "Epoch 878/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2401 - accuracy: 0.9118 - val_loss: 0.3815 - val_accuracy: 0.8305\n",
      "Epoch 879/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2400 - accuracy: 0.9118 - val_loss: 0.3815 - val_accuracy: 0.8305\n",
      "Epoch 880/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2399 - accuracy: 0.9118 - val_loss: 0.3815 - val_accuracy: 0.8305\n",
      "Epoch 881/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2398 - accuracy: 0.9118 - val_loss: 0.3815 - val_accuracy: 0.8305\n",
      "Epoch 882/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2397 - accuracy: 0.9118 - val_loss: 0.3815 - val_accuracy: 0.8305\n",
      "Epoch 883/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2396 - accuracy: 0.9118 - val_loss: 0.3815 - val_accuracy: 0.8305\n",
      "Epoch 884/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2396 - accuracy: 0.9118 - val_loss: 0.3815 - val_accuracy: 0.8305\n",
      "Epoch 885/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2395 - accuracy: 0.9118 - val_loss: 0.3814 - val_accuracy: 0.8305\n",
      "Epoch 886/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2394 - accuracy: 0.9118 - val_loss: 0.3814 - val_accuracy: 0.8305\n",
      "Epoch 887/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2393 - accuracy: 0.9118 - val_loss: 0.3814 - val_accuracy: 0.8305\n",
      "Epoch 888/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2392 - accuracy: 0.9118 - val_loss: 0.3814 - val_accuracy: 0.8305\n",
      "Epoch 889/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2391 - accuracy: 0.9118 - val_loss: 0.3814 - val_accuracy: 0.8305\n",
      "Epoch 890/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2391 - accuracy: 0.9118 - val_loss: 0.3814 - val_accuracy: 0.8305\n",
      "Epoch 891/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2390 - accuracy: 0.9118 - val_loss: 0.3814 - val_accuracy: 0.8305\n",
      "Epoch 892/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2389 - accuracy: 0.9118 - val_loss: 0.3814 - val_accuracy: 0.8305\n",
      "Epoch 893/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2388 - accuracy: 0.9118 - val_loss: 0.3814 - val_accuracy: 0.8305\n",
      "Epoch 894/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2387 - accuracy: 0.9118 - val_loss: 0.3814 - val_accuracy: 0.8305\n",
      "Epoch 895/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2386 - accuracy: 0.9118 - val_loss: 0.3814 - val_accuracy: 0.8305\n",
      "Epoch 896/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2385 - accuracy: 0.9118 - val_loss: 0.3814 - val_accuracy: 0.8305\n",
      "Epoch 897/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2385 - accuracy: 0.9118 - val_loss: 0.3814 - val_accuracy: 0.8305\n",
      "Epoch 898/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2384 - accuracy: 0.9118 - val_loss: 0.3814 - val_accuracy: 0.8305\n",
      "Epoch 899/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2383 - accuracy: 0.9118 - val_loss: 0.3814 - val_accuracy: 0.8305\n",
      "Epoch 900/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2382 - accuracy: 0.9118 - val_loss: 0.3814 - val_accuracy: 0.8305\n",
      "Epoch 901/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2381 - accuracy: 0.9118 - val_loss: 0.3814 - val_accuracy: 0.8305\n",
      "Epoch 902/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2381 - accuracy: 0.9118 - val_loss: 0.3814 - val_accuracy: 0.8305\n",
      "Epoch 903/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2380 - accuracy: 0.9118 - val_loss: 0.3814 - val_accuracy: 0.8305\n",
      "Epoch 904/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2379 - accuracy: 0.9118 - val_loss: 0.3814 - val_accuracy: 0.8305\n",
      "Epoch 905/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2378 - accuracy: 0.9118 - val_loss: 0.3814 - val_accuracy: 0.8305\n",
      "Epoch 906/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2377 - accuracy: 0.9118 - val_loss: 0.3814 - val_accuracy: 0.8305\n",
      "Epoch 907/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2376 - accuracy: 0.9118 - val_loss: 0.3814 - val_accuracy: 0.8305\n",
      "Epoch 908/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2376 - accuracy: 0.9118 - val_loss: 0.3814 - val_accuracy: 0.8305\n",
      "Epoch 909/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2375 - accuracy: 0.9118 - val_loss: 0.3814 - val_accuracy: 0.8305\n",
      "Epoch 910/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2374 - accuracy: 0.9118 - val_loss: 0.3814 - val_accuracy: 0.8305\n",
      "Epoch 911/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2373 - accuracy: 0.9118 - val_loss: 0.3814 - val_accuracy: 0.8305\n",
      "Epoch 912/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2372 - accuracy: 0.9118 - val_loss: 0.3815 - val_accuracy: 0.8305\n",
      "Epoch 913/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2372 - accuracy: 0.9118 - val_loss: 0.3815 - val_accuracy: 0.8305\n",
      "Epoch 914/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2371 - accuracy: 0.9118 - val_loss: 0.3815 - val_accuracy: 0.8305\n",
      "Epoch 915/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2370 - accuracy: 0.9118 - val_loss: 0.3815 - val_accuracy: 0.8305\n",
      "Epoch 916/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2369 - accuracy: 0.9118 - val_loss: 0.3815 - val_accuracy: 0.8305\n",
      "Epoch 917/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2368 - accuracy: 0.9118 - val_loss: 0.3815 - val_accuracy: 0.8305\n",
      "Epoch 918/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2368 - accuracy: 0.9118 - val_loss: 0.3815 - val_accuracy: 0.8305\n",
      "Epoch 919/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2367 - accuracy: 0.9118 - val_loss: 0.3815 - val_accuracy: 0.8305\n",
      "Epoch 920/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2366 - accuracy: 0.9118 - val_loss: 0.3815 - val_accuracy: 0.8305\n",
      "Epoch 921/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2365 - accuracy: 0.9118 - val_loss: 0.3815 - val_accuracy: 0.8305\n",
      "Epoch 922/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2364 - accuracy: 0.9118 - val_loss: 0.3815 - val_accuracy: 0.8305\n",
      "Epoch 923/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2364 - accuracy: 0.9118 - val_loss: 0.3815 - val_accuracy: 0.8305\n",
      "Epoch 924/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2363 - accuracy: 0.9118 - val_loss: 0.3815 - val_accuracy: 0.8305\n",
      "Epoch 925/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2362 - accuracy: 0.9118 - val_loss: 0.3815 - val_accuracy: 0.8305\n",
      "Epoch 926/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2361 - accuracy: 0.9118 - val_loss: 0.3815 - val_accuracy: 0.8305\n",
      "Epoch 927/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2360 - accuracy: 0.9118 - val_loss: 0.3815 - val_accuracy: 0.8305\n",
      "Epoch 928/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2360 - accuracy: 0.9118 - val_loss: 0.3815 - val_accuracy: 0.8305\n",
      "Epoch 929/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2359 - accuracy: 0.9118 - val_loss: 0.3815 - val_accuracy: 0.8305\n",
      "Epoch 930/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2358 - accuracy: 0.9118 - val_loss: 0.3815 - val_accuracy: 0.8305\n",
      "Epoch 931/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2357 - accuracy: 0.9118 - val_loss: 0.3815 - val_accuracy: 0.8305\n",
      "Epoch 932/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2357 - accuracy: 0.9118 - val_loss: 0.3816 - val_accuracy: 0.8305\n",
      "Epoch 933/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2356 - accuracy: 0.9118 - val_loss: 0.3816 - val_accuracy: 0.8305\n",
      "Epoch 934/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2355 - accuracy: 0.9118 - val_loss: 0.3816 - val_accuracy: 0.8305\n",
      "Epoch 935/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2354 - accuracy: 0.9118 - val_loss: 0.3816 - val_accuracy: 0.8305\n",
      "Epoch 936/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2353 - accuracy: 0.9118 - val_loss: 0.3816 - val_accuracy: 0.8305\n",
      "Epoch 937/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2353 - accuracy: 0.9118 - val_loss: 0.3816 - val_accuracy: 0.8305\n",
      "Epoch 938/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2352 - accuracy: 0.9118 - val_loss: 0.3816 - val_accuracy: 0.8305\n",
      "Epoch 939/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2351 - accuracy: 0.9118 - val_loss: 0.3816 - val_accuracy: 0.8305\n",
      "Epoch 940/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2350 - accuracy: 0.9118 - val_loss: 0.3816 - val_accuracy: 0.8305\n",
      "Epoch 941/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2350 - accuracy: 0.9118 - val_loss: 0.3816 - val_accuracy: 0.8305\n",
      "Epoch 942/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2349 - accuracy: 0.9118 - val_loss: 0.3816 - val_accuracy: 0.8305\n",
      "Epoch 943/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2348 - accuracy: 0.9118 - val_loss: 0.3816 - val_accuracy: 0.8305\n",
      "Epoch 944/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2347 - accuracy: 0.9118 - val_loss: 0.3817 - val_accuracy: 0.8305\n",
      "Epoch 945/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2347 - accuracy: 0.9118 - val_loss: 0.3817 - val_accuracy: 0.8305\n",
      "Epoch 946/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2346 - accuracy: 0.9118 - val_loss: 0.3817 - val_accuracy: 0.8305\n",
      "Epoch 947/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2345 - accuracy: 0.9118 - val_loss: 0.3817 - val_accuracy: 0.8305\n",
      "Epoch 948/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2344 - accuracy: 0.9118 - val_loss: 0.3817 - val_accuracy: 0.8305\n",
      "Epoch 949/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2344 - accuracy: 0.9118 - val_loss: 0.3817 - val_accuracy: 0.8305\n",
      "Epoch 950/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2343 - accuracy: 0.9118 - val_loss: 0.3817 - val_accuracy: 0.8305\n",
      "Epoch 951/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2342 - accuracy: 0.9118 - val_loss: 0.3817 - val_accuracy: 0.8305\n",
      "Epoch 952/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2341 - accuracy: 0.9118 - val_loss: 0.3817 - val_accuracy: 0.8305\n",
      "Epoch 953/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2341 - accuracy: 0.9118 - val_loss: 0.3817 - val_accuracy: 0.8305\n",
      "Epoch 954/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2340 - accuracy: 0.9118 - val_loss: 0.3818 - val_accuracy: 0.8305\n",
      "Epoch 955/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2339 - accuracy: 0.9118 - val_loss: 0.3818 - val_accuracy: 0.8305\n",
      "Epoch 956/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2338 - accuracy: 0.9118 - val_loss: 0.3818 - val_accuracy: 0.8305\n",
      "Epoch 957/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2338 - accuracy: 0.9118 - val_loss: 0.3818 - val_accuracy: 0.8305\n",
      "Epoch 958/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2337 - accuracy: 0.9118 - val_loss: 0.3818 - val_accuracy: 0.8305\n",
      "Epoch 959/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2336 - accuracy: 0.9118 - val_loss: 0.3818 - val_accuracy: 0.8305\n",
      "Epoch 960/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2335 - accuracy: 0.9118 - val_loss: 0.3818 - val_accuracy: 0.8305\n",
      "Epoch 961/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2335 - accuracy: 0.9118 - val_loss: 0.3818 - val_accuracy: 0.8305\n",
      "Epoch 962/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2334 - accuracy: 0.9118 - val_loss: 0.3819 - val_accuracy: 0.8305\n",
      "Epoch 963/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2333 - accuracy: 0.9118 - val_loss: 0.3819 - val_accuracy: 0.8305\n",
      "Epoch 964/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2332 - accuracy: 0.9118 - val_loss: 0.3819 - val_accuracy: 0.8305\n",
      "Epoch 965/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2332 - accuracy: 0.9118 - val_loss: 0.3819 - val_accuracy: 0.8305\n",
      "Epoch 966/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2331 - accuracy: 0.9118 - val_loss: 0.3819 - val_accuracy: 0.8305\n",
      "Epoch 967/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2330 - accuracy: 0.9118 - val_loss: 0.3819 - val_accuracy: 0.8305\n",
      "Epoch 968/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2330 - accuracy: 0.9118 - val_loss: 0.3819 - val_accuracy: 0.8305\n",
      "Epoch 969/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2329 - accuracy: 0.9118 - val_loss: 0.3819 - val_accuracy: 0.8305\n",
      "Epoch 970/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2328 - accuracy: 0.9118 - val_loss: 0.3820 - val_accuracy: 0.8305\n",
      "Epoch 971/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2327 - accuracy: 0.9118 - val_loss: 0.3820 - val_accuracy: 0.8305\n",
      "Epoch 972/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2327 - accuracy: 0.9118 - val_loss: 0.3820 - val_accuracy: 0.8305\n",
      "Epoch 973/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2326 - accuracy: 0.9118 - val_loss: 0.3820 - val_accuracy: 0.8305\n",
      "Epoch 974/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2325 - accuracy: 0.9118 - val_loss: 0.3820 - val_accuracy: 0.8305\n",
      "Epoch 975/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2324 - accuracy: 0.9118 - val_loss: 0.3820 - val_accuracy: 0.8305\n",
      "Epoch 976/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2324 - accuracy: 0.9118 - val_loss: 0.3821 - val_accuracy: 0.8305\n",
      "Epoch 977/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2323 - accuracy: 0.9118 - val_loss: 0.3821 - val_accuracy: 0.8305\n",
      "Epoch 978/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2322 - accuracy: 0.9118 - val_loss: 0.3821 - val_accuracy: 0.8305\n",
      "Epoch 979/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2322 - accuracy: 0.9118 - val_loss: 0.3821 - val_accuracy: 0.8305\n",
      "Epoch 980/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2321 - accuracy: 0.9118 - val_loss: 0.3821 - val_accuracy: 0.8305\n",
      "Epoch 981/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2320 - accuracy: 0.9118 - val_loss: 0.3821 - val_accuracy: 0.8305\n",
      "Epoch 982/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2319 - accuracy: 0.9118 - val_loss: 0.3822 - val_accuracy: 0.8305\n",
      "Epoch 983/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2319 - accuracy: 0.9118 - val_loss: 0.3822 - val_accuracy: 0.8305\n",
      "Epoch 984/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2318 - accuracy: 0.9118 - val_loss: 0.3822 - val_accuracy: 0.8305\n",
      "Epoch 985/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2317 - accuracy: 0.9118 - val_loss: 0.3822 - val_accuracy: 0.8305\n",
      "Epoch 986/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2317 - accuracy: 0.9118 - val_loss: 0.3822 - val_accuracy: 0.8305\n",
      "Epoch 987/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2316 - accuracy: 0.9118 - val_loss: 0.3822 - val_accuracy: 0.8305\n",
      "Epoch 988/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2315 - accuracy: 0.9118 - val_loss: 0.3822 - val_accuracy: 0.8305\n",
      "Epoch 989/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2315 - accuracy: 0.9118 - val_loss: 0.3822 - val_accuracy: 0.8305\n",
      "Epoch 990/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2314 - accuracy: 0.9118 - val_loss: 0.3823 - val_accuracy: 0.8305\n",
      "Epoch 991/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2313 - accuracy: 0.9191 - val_loss: 0.3823 - val_accuracy: 0.8305\n",
      "Epoch 992/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2313 - accuracy: 0.9191 - val_loss: 0.3823 - val_accuracy: 0.8305\n",
      "Epoch 993/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2312 - accuracy: 0.9191 - val_loss: 0.3823 - val_accuracy: 0.8305\n",
      "Epoch 994/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2311 - accuracy: 0.9191 - val_loss: 0.3823 - val_accuracy: 0.8305\n",
      "Epoch 995/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2310 - accuracy: 0.9191 - val_loss: 0.3823 - val_accuracy: 0.8305\n",
      "Epoch 996/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2310 - accuracy: 0.9191 - val_loss: 0.3823 - val_accuracy: 0.8305\n",
      "Epoch 997/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2309 - accuracy: 0.9191 - val_loss: 0.3823 - val_accuracy: 0.8305\n",
      "Epoch 998/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2308 - accuracy: 0.9191 - val_loss: 0.3824 - val_accuracy: 0.8305\n",
      "Epoch 999/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2308 - accuracy: 0.9191 - val_loss: 0.3824 - val_accuracy: 0.8305\n",
      "Epoch 1000/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2307 - accuracy: 0.9191 - val_loss: 0.3824 - val_accuracy: 0.8305\n",
      "Epoch 1001/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2306 - accuracy: 0.9191 - val_loss: 0.3824 - val_accuracy: 0.8305\n",
      "Epoch 1002/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2306 - accuracy: 0.9191 - val_loss: 0.3824 - val_accuracy: 0.8305\n",
      "Epoch 1003/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2305 - accuracy: 0.9191 - val_loss: 0.3824 - val_accuracy: 0.8305\n",
      "Epoch 1004/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2304 - accuracy: 0.9191 - val_loss: 0.3825 - val_accuracy: 0.8305\n",
      "Epoch 1005/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2304 - accuracy: 0.9191 - val_loss: 0.3825 - val_accuracy: 0.8305\n",
      "Epoch 1006/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2303 - accuracy: 0.9191 - val_loss: 0.3825 - val_accuracy: 0.8305\n",
      "Epoch 1007/4000\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.2254 - accuracy: 0.93 - 0s 51us/step - loss: 0.2302 - accuracy: 0.9191 - val_loss: 0.3825 - val_accuracy: 0.8305\n",
      "Epoch 1008/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2302 - accuracy: 0.9191 - val_loss: 0.3825 - val_accuracy: 0.8305\n",
      "Epoch 1009/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2301 - accuracy: 0.9191 - val_loss: 0.3825 - val_accuracy: 0.8305\n",
      "Epoch 1010/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2300 - accuracy: 0.9191 - val_loss: 0.3826 - val_accuracy: 0.8305\n",
      "Epoch 1011/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2300 - accuracy: 0.9191 - val_loss: 0.3826 - val_accuracy: 0.8305\n",
      "Epoch 1012/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2299 - accuracy: 0.9191 - val_loss: 0.3826 - val_accuracy: 0.8305\n",
      "Epoch 1013/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2298 - accuracy: 0.9191 - val_loss: 0.3826 - val_accuracy: 0.8305\n",
      "Epoch 1014/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2298 - accuracy: 0.9191 - val_loss: 0.3826 - val_accuracy: 0.8305\n",
      "Epoch 1015/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2297 - accuracy: 0.9191 - val_loss: 0.3827 - val_accuracy: 0.8305\n",
      "Epoch 1016/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2296 - accuracy: 0.9191 - val_loss: 0.3827 - val_accuracy: 0.8305\n",
      "Epoch 1017/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2296 - accuracy: 0.9191 - val_loss: 0.3827 - val_accuracy: 0.8305\n",
      "Epoch 1018/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2295 - accuracy: 0.9191 - val_loss: 0.3827 - val_accuracy: 0.8305\n",
      "Epoch 1019/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2295 - accuracy: 0.9191 - val_loss: 0.3827 - val_accuracy: 0.8305\n",
      "Epoch 1020/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2294 - accuracy: 0.9191 - val_loss: 0.3828 - val_accuracy: 0.8305\n",
      "Epoch 1021/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2293 - accuracy: 0.9191 - val_loss: 0.3828 - val_accuracy: 0.8305\n",
      "Epoch 1022/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2293 - accuracy: 0.9191 - val_loss: 0.3828 - val_accuracy: 0.8305\n",
      "Epoch 1023/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2292 - accuracy: 0.9191 - val_loss: 0.3828 - val_accuracy: 0.8305\n",
      "Epoch 1024/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2291 - accuracy: 0.9191 - val_loss: 0.3829 - val_accuracy: 0.8305\n",
      "Epoch 1025/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2291 - accuracy: 0.9191 - val_loss: 0.3829 - val_accuracy: 0.8305\n",
      "Epoch 1026/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2290 - accuracy: 0.9191 - val_loss: 0.3829 - val_accuracy: 0.8305\n",
      "Epoch 1027/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2289 - accuracy: 0.9191 - val_loss: 0.3829 - val_accuracy: 0.8305\n",
      "Epoch 1028/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2289 - accuracy: 0.9191 - val_loss: 0.3830 - val_accuracy: 0.8305\n",
      "Epoch 1029/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2288 - accuracy: 0.9191 - val_loss: 0.3830 - val_accuracy: 0.8305\n",
      "Epoch 1030/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2287 - accuracy: 0.9191 - val_loss: 0.3830 - val_accuracy: 0.8305\n",
      "Epoch 1031/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2287 - accuracy: 0.9191 - val_loss: 0.3830 - val_accuracy: 0.8305\n",
      "Epoch 1032/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2286 - accuracy: 0.9191 - val_loss: 0.3831 - val_accuracy: 0.8305\n",
      "Epoch 1033/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2286 - accuracy: 0.9191 - val_loss: 0.3831 - val_accuracy: 0.8305\n",
      "Epoch 1034/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2285 - accuracy: 0.9191 - val_loss: 0.3831 - val_accuracy: 0.8305\n",
      "Epoch 1035/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2284 - accuracy: 0.9191 - val_loss: 0.3831 - val_accuracy: 0.8305\n",
      "Epoch 1036/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2284 - accuracy: 0.9191 - val_loss: 0.3832 - val_accuracy: 0.8305\n",
      "Epoch 1037/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2283 - accuracy: 0.9191 - val_loss: 0.3832 - val_accuracy: 0.8305\n",
      "Epoch 1038/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2282 - accuracy: 0.9191 - val_loss: 0.3832 - val_accuracy: 0.8305\n",
      "Epoch 1039/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2282 - accuracy: 0.9191 - val_loss: 0.3832 - val_accuracy: 0.8305\n",
      "Epoch 1040/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2281 - accuracy: 0.9191 - val_loss: 0.3833 - val_accuracy: 0.8305\n",
      "Epoch 1041/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2280 - accuracy: 0.9191 - val_loss: 0.3833 - val_accuracy: 0.8305\n",
      "Epoch 1042/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2280 - accuracy: 0.9191 - val_loss: 0.3833 - val_accuracy: 0.8305\n",
      "Epoch 1043/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2279 - accuracy: 0.9191 - val_loss: 0.3833 - val_accuracy: 0.8305\n",
      "Epoch 1044/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2279 - accuracy: 0.9191 - val_loss: 0.3834 - val_accuracy: 0.8305\n",
      "Epoch 1045/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2278 - accuracy: 0.9191 - val_loss: 0.3834 - val_accuracy: 0.8305\n",
      "Epoch 1046/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2277 - accuracy: 0.9191 - val_loss: 0.3834 - val_accuracy: 0.8305\n",
      "Epoch 1047/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2277 - accuracy: 0.9191 - val_loss: 0.3834 - val_accuracy: 0.8305\n",
      "Epoch 1048/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2276 - accuracy: 0.9191 - val_loss: 0.3835 - val_accuracy: 0.8305\n",
      "Epoch 1049/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2275 - accuracy: 0.9191 - val_loss: 0.3835 - val_accuracy: 0.8305\n",
      "Epoch 1050/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2275 - accuracy: 0.9191 - val_loss: 0.3835 - val_accuracy: 0.8305\n",
      "Epoch 1051/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2274 - accuracy: 0.9191 - val_loss: 0.3835 - val_accuracy: 0.8305\n",
      "Epoch 1052/4000\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.2225 - accuracy: 0.93 - 0s 51us/step - loss: 0.2274 - accuracy: 0.9191 - val_loss: 0.3836 - val_accuracy: 0.8305\n",
      "Epoch 1053/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2273 - accuracy: 0.9191 - val_loss: 0.3836 - val_accuracy: 0.8305\n",
      "Epoch 1054/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2272 - accuracy: 0.9191 - val_loss: 0.3836 - val_accuracy: 0.8305\n",
      "Epoch 1055/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2272 - accuracy: 0.9191 - val_loss: 0.3836 - val_accuracy: 0.8305\n",
      "Epoch 1056/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2271 - accuracy: 0.9191 - val_loss: 0.3837 - val_accuracy: 0.8305\n",
      "Epoch 1057/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2271 - accuracy: 0.9191 - val_loss: 0.3837 - val_accuracy: 0.8305\n",
      "Epoch 1058/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2270 - accuracy: 0.9191 - val_loss: 0.3837 - val_accuracy: 0.8305\n",
      "Epoch 1059/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2269 - accuracy: 0.9191 - val_loss: 0.3838 - val_accuracy: 0.8305\n",
      "Epoch 1060/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2269 - accuracy: 0.9191 - val_loss: 0.3838 - val_accuracy: 0.8305\n",
      "Epoch 1061/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2268 - accuracy: 0.9191 - val_loss: 0.3838 - val_accuracy: 0.8305\n",
      "Epoch 1062/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2267 - accuracy: 0.9191 - val_loss: 0.3839 - val_accuracy: 0.8305\n",
      "Epoch 1063/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2267 - accuracy: 0.9191 - val_loss: 0.3839 - val_accuracy: 0.8305\n",
      "Epoch 1064/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2266 - accuracy: 0.9191 - val_loss: 0.3839 - val_accuracy: 0.8305\n",
      "Epoch 1065/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2266 - accuracy: 0.9191 - val_loss: 0.3839 - val_accuracy: 0.8305\n",
      "Epoch 1066/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2265 - accuracy: 0.9191 - val_loss: 0.3840 - val_accuracy: 0.8305\n",
      "Epoch 1067/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2264 - accuracy: 0.9191 - val_loss: 0.3840 - val_accuracy: 0.8305\n",
      "Epoch 1068/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2264 - accuracy: 0.9191 - val_loss: 0.3840 - val_accuracy: 0.8305\n",
      "Epoch 1069/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2263 - accuracy: 0.9191 - val_loss: 0.3841 - val_accuracy: 0.8305\n",
      "Epoch 1070/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2263 - accuracy: 0.9191 - val_loss: 0.3841 - val_accuracy: 0.8305\n",
      "Epoch 1071/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2262 - accuracy: 0.9191 - val_loss: 0.3841 - val_accuracy: 0.8305\n",
      "Epoch 1072/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2261 - accuracy: 0.9191 - val_loss: 0.3841 - val_accuracy: 0.8305\n",
      "Epoch 1073/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2261 - accuracy: 0.9191 - val_loss: 0.3842 - val_accuracy: 0.8305\n",
      "Epoch 1074/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2260 - accuracy: 0.9191 - val_loss: 0.3842 - val_accuracy: 0.8305\n",
      "Epoch 1075/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2260 - accuracy: 0.9191 - val_loss: 0.3842 - val_accuracy: 0.8305\n",
      "Epoch 1076/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2259 - accuracy: 0.9191 - val_loss: 0.3843 - val_accuracy: 0.8305\n",
      "Epoch 1077/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2258 - accuracy: 0.9191 - val_loss: 0.3843 - val_accuracy: 0.8305\n",
      "Epoch 1078/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2258 - accuracy: 0.9191 - val_loss: 0.3843 - val_accuracy: 0.8305\n",
      "Epoch 1079/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2257 - accuracy: 0.9191 - val_loss: 0.3844 - val_accuracy: 0.8305\n",
      "Epoch 1080/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2257 - accuracy: 0.9191 - val_loss: 0.3844 - val_accuracy: 0.8305\n",
      "Epoch 1081/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2256 - accuracy: 0.9191 - val_loss: 0.3844 - val_accuracy: 0.8305\n",
      "Epoch 1082/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2255 - accuracy: 0.9191 - val_loss: 0.3844 - val_accuracy: 0.8305\n",
      "Epoch 1083/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2255 - accuracy: 0.9191 - val_loss: 0.3845 - val_accuracy: 0.8305\n",
      "Epoch 1084/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2254 - accuracy: 0.9191 - val_loss: 0.3845 - val_accuracy: 0.8305\n",
      "Epoch 1085/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2254 - accuracy: 0.9191 - val_loss: 0.3845 - val_accuracy: 0.8305\n",
      "Epoch 1086/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2253 - accuracy: 0.9191 - val_loss: 0.3846 - val_accuracy: 0.8305\n",
      "Epoch 1087/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2253 - accuracy: 0.9191 - val_loss: 0.3846 - val_accuracy: 0.8305\n",
      "Epoch 1088/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2252 - accuracy: 0.9191 - val_loss: 0.3846 - val_accuracy: 0.8305\n",
      "Epoch 1089/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2252 - accuracy: 0.9191 - val_loss: 0.3846 - val_accuracy: 0.8305\n",
      "Epoch 1090/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2251 - accuracy: 0.9191 - val_loss: 0.3847 - val_accuracy: 0.8305\n",
      "Epoch 1091/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2250 - accuracy: 0.9191 - val_loss: 0.3847 - val_accuracy: 0.8305\n",
      "Epoch 1092/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2250 - accuracy: 0.9191 - val_loss: 0.3847 - val_accuracy: 0.8305\n",
      "Epoch 1093/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2249 - accuracy: 0.9191 - val_loss: 0.3847 - val_accuracy: 0.8305\n",
      "Epoch 1094/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2249 - accuracy: 0.9191 - val_loss: 0.3848 - val_accuracy: 0.8305\n",
      "Epoch 1095/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2248 - accuracy: 0.9191 - val_loss: 0.3848 - val_accuracy: 0.8305\n",
      "Epoch 1096/4000\n",
      "136/136 [==============================] - 0s 73us/step - loss: 0.2248 - accuracy: 0.9191 - val_loss: 0.3848 - val_accuracy: 0.8305\n",
      "Epoch 1097/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2247 - accuracy: 0.9191 - val_loss: 0.3848 - val_accuracy: 0.8305\n",
      "Epoch 1098/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2247 - accuracy: 0.9191 - val_loss: 0.3849 - val_accuracy: 0.8305\n",
      "Epoch 1099/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2246 - accuracy: 0.9191 - val_loss: 0.3849 - val_accuracy: 0.8305\n",
      "Epoch 1100/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2245 - accuracy: 0.9191 - val_loss: 0.3849 - val_accuracy: 0.8305\n",
      "Epoch 1101/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2245 - accuracy: 0.9191 - val_loss: 0.3849 - val_accuracy: 0.8305\n",
      "Epoch 1102/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2244 - accuracy: 0.9191 - val_loss: 0.3850 - val_accuracy: 0.8305\n",
      "Epoch 1103/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2244 - accuracy: 0.9191 - val_loss: 0.3850 - val_accuracy: 0.8305\n",
      "Epoch 1104/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2243 - accuracy: 0.9191 - val_loss: 0.3850 - val_accuracy: 0.8305\n",
      "Epoch 1105/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2243 - accuracy: 0.9191 - val_loss: 0.3850 - val_accuracy: 0.8305\n",
      "Epoch 1106/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2242 - accuracy: 0.9191 - val_loss: 0.3851 - val_accuracy: 0.8305\n",
      "Epoch 1107/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2242 - accuracy: 0.9191 - val_loss: 0.3851 - val_accuracy: 0.8305\n",
      "Epoch 1108/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2241 - accuracy: 0.9191 - val_loss: 0.3851 - val_accuracy: 0.8305\n",
      "Epoch 1109/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2241 - accuracy: 0.9191 - val_loss: 0.3851 - val_accuracy: 0.8305\n",
      "Epoch 1110/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2240 - accuracy: 0.9191 - val_loss: 0.3852 - val_accuracy: 0.8305\n",
      "Epoch 1111/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2240 - accuracy: 0.9191 - val_loss: 0.3852 - val_accuracy: 0.8305\n",
      "Epoch 1112/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2239 - accuracy: 0.9191 - val_loss: 0.3852 - val_accuracy: 0.8305\n",
      "Epoch 1113/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2238 - accuracy: 0.9191 - val_loss: 0.3852 - val_accuracy: 0.8305\n",
      "Epoch 1114/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2238 - accuracy: 0.9191 - val_loss: 0.3853 - val_accuracy: 0.8305\n",
      "Epoch 1115/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2237 - accuracy: 0.9191 - val_loss: 0.3853 - val_accuracy: 0.8305\n",
      "Epoch 1116/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2237 - accuracy: 0.9191 - val_loss: 0.3853 - val_accuracy: 0.8305\n",
      "Epoch 1117/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2236 - accuracy: 0.9191 - val_loss: 0.3853 - val_accuracy: 0.8305\n",
      "Epoch 1118/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2236 - accuracy: 0.9191 - val_loss: 0.3854 - val_accuracy: 0.8305\n",
      "Epoch 1119/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2235 - accuracy: 0.9191 - val_loss: 0.3854 - val_accuracy: 0.8305\n",
      "Epoch 1120/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2235 - accuracy: 0.9191 - val_loss: 0.3854 - val_accuracy: 0.8305\n",
      "Epoch 1121/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2234 - accuracy: 0.9191 - val_loss: 0.3855 - val_accuracy: 0.8305\n",
      "Epoch 1122/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2234 - accuracy: 0.9191 - val_loss: 0.3855 - val_accuracy: 0.8305\n",
      "Epoch 1123/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2233 - accuracy: 0.9191 - val_loss: 0.3855 - val_accuracy: 0.8305\n",
      "Epoch 1124/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2233 - accuracy: 0.9191 - val_loss: 0.3855 - val_accuracy: 0.8305\n",
      "Epoch 1125/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2232 - accuracy: 0.9191 - val_loss: 0.3856 - val_accuracy: 0.8305\n",
      "Epoch 1126/4000\n",
      "136/136 [==============================] - 0s 57us/step - loss: 0.2232 - accuracy: 0.9191 - val_loss: 0.3856 - val_accuracy: 0.8305\n",
      "Epoch 1127/4000\n",
      "136/136 [==============================] - 0s 32us/step - loss: 0.2231 - accuracy: 0.9191 - val_loss: 0.3856 - val_accuracy: 0.8305\n",
      "Epoch 1128/4000\n",
      "136/136 [==============================] - 0s 82us/step - loss: 0.2231 - accuracy: 0.9191 - val_loss: 0.3856 - val_accuracy: 0.8305\n",
      "Epoch 1129/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2230 - accuracy: 0.9191 - val_loss: 0.3857 - val_accuracy: 0.8305\n",
      "Epoch 1130/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2229 - accuracy: 0.9191 - val_loss: 0.3857 - val_accuracy: 0.8305\n",
      "Epoch 1131/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2229 - accuracy: 0.9191 - val_loss: 0.3857 - val_accuracy: 0.8305\n",
      "Epoch 1132/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2228 - accuracy: 0.9191 - val_loss: 0.3858 - val_accuracy: 0.8305\n",
      "Epoch 1133/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2228 - accuracy: 0.9191 - val_loss: 0.3858 - val_accuracy: 0.8305\n",
      "Epoch 1134/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2227 - accuracy: 0.9191 - val_loss: 0.3858 - val_accuracy: 0.8305\n",
      "Epoch 1135/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2227 - accuracy: 0.9191 - val_loss: 0.3858 - val_accuracy: 0.8305\n",
      "Epoch 1136/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2226 - accuracy: 0.9191 - val_loss: 0.3859 - val_accuracy: 0.8305\n",
      "Epoch 1137/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2226 - accuracy: 0.9191 - val_loss: 0.3859 - val_accuracy: 0.8305\n",
      "Epoch 1138/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2225 - accuracy: 0.9191 - val_loss: 0.3859 - val_accuracy: 0.8305\n",
      "Epoch 1139/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2225 - accuracy: 0.9191 - val_loss: 0.3859 - val_accuracy: 0.8305\n",
      "Epoch 1140/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2224 - accuracy: 0.9191 - val_loss: 0.3860 - val_accuracy: 0.8305\n",
      "Epoch 1141/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2224 - accuracy: 0.9191 - val_loss: 0.3860 - val_accuracy: 0.8305\n",
      "Epoch 1142/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2223 - accuracy: 0.9191 - val_loss: 0.3860 - val_accuracy: 0.8305\n",
      "Epoch 1143/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2223 - accuracy: 0.9191 - val_loss: 0.3861 - val_accuracy: 0.8305\n",
      "Epoch 1144/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2222 - accuracy: 0.9191 - val_loss: 0.3861 - val_accuracy: 0.8305\n",
      "Epoch 1145/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2222 - accuracy: 0.9191 - val_loss: 0.3861 - val_accuracy: 0.8305\n",
      "Epoch 1146/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2221 - accuracy: 0.9191 - val_loss: 0.3862 - val_accuracy: 0.8305\n",
      "Epoch 1147/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2221 - accuracy: 0.9191 - val_loss: 0.3862 - val_accuracy: 0.8305\n",
      "Epoch 1148/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2220 - accuracy: 0.9191 - val_loss: 0.3862 - val_accuracy: 0.8305\n",
      "Epoch 1149/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2220 - accuracy: 0.9191 - val_loss: 0.3862 - val_accuracy: 0.8305\n",
      "Epoch 1150/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2219 - accuracy: 0.9191 - val_loss: 0.3863 - val_accuracy: 0.8305\n",
      "Epoch 1151/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2219 - accuracy: 0.9191 - val_loss: 0.3863 - val_accuracy: 0.8305\n",
      "Epoch 1152/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2218 - accuracy: 0.9191 - val_loss: 0.3863 - val_accuracy: 0.8305\n",
      "Epoch 1153/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2218 - accuracy: 0.9191 - val_loss: 0.3864 - val_accuracy: 0.8305\n",
      "Epoch 1154/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2217 - accuracy: 0.9191 - val_loss: 0.3864 - val_accuracy: 0.8305\n",
      "Epoch 1155/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2217 - accuracy: 0.9191 - val_loss: 0.3864 - val_accuracy: 0.8305\n",
      "Epoch 1156/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2216 - accuracy: 0.9191 - val_loss: 0.3865 - val_accuracy: 0.8305\n",
      "Epoch 1157/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2216 - accuracy: 0.9191 - val_loss: 0.3865 - val_accuracy: 0.8305\n",
      "Epoch 1158/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2215 - accuracy: 0.9191 - val_loss: 0.3865 - val_accuracy: 0.8305\n",
      "Epoch 1159/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2215 - accuracy: 0.9191 - val_loss: 0.3865 - val_accuracy: 0.8305\n",
      "Epoch 1160/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2214 - accuracy: 0.9191 - val_loss: 0.3866 - val_accuracy: 0.8305\n",
      "Epoch 1161/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2214 - accuracy: 0.9191 - val_loss: 0.3866 - val_accuracy: 0.8305\n",
      "Epoch 1162/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2213 - accuracy: 0.9191 - val_loss: 0.3866 - val_accuracy: 0.8305\n",
      "Epoch 1163/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2213 - accuracy: 0.9191 - val_loss: 0.3867 - val_accuracy: 0.8305\n",
      "Epoch 1164/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2212 - accuracy: 0.9191 - val_loss: 0.3867 - val_accuracy: 0.8305\n",
      "Epoch 1165/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2212 - accuracy: 0.9191 - val_loss: 0.3867 - val_accuracy: 0.8305\n",
      "Epoch 1166/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2211 - accuracy: 0.9191 - val_loss: 0.3868 - val_accuracy: 0.8305\n",
      "Epoch 1167/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2211 - accuracy: 0.9191 - val_loss: 0.3868 - val_accuracy: 0.8305\n",
      "Epoch 1168/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2210 - accuracy: 0.9191 - val_loss: 0.3868 - val_accuracy: 0.8305\n",
      "Epoch 1169/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2210 - accuracy: 0.9191 - val_loss: 0.3869 - val_accuracy: 0.8305\n",
      "Epoch 1170/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2209 - accuracy: 0.9191 - val_loss: 0.3869 - val_accuracy: 0.8305\n",
      "Epoch 1171/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2209 - accuracy: 0.9191 - val_loss: 0.3869 - val_accuracy: 0.8305\n",
      "Epoch 1172/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2208 - accuracy: 0.9191 - val_loss: 0.3869 - val_accuracy: 0.8305\n",
      "Epoch 1173/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2208 - accuracy: 0.9191 - val_loss: 0.3870 - val_accuracy: 0.8305\n",
      "Epoch 1174/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2207 - accuracy: 0.9191 - val_loss: 0.3870 - val_accuracy: 0.8305\n",
      "Epoch 1175/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2207 - accuracy: 0.9191 - val_loss: 0.3870 - val_accuracy: 0.8305\n",
      "Epoch 1176/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2206 - accuracy: 0.9191 - val_loss: 0.3871 - val_accuracy: 0.8305\n",
      "Epoch 1177/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2206 - accuracy: 0.9191 - val_loss: 0.3871 - val_accuracy: 0.8305\n",
      "Epoch 1178/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2205 - accuracy: 0.9191 - val_loss: 0.3871 - val_accuracy: 0.8305\n",
      "Epoch 1179/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2205 - accuracy: 0.9191 - val_loss: 0.3872 - val_accuracy: 0.8305\n",
      "Epoch 1180/4000\n",
      "136/136 [==============================] - 0s 96us/step - loss: 0.2205 - accuracy: 0.9191 - val_loss: 0.3872 - val_accuracy: 0.8305\n",
      "Epoch 1181/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2204 - accuracy: 0.9191 - val_loss: 0.3872 - val_accuracy: 0.8305\n",
      "Epoch 1182/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2204 - accuracy: 0.9191 - val_loss: 0.3872 - val_accuracy: 0.8305\n",
      "Epoch 1183/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2203 - accuracy: 0.9191 - val_loss: 0.3873 - val_accuracy: 0.8305\n",
      "Epoch 1184/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2203 - accuracy: 0.9191 - val_loss: 0.3873 - val_accuracy: 0.8305\n",
      "Epoch 1185/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2202 - accuracy: 0.9191 - val_loss: 0.3873 - val_accuracy: 0.8305\n",
      "Epoch 1186/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2202 - accuracy: 0.9191 - val_loss: 0.3874 - val_accuracy: 0.8305\n",
      "Epoch 1187/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2201 - accuracy: 0.9191 - val_loss: 0.3874 - val_accuracy: 0.8305\n",
      "Epoch 1188/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2201 - accuracy: 0.9191 - val_loss: 0.3874 - val_accuracy: 0.8305\n",
      "Epoch 1189/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2200 - accuracy: 0.9191 - val_loss: 0.3875 - val_accuracy: 0.8305\n",
      "Epoch 1190/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2200 - accuracy: 0.9191 - val_loss: 0.3875 - val_accuracy: 0.8305\n",
      "Epoch 1191/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2199 - accuracy: 0.9191 - val_loss: 0.3875 - val_accuracy: 0.8305\n",
      "Epoch 1192/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2199 - accuracy: 0.9191 - val_loss: 0.3875 - val_accuracy: 0.8305\n",
      "Epoch 1193/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2198 - accuracy: 0.9191 - val_loss: 0.3876 - val_accuracy: 0.8305\n",
      "Epoch 1194/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2198 - accuracy: 0.9191 - val_loss: 0.3876 - val_accuracy: 0.8305\n",
      "Epoch 1195/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2198 - accuracy: 0.9191 - val_loss: 0.3876 - val_accuracy: 0.8305\n",
      "Epoch 1196/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2197 - accuracy: 0.9191 - val_loss: 0.3877 - val_accuracy: 0.8136\n",
      "Epoch 1197/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2197 - accuracy: 0.9191 - val_loss: 0.3877 - val_accuracy: 0.8136\n",
      "Epoch 1198/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2196 - accuracy: 0.9191 - val_loss: 0.3877 - val_accuracy: 0.8136\n",
      "Epoch 1199/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2196 - accuracy: 0.9191 - val_loss: 0.3878 - val_accuracy: 0.8136\n",
      "Epoch 1200/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2195 - accuracy: 0.9191 - val_loss: 0.3878 - val_accuracy: 0.8136\n",
      "Epoch 1201/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2195 - accuracy: 0.9191 - val_loss: 0.3878 - val_accuracy: 0.8136\n",
      "Epoch 1202/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2194 - accuracy: 0.9191 - val_loss: 0.3879 - val_accuracy: 0.8136\n",
      "Epoch 1203/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2194 - accuracy: 0.9191 - val_loss: 0.3879 - val_accuracy: 0.8136\n",
      "Epoch 1204/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2193 - accuracy: 0.9191 - val_loss: 0.3879 - val_accuracy: 0.8136\n",
      "Epoch 1205/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2193 - accuracy: 0.9191 - val_loss: 0.3879 - val_accuracy: 0.8136\n",
      "Epoch 1206/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2193 - accuracy: 0.9191 - val_loss: 0.3880 - val_accuracy: 0.8136\n",
      "Epoch 1207/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2192 - accuracy: 0.9191 - val_loss: 0.3880 - val_accuracy: 0.8136\n",
      "Epoch 1208/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2192 - accuracy: 0.9191 - val_loss: 0.3880 - val_accuracy: 0.8136\n",
      "Epoch 1209/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2191 - accuracy: 0.9191 - val_loss: 0.3881 - val_accuracy: 0.7966\n",
      "Epoch 1210/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2191 - accuracy: 0.9191 - val_loss: 0.3881 - val_accuracy: 0.7966\n",
      "Epoch 1211/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2190 - accuracy: 0.9191 - val_loss: 0.3881 - val_accuracy: 0.7966\n",
      "Epoch 1212/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2190 - accuracy: 0.9191 - val_loss: 0.3882 - val_accuracy: 0.7966\n",
      "Epoch 1213/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2189 - accuracy: 0.9191 - val_loss: 0.3882 - val_accuracy: 0.7966\n",
      "Epoch 1214/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2189 - accuracy: 0.9191 - val_loss: 0.3882 - val_accuracy: 0.7966\n",
      "Epoch 1215/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2188 - accuracy: 0.9191 - val_loss: 0.3883 - val_accuracy: 0.7966\n",
      "Epoch 1216/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2188 - accuracy: 0.9191 - val_loss: 0.3883 - val_accuracy: 0.7966\n",
      "Epoch 1217/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2188 - accuracy: 0.9191 - val_loss: 0.3883 - val_accuracy: 0.7966\n",
      "Epoch 1218/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2187 - accuracy: 0.9191 - val_loss: 0.3884 - val_accuracy: 0.7966\n",
      "Epoch 1219/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2187 - accuracy: 0.9191 - val_loss: 0.3884 - val_accuracy: 0.7966\n",
      "Epoch 1220/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2186 - accuracy: 0.9191 - val_loss: 0.3884 - val_accuracy: 0.7966\n",
      "Epoch 1221/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2186 - accuracy: 0.9191 - val_loss: 0.3885 - val_accuracy: 0.7966\n",
      "Epoch 1222/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2185 - accuracy: 0.9191 - val_loss: 0.3885 - val_accuracy: 0.7966\n",
      "Epoch 1223/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2185 - accuracy: 0.9191 - val_loss: 0.3885 - val_accuracy: 0.7966\n",
      "Epoch 1224/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2184 - accuracy: 0.9191 - val_loss: 0.3886 - val_accuracy: 0.7966\n",
      "Epoch 1225/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2184 - accuracy: 0.9191 - val_loss: 0.3886 - val_accuracy: 0.7966\n",
      "Epoch 1226/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2184 - accuracy: 0.9191 - val_loss: 0.3886 - val_accuracy: 0.7966\n",
      "Epoch 1227/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2183 - accuracy: 0.9191 - val_loss: 0.3886 - val_accuracy: 0.7966\n",
      "Epoch 1228/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2183 - accuracy: 0.9191 - val_loss: 0.3887 - val_accuracy: 0.7966\n",
      "Epoch 1229/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2182 - accuracy: 0.9191 - val_loss: 0.3887 - val_accuracy: 0.7966\n",
      "Epoch 1230/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2182 - accuracy: 0.9191 - val_loss: 0.3887 - val_accuracy: 0.7966\n",
      "Epoch 1231/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2181 - accuracy: 0.9191 - val_loss: 0.3888 - val_accuracy: 0.7966\n",
      "Epoch 1232/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2181 - accuracy: 0.9191 - val_loss: 0.3888 - val_accuracy: 0.7966\n",
      "Epoch 1233/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2180 - accuracy: 0.9191 - val_loss: 0.3888 - val_accuracy: 0.7966\n",
      "Epoch 1234/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2180 - accuracy: 0.9191 - val_loss: 0.3889 - val_accuracy: 0.7966\n",
      "Epoch 1235/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2180 - accuracy: 0.9191 - val_loss: 0.3889 - val_accuracy: 0.7966\n",
      "Epoch 1236/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2179 - accuracy: 0.9191 - val_loss: 0.3889 - val_accuracy: 0.7966\n",
      "Epoch 1237/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2179 - accuracy: 0.9191 - val_loss: 0.3890 - val_accuracy: 0.7966\n",
      "Epoch 1238/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2178 - accuracy: 0.9191 - val_loss: 0.3890 - val_accuracy: 0.7966\n",
      "Epoch 1239/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2178 - accuracy: 0.9191 - val_loss: 0.3890 - val_accuracy: 0.7966\n",
      "Epoch 1240/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2177 - accuracy: 0.9191 - val_loss: 0.3891 - val_accuracy: 0.7966\n",
      "Epoch 1241/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2177 - accuracy: 0.9191 - val_loss: 0.3891 - val_accuracy: 0.8136\n",
      "Epoch 1242/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2177 - accuracy: 0.9191 - val_loss: 0.3891 - val_accuracy: 0.8136\n",
      "Epoch 1243/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2176 - accuracy: 0.9191 - val_loss: 0.3892 - val_accuracy: 0.8136\n",
      "Epoch 1244/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2176 - accuracy: 0.9191 - val_loss: 0.3892 - val_accuracy: 0.8136\n",
      "Epoch 1245/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2175 - accuracy: 0.9191 - val_loss: 0.3892 - val_accuracy: 0.8136\n",
      "Epoch 1246/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2175 - accuracy: 0.9191 - val_loss: 0.3893 - val_accuracy: 0.8136\n",
      "Epoch 1247/4000\n",
      "136/136 [==============================] - 0s 65us/step - loss: 0.2174 - accuracy: 0.9191 - val_loss: 0.3893 - val_accuracy: 0.8136\n",
      "Epoch 1248/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2174 - accuracy: 0.9191 - val_loss: 0.3894 - val_accuracy: 0.8136\n",
      "Epoch 1249/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2174 - accuracy: 0.9191 - val_loss: 0.3894 - val_accuracy: 0.8136\n",
      "Epoch 1250/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2173 - accuracy: 0.9191 - val_loss: 0.3894 - val_accuracy: 0.8136\n",
      "Epoch 1251/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2173 - accuracy: 0.9191 - val_loss: 0.3895 - val_accuracy: 0.8136\n",
      "Epoch 1252/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2172 - accuracy: 0.9191 - val_loss: 0.3895 - val_accuracy: 0.8136\n",
      "Epoch 1253/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2172 - accuracy: 0.9191 - val_loss: 0.3895 - val_accuracy: 0.8136\n",
      "Epoch 1254/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2171 - accuracy: 0.9191 - val_loss: 0.3896 - val_accuracy: 0.8136\n",
      "Epoch 1255/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2171 - accuracy: 0.9191 - val_loss: 0.3896 - val_accuracy: 0.8136\n",
      "Epoch 1256/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2171 - accuracy: 0.9191 - val_loss: 0.3896 - val_accuracy: 0.8136\n",
      "Epoch 1257/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2170 - accuracy: 0.9191 - val_loss: 0.3897 - val_accuracy: 0.8136\n",
      "Epoch 1258/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2170 - accuracy: 0.9191 - val_loss: 0.3897 - val_accuracy: 0.8136\n",
      "Epoch 1259/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2169 - accuracy: 0.9191 - val_loss: 0.3897 - val_accuracy: 0.8136\n",
      "Epoch 1260/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2169 - accuracy: 0.9191 - val_loss: 0.3898 - val_accuracy: 0.8136\n",
      "Epoch 1261/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2168 - accuracy: 0.9191 - val_loss: 0.3898 - val_accuracy: 0.8136\n",
      "Epoch 1262/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2168 - accuracy: 0.9191 - val_loss: 0.3899 - val_accuracy: 0.8136\n",
      "Epoch 1263/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2168 - accuracy: 0.9191 - val_loss: 0.3899 - val_accuracy: 0.8136\n",
      "Epoch 1264/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2167 - accuracy: 0.9191 - val_loss: 0.3899 - val_accuracy: 0.8136\n",
      "Epoch 1265/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2167 - accuracy: 0.9191 - val_loss: 0.3900 - val_accuracy: 0.8136\n",
      "Epoch 1266/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2166 - accuracy: 0.9191 - val_loss: 0.3900 - val_accuracy: 0.8136\n",
      "Epoch 1267/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2166 - accuracy: 0.9191 - val_loss: 0.3900 - val_accuracy: 0.8136\n",
      "Epoch 1268/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2166 - accuracy: 0.9191 - val_loss: 0.3901 - val_accuracy: 0.8136\n",
      "Epoch 1269/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2165 - accuracy: 0.9191 - val_loss: 0.3901 - val_accuracy: 0.8136\n",
      "Epoch 1270/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2165 - accuracy: 0.9191 - val_loss: 0.3901 - val_accuracy: 0.8136\n",
      "Epoch 1271/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2164 - accuracy: 0.9191 - val_loss: 0.3902 - val_accuracy: 0.8136\n",
      "Epoch 1272/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2164 - accuracy: 0.9191 - val_loss: 0.3902 - val_accuracy: 0.8136\n",
      "Epoch 1273/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2163 - accuracy: 0.9191 - val_loss: 0.3903 - val_accuracy: 0.8136\n",
      "Epoch 1274/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2163 - accuracy: 0.9191 - val_loss: 0.3903 - val_accuracy: 0.8136\n",
      "Epoch 1275/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2163 - accuracy: 0.9191 - val_loss: 0.3903 - val_accuracy: 0.8136\n",
      "Epoch 1276/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2162 - accuracy: 0.9191 - val_loss: 0.3903 - val_accuracy: 0.8136\n",
      "Epoch 1277/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2162 - accuracy: 0.9191 - val_loss: 0.3904 - val_accuracy: 0.8136\n",
      "Epoch 1278/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2161 - accuracy: 0.9191 - val_loss: 0.3904 - val_accuracy: 0.8136\n",
      "Epoch 1279/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2161 - accuracy: 0.9191 - val_loss: 0.3905 - val_accuracy: 0.8136\n",
      "Epoch 1280/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2161 - accuracy: 0.9191 - val_loss: 0.3905 - val_accuracy: 0.8136\n",
      "Epoch 1281/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2160 - accuracy: 0.9191 - val_loss: 0.3905 - val_accuracy: 0.8136\n",
      "Epoch 1282/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2160 - accuracy: 0.9191 - val_loss: 0.3905 - val_accuracy: 0.8136\n",
      "Epoch 1283/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2159 - accuracy: 0.9191 - val_loss: 0.3906 - val_accuracy: 0.8136\n",
      "Epoch 1284/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2159 - accuracy: 0.9191 - val_loss: 0.3906 - val_accuracy: 0.8136\n",
      "Epoch 1285/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2158 - accuracy: 0.9191 - val_loss: 0.3906 - val_accuracy: 0.8136\n",
      "Epoch 1286/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2158 - accuracy: 0.9191 - val_loss: 0.3906 - val_accuracy: 0.8136\n",
      "Epoch 1287/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2157 - accuracy: 0.9191 - val_loss: 0.3907 - val_accuracy: 0.8136\n",
      "Epoch 1288/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2157 - accuracy: 0.9191 - val_loss: 0.3907 - val_accuracy: 0.8136\n",
      "Epoch 1289/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2157 - accuracy: 0.9191 - val_loss: 0.3907 - val_accuracy: 0.8136\n",
      "Epoch 1290/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2156 - accuracy: 0.9191 - val_loss: 0.3907 - val_accuracy: 0.8136\n",
      "Epoch 1291/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2156 - accuracy: 0.9191 - val_loss: 0.3908 - val_accuracy: 0.8136\n",
      "Epoch 1292/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2155 - accuracy: 0.9191 - val_loss: 0.3908 - val_accuracy: 0.8136\n",
      "Epoch 1293/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2155 - accuracy: 0.9191 - val_loss: 0.3908 - val_accuracy: 0.8136\n",
      "Epoch 1294/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2154 - accuracy: 0.9191 - val_loss: 0.3908 - val_accuracy: 0.8136\n",
      "Epoch 1295/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2154 - accuracy: 0.9191 - val_loss: 0.3909 - val_accuracy: 0.8136\n",
      "Epoch 1296/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2154 - accuracy: 0.9191 - val_loss: 0.3909 - val_accuracy: 0.8136\n",
      "Epoch 1297/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2153 - accuracy: 0.9191 - val_loss: 0.3909 - val_accuracy: 0.8136\n",
      "Epoch 1298/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2153 - accuracy: 0.9191 - val_loss: 0.3909 - val_accuracy: 0.8136\n",
      "Epoch 1299/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2152 - accuracy: 0.9191 - val_loss: 0.3910 - val_accuracy: 0.8136\n",
      "Epoch 1300/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2152 - accuracy: 0.9191 - val_loss: 0.3910 - val_accuracy: 0.8136\n",
      "Epoch 1301/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2151 - accuracy: 0.9191 - val_loss: 0.3910 - val_accuracy: 0.8136\n",
      "Epoch 1302/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2151 - accuracy: 0.9191 - val_loss: 0.3910 - val_accuracy: 0.8136\n",
      "Epoch 1303/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2151 - accuracy: 0.9191 - val_loss: 0.3911 - val_accuracy: 0.8136\n",
      "Epoch 1304/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2150 - accuracy: 0.9191 - val_loss: 0.3911 - val_accuracy: 0.8136\n",
      "Epoch 1305/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2150 - accuracy: 0.9191 - val_loss: 0.3911 - val_accuracy: 0.8136\n",
      "Epoch 1306/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2149 - accuracy: 0.9191 - val_loss: 0.3912 - val_accuracy: 0.8136\n",
      "Epoch 1307/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2149 - accuracy: 0.9191 - val_loss: 0.3912 - val_accuracy: 0.8136\n",
      "Epoch 1308/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2148 - accuracy: 0.9191 - val_loss: 0.3912 - val_accuracy: 0.8136\n",
      "Epoch 1309/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2148 - accuracy: 0.9191 - val_loss: 0.3912 - val_accuracy: 0.8136\n",
      "Epoch 1310/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2148 - accuracy: 0.9191 - val_loss: 0.3913 - val_accuracy: 0.8136\n",
      "Epoch 1311/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2147 - accuracy: 0.9191 - val_loss: 0.3913 - val_accuracy: 0.8136\n",
      "Epoch 1312/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2147 - accuracy: 0.9191 - val_loss: 0.3913 - val_accuracy: 0.8136\n",
      "Epoch 1313/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2146 - accuracy: 0.9191 - val_loss: 0.3913 - val_accuracy: 0.8136\n",
      "Epoch 1314/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2146 - accuracy: 0.9191 - val_loss: 0.3914 - val_accuracy: 0.8136\n",
      "Epoch 1315/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2146 - accuracy: 0.9191 - val_loss: 0.3914 - val_accuracy: 0.8136\n",
      "Epoch 1316/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2145 - accuracy: 0.9191 - val_loss: 0.3914 - val_accuracy: 0.8136\n",
      "Epoch 1317/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2145 - accuracy: 0.9191 - val_loss: 0.3914 - val_accuracy: 0.8136\n",
      "Epoch 1318/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2144 - accuracy: 0.9191 - val_loss: 0.3915 - val_accuracy: 0.8136\n",
      "Epoch 1319/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2144 - accuracy: 0.9191 - val_loss: 0.3915 - val_accuracy: 0.8136\n",
      "Epoch 1320/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2143 - accuracy: 0.9191 - val_loss: 0.3915 - val_accuracy: 0.8136\n",
      "Epoch 1321/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2143 - accuracy: 0.9191 - val_loss: 0.3915 - val_accuracy: 0.8136\n",
      "Epoch 1322/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2143 - accuracy: 0.9191 - val_loss: 0.3916 - val_accuracy: 0.8136\n",
      "Epoch 1323/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2142 - accuracy: 0.9191 - val_loss: 0.3916 - val_accuracy: 0.8136\n",
      "Epoch 1324/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2142 - accuracy: 0.9191 - val_loss: 0.3916 - val_accuracy: 0.8136\n",
      "Epoch 1325/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2141 - accuracy: 0.9191 - val_loss: 0.3917 - val_accuracy: 0.8136\n",
      "Epoch 1326/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2141 - accuracy: 0.9191 - val_loss: 0.3917 - val_accuracy: 0.8136\n",
      "Epoch 1327/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2141 - accuracy: 0.9191 - val_loss: 0.3917 - val_accuracy: 0.8136\n",
      "Epoch 1328/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2140 - accuracy: 0.9191 - val_loss: 0.3917 - val_accuracy: 0.8136\n",
      "Epoch 1329/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2140 - accuracy: 0.9191 - val_loss: 0.3918 - val_accuracy: 0.8136\n",
      "Epoch 1330/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2139 - accuracy: 0.9191 - val_loss: 0.3918 - val_accuracy: 0.8136\n",
      "Epoch 1331/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2139 - accuracy: 0.9191 - val_loss: 0.3918 - val_accuracy: 0.8136\n",
      "Epoch 1332/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2138 - accuracy: 0.9191 - val_loss: 0.3919 - val_accuracy: 0.8136\n",
      "Epoch 1333/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2138 - accuracy: 0.9191 - val_loss: 0.3919 - val_accuracy: 0.8136\n",
      "Epoch 1334/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2138 - accuracy: 0.9191 - val_loss: 0.3919 - val_accuracy: 0.8136\n",
      "Epoch 1335/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2137 - accuracy: 0.9191 - val_loss: 0.3919 - val_accuracy: 0.8136\n",
      "Epoch 1336/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2137 - accuracy: 0.9191 - val_loss: 0.3920 - val_accuracy: 0.8136\n",
      "Epoch 1337/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2136 - accuracy: 0.9191 - val_loss: 0.3920 - val_accuracy: 0.8136\n",
      "Epoch 1338/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2136 - accuracy: 0.9191 - val_loss: 0.3920 - val_accuracy: 0.8136\n",
      "Epoch 1339/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2136 - accuracy: 0.9191 - val_loss: 0.3920 - val_accuracy: 0.8136\n",
      "Epoch 1340/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2135 - accuracy: 0.9191 - val_loss: 0.3921 - val_accuracy: 0.8136\n",
      "Epoch 1341/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2135 - accuracy: 0.9191 - val_loss: 0.3921 - val_accuracy: 0.8136\n",
      "Epoch 1342/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2134 - accuracy: 0.9191 - val_loss: 0.3921 - val_accuracy: 0.8136\n",
      "Epoch 1343/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2134 - accuracy: 0.9191 - val_loss: 0.3922 - val_accuracy: 0.8136\n",
      "Epoch 1344/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2134 - accuracy: 0.9191 - val_loss: 0.3922 - val_accuracy: 0.8136\n",
      "Epoch 1345/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2133 - accuracy: 0.9191 - val_loss: 0.3922 - val_accuracy: 0.8136\n",
      "Epoch 1346/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2133 - accuracy: 0.9191 - val_loss: 0.3922 - val_accuracy: 0.8136\n",
      "Epoch 1347/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2132 - accuracy: 0.9191 - val_loss: 0.3923 - val_accuracy: 0.8136\n",
      "Epoch 1348/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2132 - accuracy: 0.9191 - val_loss: 0.3923 - val_accuracy: 0.8136\n",
      "Epoch 1349/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2132 - accuracy: 0.9191 - val_loss: 0.3923 - val_accuracy: 0.8136\n",
      "Epoch 1350/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2131 - accuracy: 0.9191 - val_loss: 0.3923 - val_accuracy: 0.8136\n",
      "Epoch 1351/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2131 - accuracy: 0.9191 - val_loss: 0.3924 - val_accuracy: 0.8136\n",
      "Epoch 1352/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2130 - accuracy: 0.9191 - val_loss: 0.3924 - val_accuracy: 0.8136\n",
      "Epoch 1353/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2130 - accuracy: 0.9191 - val_loss: 0.3924 - val_accuracy: 0.8136\n",
      "Epoch 1354/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2130 - accuracy: 0.9191 - val_loss: 0.3925 - val_accuracy: 0.8136\n",
      "Epoch 1355/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2129 - accuracy: 0.9191 - val_loss: 0.3925 - val_accuracy: 0.8136\n",
      "Epoch 1356/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2129 - accuracy: 0.9191 - val_loss: 0.3925 - val_accuracy: 0.8136\n",
      "Epoch 1357/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2128 - accuracy: 0.9191 - val_loss: 0.3925 - val_accuracy: 0.8136\n",
      "Epoch 1358/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2128 - accuracy: 0.9191 - val_loss: 0.3926 - val_accuracy: 0.8136\n",
      "Epoch 1359/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2128 - accuracy: 0.9191 - val_loss: 0.3926 - val_accuracy: 0.8136\n",
      "Epoch 1360/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2127 - accuracy: 0.9191 - val_loss: 0.3926 - val_accuracy: 0.8136\n",
      "Epoch 1361/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2127 - accuracy: 0.9191 - val_loss: 0.3927 - val_accuracy: 0.8136\n",
      "Epoch 1362/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2126 - accuracy: 0.9191 - val_loss: 0.3927 - val_accuracy: 0.8136\n",
      "Epoch 1363/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2126 - accuracy: 0.9191 - val_loss: 0.3927 - val_accuracy: 0.8136\n",
      "Epoch 1364/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2126 - accuracy: 0.9191 - val_loss: 0.3928 - val_accuracy: 0.8136\n",
      "Epoch 1365/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2125 - accuracy: 0.9191 - val_loss: 0.3928 - val_accuracy: 0.8136\n",
      "Epoch 1366/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2125 - accuracy: 0.9191 - val_loss: 0.3928 - val_accuracy: 0.8136\n",
      "Epoch 1367/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2124 - accuracy: 0.9191 - val_loss: 0.3928 - val_accuracy: 0.8136\n",
      "Epoch 1368/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2124 - accuracy: 0.9191 - val_loss: 0.3929 - val_accuracy: 0.8136\n",
      "Epoch 1369/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2124 - accuracy: 0.9191 - val_loss: 0.3929 - val_accuracy: 0.8136\n",
      "Epoch 1370/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2123 - accuracy: 0.9191 - val_loss: 0.3929 - val_accuracy: 0.8136\n",
      "Epoch 1371/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2123 - accuracy: 0.9191 - val_loss: 0.3930 - val_accuracy: 0.8136\n",
      "Epoch 1372/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2123 - accuracy: 0.9191 - val_loss: 0.3930 - val_accuracy: 0.8136\n",
      "Epoch 1373/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2122 - accuracy: 0.9191 - val_loss: 0.3930 - val_accuracy: 0.8136\n",
      "Epoch 1374/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2122 - accuracy: 0.9191 - val_loss: 0.3931 - val_accuracy: 0.8136\n",
      "Epoch 1375/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2121 - accuracy: 0.9191 - val_loss: 0.3931 - val_accuracy: 0.8136\n",
      "Epoch 1376/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2121 - accuracy: 0.9191 - val_loss: 0.3931 - val_accuracy: 0.8136\n",
      "Epoch 1377/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2121 - accuracy: 0.9191 - val_loss: 0.3932 - val_accuracy: 0.8136\n",
      "Epoch 1378/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2120 - accuracy: 0.9191 - val_loss: 0.3932 - val_accuracy: 0.8136\n",
      "Epoch 1379/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2120 - accuracy: 0.9191 - val_loss: 0.3932 - val_accuracy: 0.8136\n",
      "Epoch 1380/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2119 - accuracy: 0.9191 - val_loss: 0.3932 - val_accuracy: 0.8136\n",
      "Epoch 1381/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2119 - accuracy: 0.9191 - val_loss: 0.3933 - val_accuracy: 0.8136\n",
      "Epoch 1382/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2119 - accuracy: 0.9191 - val_loss: 0.3933 - val_accuracy: 0.8136\n",
      "Epoch 1383/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2118 - accuracy: 0.9191 - val_loss: 0.3933 - val_accuracy: 0.8136\n",
      "Epoch 1384/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2118 - accuracy: 0.9191 - val_loss: 0.3934 - val_accuracy: 0.8136\n",
      "Epoch 1385/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2118 - accuracy: 0.9191 - val_loss: 0.3934 - val_accuracy: 0.8136\n",
      "Epoch 1386/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2117 - accuracy: 0.9191 - val_loss: 0.3934 - val_accuracy: 0.8136\n",
      "Epoch 1387/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2117 - accuracy: 0.9191 - val_loss: 0.3935 - val_accuracy: 0.8136\n",
      "Epoch 1388/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2116 - accuracy: 0.9191 - val_loss: 0.3935 - val_accuracy: 0.8136\n",
      "Epoch 1389/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2116 - accuracy: 0.9191 - val_loss: 0.3935 - val_accuracy: 0.8136\n",
      "Epoch 1390/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2116 - accuracy: 0.9191 - val_loss: 0.3936 - val_accuracy: 0.8136\n",
      "Epoch 1391/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2115 - accuracy: 0.9191 - val_loss: 0.3936 - val_accuracy: 0.8136\n",
      "Epoch 1392/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2115 - accuracy: 0.9191 - val_loss: 0.3936 - val_accuracy: 0.8136\n",
      "Epoch 1393/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2114 - accuracy: 0.9191 - val_loss: 0.3937 - val_accuracy: 0.8136\n",
      "Epoch 1394/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2114 - accuracy: 0.9191 - val_loss: 0.3937 - val_accuracy: 0.8136\n",
      "Epoch 1395/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2114 - accuracy: 0.9191 - val_loss: 0.3937 - val_accuracy: 0.8136\n",
      "Epoch 1396/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2113 - accuracy: 0.9191 - val_loss: 0.3938 - val_accuracy: 0.8136\n",
      "Epoch 1397/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2113 - accuracy: 0.9191 - val_loss: 0.3938 - val_accuracy: 0.8136\n",
      "Epoch 1398/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2113 - accuracy: 0.9191 - val_loss: 0.3938 - val_accuracy: 0.8136\n",
      "Epoch 1399/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2112 - accuracy: 0.9191 - val_loss: 0.3938 - val_accuracy: 0.8136\n",
      "Epoch 1400/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2112 - accuracy: 0.9191 - val_loss: 0.3939 - val_accuracy: 0.8136\n",
      "Epoch 1401/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2111 - accuracy: 0.9191 - val_loss: 0.3939 - val_accuracy: 0.8136\n",
      "Epoch 1402/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2111 - accuracy: 0.9191 - val_loss: 0.3939 - val_accuracy: 0.8136\n",
      "Epoch 1403/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2111 - accuracy: 0.9191 - val_loss: 0.3940 - val_accuracy: 0.8136\n",
      "Epoch 1404/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2110 - accuracy: 0.9191 - val_loss: 0.3940 - val_accuracy: 0.8136\n",
      "Epoch 1405/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2110 - accuracy: 0.9191 - val_loss: 0.3940 - val_accuracy: 0.8136\n",
      "Epoch 1406/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2110 - accuracy: 0.9191 - val_loss: 0.3941 - val_accuracy: 0.8136\n",
      "Epoch 1407/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2109 - accuracy: 0.9191 - val_loss: 0.3941 - val_accuracy: 0.8136\n",
      "Epoch 1408/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2109 - accuracy: 0.9191 - val_loss: 0.3941 - val_accuracy: 0.8136\n",
      "Epoch 1409/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2108 - accuracy: 0.9191 - val_loss: 0.3942 - val_accuracy: 0.8136\n",
      "Epoch 1410/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2108 - accuracy: 0.9191 - val_loss: 0.3942 - val_accuracy: 0.8136\n",
      "Epoch 1411/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2108 - accuracy: 0.9191 - val_loss: 0.3942 - val_accuracy: 0.8136\n",
      "Epoch 1412/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2107 - accuracy: 0.9191 - val_loss: 0.3943 - val_accuracy: 0.8136\n",
      "Epoch 1413/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2107 - accuracy: 0.9191 - val_loss: 0.3943 - val_accuracy: 0.8136\n",
      "Epoch 1414/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2107 - accuracy: 0.9191 - val_loss: 0.3943 - val_accuracy: 0.8136\n",
      "Epoch 1415/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2106 - accuracy: 0.9191 - val_loss: 0.3943 - val_accuracy: 0.8136\n",
      "Epoch 1416/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2106 - accuracy: 0.9191 - val_loss: 0.3944 - val_accuracy: 0.8136\n",
      "Epoch 1417/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2106 - accuracy: 0.9191 - val_loss: 0.3944 - val_accuracy: 0.8136\n",
      "Epoch 1418/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2105 - accuracy: 0.9191 - val_loss: 0.3944 - val_accuracy: 0.8136\n",
      "Epoch 1419/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2105 - accuracy: 0.9191 - val_loss: 0.3945 - val_accuracy: 0.8136\n",
      "Epoch 1420/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2105 - accuracy: 0.9191 - val_loss: 0.3945 - val_accuracy: 0.8136\n",
      "Epoch 1421/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2104 - accuracy: 0.9191 - val_loss: 0.3945 - val_accuracy: 0.8136\n",
      "Epoch 1422/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2104 - accuracy: 0.9191 - val_loss: 0.3945 - val_accuracy: 0.8136\n",
      "Epoch 1423/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2103 - accuracy: 0.9191 - val_loss: 0.3946 - val_accuracy: 0.8136\n",
      "Epoch 1424/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2103 - accuracy: 0.9191 - val_loss: 0.3946 - val_accuracy: 0.8136\n",
      "Epoch 1425/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2103 - accuracy: 0.9191 - val_loss: 0.3946 - val_accuracy: 0.8136\n",
      "Epoch 1426/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2102 - accuracy: 0.9191 - val_loss: 0.3946 - val_accuracy: 0.8136\n",
      "Epoch 1427/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2102 - accuracy: 0.9191 - val_loss: 0.3947 - val_accuracy: 0.8136\n",
      "Epoch 1428/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2102 - accuracy: 0.9191 - val_loss: 0.3947 - val_accuracy: 0.8136\n",
      "Epoch 1429/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2101 - accuracy: 0.9191 - val_loss: 0.3947 - val_accuracy: 0.8136\n",
      "Epoch 1430/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2101 - accuracy: 0.9191 - val_loss: 0.3947 - val_accuracy: 0.8136\n",
      "Epoch 1431/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2101 - accuracy: 0.9191 - val_loss: 0.3947 - val_accuracy: 0.8136\n",
      "Epoch 1432/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2100 - accuracy: 0.9191 - val_loss: 0.3948 - val_accuracy: 0.8136\n",
      "Epoch 1433/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2100 - accuracy: 0.9191 - val_loss: 0.3948 - val_accuracy: 0.8136\n",
      "Epoch 1434/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2100 - accuracy: 0.9191 - val_loss: 0.3948 - val_accuracy: 0.8136\n",
      "Epoch 1435/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2099 - accuracy: 0.9191 - val_loss: 0.3948 - val_accuracy: 0.8136\n",
      "Epoch 1436/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2099 - accuracy: 0.9191 - val_loss: 0.3949 - val_accuracy: 0.8136\n",
      "Epoch 1437/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2099 - accuracy: 0.9191 - val_loss: 0.3949 - val_accuracy: 0.8136\n",
      "Epoch 1438/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2098 - accuracy: 0.9191 - val_loss: 0.3949 - val_accuracy: 0.8136\n",
      "Epoch 1439/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2098 - accuracy: 0.9191 - val_loss: 0.3949 - val_accuracy: 0.8136\n",
      "Epoch 1440/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2098 - accuracy: 0.9191 - val_loss: 0.3950 - val_accuracy: 0.8136\n",
      "Epoch 1441/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2097 - accuracy: 0.9191 - val_loss: 0.3950 - val_accuracy: 0.8136\n",
      "Epoch 1442/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2097 - accuracy: 0.9191 - val_loss: 0.3950 - val_accuracy: 0.8136\n",
      "Epoch 1443/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2097 - accuracy: 0.9191 - val_loss: 0.3950 - val_accuracy: 0.8136\n",
      "Epoch 1444/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2096 - accuracy: 0.9191 - val_loss: 0.3950 - val_accuracy: 0.8136\n",
      "Epoch 1445/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2096 - accuracy: 0.9191 - val_loss: 0.3951 - val_accuracy: 0.8136\n",
      "Epoch 1446/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2096 - accuracy: 0.9191 - val_loss: 0.3951 - val_accuracy: 0.8136\n",
      "Epoch 1447/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2095 - accuracy: 0.9191 - val_loss: 0.3951 - val_accuracy: 0.8136\n",
      "Epoch 1448/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2095 - accuracy: 0.9191 - val_loss: 0.3951 - val_accuracy: 0.8136\n",
      "Epoch 1449/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2095 - accuracy: 0.9191 - val_loss: 0.3952 - val_accuracy: 0.8136\n",
      "Epoch 1450/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2094 - accuracy: 0.9191 - val_loss: 0.3952 - val_accuracy: 0.8136\n",
      "Epoch 1451/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2094 - accuracy: 0.9191 - val_loss: 0.3952 - val_accuracy: 0.8136\n",
      "Epoch 1452/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2094 - accuracy: 0.9118 - val_loss: 0.3952 - val_accuracy: 0.8136\n",
      "Epoch 1453/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2094 - accuracy: 0.9118 - val_loss: 0.3953 - val_accuracy: 0.8136\n",
      "Epoch 1454/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2093 - accuracy: 0.9118 - val_loss: 0.3953 - val_accuracy: 0.8136\n",
      "Epoch 1455/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2093 - accuracy: 0.9118 - val_loss: 0.3953 - val_accuracy: 0.8136\n",
      "Epoch 1456/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2093 - accuracy: 0.9118 - val_loss: 0.3953 - val_accuracy: 0.8136\n",
      "Epoch 1457/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2092 - accuracy: 0.9118 - val_loss: 0.3954 - val_accuracy: 0.8136\n",
      "Epoch 1458/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2092 - accuracy: 0.9118 - val_loss: 0.3954 - val_accuracy: 0.8136\n",
      "Epoch 1459/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2092 - accuracy: 0.9118 - val_loss: 0.3954 - val_accuracy: 0.8136\n",
      "Epoch 1460/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2091 - accuracy: 0.9118 - val_loss: 0.3954 - val_accuracy: 0.8136\n",
      "Epoch 1461/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2091 - accuracy: 0.9118 - val_loss: 0.3955 - val_accuracy: 0.8136\n",
      "Epoch 1462/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2091 - accuracy: 0.9118 - val_loss: 0.3955 - val_accuracy: 0.8136\n",
      "Epoch 1463/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2090 - accuracy: 0.9118 - val_loss: 0.3955 - val_accuracy: 0.8136\n",
      "Epoch 1464/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2090 - accuracy: 0.9118 - val_loss: 0.3955 - val_accuracy: 0.8136\n",
      "Epoch 1465/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2090 - accuracy: 0.9118 - val_loss: 0.3956 - val_accuracy: 0.8136\n",
      "Epoch 1466/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2089 - accuracy: 0.9118 - val_loss: 0.3956 - val_accuracy: 0.8136\n",
      "Epoch 1467/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2089 - accuracy: 0.9118 - val_loss: 0.3956 - val_accuracy: 0.8136\n",
      "Epoch 1468/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2089 - accuracy: 0.9118 - val_loss: 0.3956 - val_accuracy: 0.8136\n",
      "Epoch 1469/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2088 - accuracy: 0.9118 - val_loss: 0.3956 - val_accuracy: 0.8136\n",
      "Epoch 1470/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2088 - accuracy: 0.9118 - val_loss: 0.3957 - val_accuracy: 0.8136\n",
      "Epoch 1471/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2088 - accuracy: 0.9118 - val_loss: 0.3957 - val_accuracy: 0.8136\n",
      "Epoch 1472/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2087 - accuracy: 0.9118 - val_loss: 0.3957 - val_accuracy: 0.8136\n",
      "Epoch 1473/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2087 - accuracy: 0.9118 - val_loss: 0.3957 - val_accuracy: 0.8136\n",
      "Epoch 1474/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2087 - accuracy: 0.9118 - val_loss: 0.3958 - val_accuracy: 0.8136\n",
      "Epoch 1475/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2086 - accuracy: 0.9118 - val_loss: 0.3958 - val_accuracy: 0.8136\n",
      "Epoch 1476/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2086 - accuracy: 0.9118 - val_loss: 0.3958 - val_accuracy: 0.8136\n",
      "Epoch 1477/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2086 - accuracy: 0.9118 - val_loss: 0.3958 - val_accuracy: 0.8136\n",
      "Epoch 1478/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2086 - accuracy: 0.9118 - val_loss: 0.3958 - val_accuracy: 0.8136\n",
      "Epoch 1479/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2085 - accuracy: 0.9118 - val_loss: 0.3959 - val_accuracy: 0.8136\n",
      "Epoch 1480/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2085 - accuracy: 0.9118 - val_loss: 0.3959 - val_accuracy: 0.8136\n",
      "Epoch 1481/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2085 - accuracy: 0.9118 - val_loss: 0.3959 - val_accuracy: 0.8136\n",
      "Epoch 1482/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2084 - accuracy: 0.9118 - val_loss: 0.3959 - val_accuracy: 0.8136\n",
      "Epoch 1483/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2084 - accuracy: 0.9118 - val_loss: 0.3960 - val_accuracy: 0.8136\n",
      "Epoch 1484/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2084 - accuracy: 0.9118 - val_loss: 0.3960 - val_accuracy: 0.8136\n",
      "Epoch 1485/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2083 - accuracy: 0.9118 - val_loss: 0.3960 - val_accuracy: 0.8136\n",
      "Epoch 1486/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2083 - accuracy: 0.9118 - val_loss: 0.3960 - val_accuracy: 0.8136\n",
      "Epoch 1487/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2083 - accuracy: 0.9118 - val_loss: 0.3961 - val_accuracy: 0.8136\n",
      "Epoch 1488/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2082 - accuracy: 0.9118 - val_loss: 0.3961 - val_accuracy: 0.8136\n",
      "Epoch 1489/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2082 - accuracy: 0.9118 - val_loss: 0.3961 - val_accuracy: 0.8136\n",
      "Epoch 1490/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2082 - accuracy: 0.9118 - val_loss: 0.3961 - val_accuracy: 0.8136\n",
      "Epoch 1491/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2081 - accuracy: 0.9118 - val_loss: 0.3961 - val_accuracy: 0.8136\n",
      "Epoch 1492/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2081 - accuracy: 0.9118 - val_loss: 0.3962 - val_accuracy: 0.8136\n",
      "Epoch 1493/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2081 - accuracy: 0.9118 - val_loss: 0.3962 - val_accuracy: 0.8136\n",
      "Epoch 1494/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2081 - accuracy: 0.9118 - val_loss: 0.3962 - val_accuracy: 0.8136\n",
      "Epoch 1495/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2080 - accuracy: 0.9118 - val_loss: 0.3962 - val_accuracy: 0.8136\n",
      "Epoch 1496/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2080 - accuracy: 0.9118 - val_loss: 0.3962 - val_accuracy: 0.8136\n",
      "Epoch 1497/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2080 - accuracy: 0.9118 - val_loss: 0.3963 - val_accuracy: 0.8136\n",
      "Epoch 1498/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2079 - accuracy: 0.9118 - val_loss: 0.3963 - val_accuracy: 0.8136\n",
      "Epoch 1499/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2079 - accuracy: 0.9118 - val_loss: 0.3963 - val_accuracy: 0.7966\n",
      "Epoch 1500/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2079 - accuracy: 0.9118 - val_loss: 0.3963 - val_accuracy: 0.7966\n",
      "Epoch 1501/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2078 - accuracy: 0.9118 - val_loss: 0.3964 - val_accuracy: 0.7966\n",
      "Epoch 1502/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2078 - accuracy: 0.9118 - val_loss: 0.3964 - val_accuracy: 0.7966\n",
      "Epoch 1503/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2078 - accuracy: 0.9118 - val_loss: 0.3964 - val_accuracy: 0.7966\n",
      "Epoch 1504/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2077 - accuracy: 0.9118 - val_loss: 0.3964 - val_accuracy: 0.7966\n",
      "Epoch 1505/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2077 - accuracy: 0.9118 - val_loss: 0.3964 - val_accuracy: 0.7966\n",
      "Epoch 1506/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2077 - accuracy: 0.9118 - val_loss: 0.3965 - val_accuracy: 0.7966\n",
      "Epoch 1507/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2077 - accuracy: 0.9118 - val_loss: 0.3965 - val_accuracy: 0.7966\n",
      "Epoch 1508/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2076 - accuracy: 0.9118 - val_loss: 0.3965 - val_accuracy: 0.7966\n",
      "Epoch 1509/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2076 - accuracy: 0.9118 - val_loss: 0.3965 - val_accuracy: 0.7966\n",
      "Epoch 1510/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2076 - accuracy: 0.9118 - val_loss: 0.3965 - val_accuracy: 0.7966\n",
      "Epoch 1511/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2075 - accuracy: 0.9118 - val_loss: 0.3966 - val_accuracy: 0.7966\n",
      "Epoch 1512/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2075 - accuracy: 0.9118 - val_loss: 0.3966 - val_accuracy: 0.7966\n",
      "Epoch 1513/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2075 - accuracy: 0.9118 - val_loss: 0.3966 - val_accuracy: 0.7966\n",
      "Epoch 1514/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2074 - accuracy: 0.9118 - val_loss: 0.3966 - val_accuracy: 0.7966\n",
      "Epoch 1515/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2074 - accuracy: 0.9118 - val_loss: 0.3966 - val_accuracy: 0.7966\n",
      "Epoch 1516/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2074 - accuracy: 0.9118 - val_loss: 0.3967 - val_accuracy: 0.7966\n",
      "Epoch 1517/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2074 - accuracy: 0.9118 - val_loss: 0.3967 - val_accuracy: 0.7966\n",
      "Epoch 1518/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2073 - accuracy: 0.9118 - val_loss: 0.3967 - val_accuracy: 0.7966\n",
      "Epoch 1519/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2073 - accuracy: 0.9118 - val_loss: 0.3967 - val_accuracy: 0.7966\n",
      "Epoch 1520/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2073 - accuracy: 0.9118 - val_loss: 0.3967 - val_accuracy: 0.7966\n",
      "Epoch 1521/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2072 - accuracy: 0.9118 - val_loss: 0.3968 - val_accuracy: 0.7966\n",
      "Epoch 1522/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2072 - accuracy: 0.9118 - val_loss: 0.3968 - val_accuracy: 0.7966\n",
      "Epoch 1523/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2072 - accuracy: 0.9118 - val_loss: 0.3968 - val_accuracy: 0.7966\n",
      "Epoch 1524/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2071 - accuracy: 0.9118 - val_loss: 0.3968 - val_accuracy: 0.7966\n",
      "Epoch 1525/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2071 - accuracy: 0.9118 - val_loss: 0.3969 - val_accuracy: 0.7966\n",
      "Epoch 1526/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2071 - accuracy: 0.9118 - val_loss: 0.3969 - val_accuracy: 0.7966\n",
      "Epoch 1527/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2071 - accuracy: 0.9118 - val_loss: 0.3969 - val_accuracy: 0.7966\n",
      "Epoch 1528/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2070 - accuracy: 0.9118 - val_loss: 0.3969 - val_accuracy: 0.7966\n",
      "Epoch 1529/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2070 - accuracy: 0.9118 - val_loss: 0.3969 - val_accuracy: 0.7966\n",
      "Epoch 1530/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2070 - accuracy: 0.9118 - val_loss: 0.3970 - val_accuracy: 0.7966\n",
      "Epoch 1531/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2069 - accuracy: 0.9118 - val_loss: 0.3970 - val_accuracy: 0.7966\n",
      "Epoch 1532/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2069 - accuracy: 0.9118 - val_loss: 0.3970 - val_accuracy: 0.7966\n",
      "Epoch 1533/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2069 - accuracy: 0.9118 - val_loss: 0.3970 - val_accuracy: 0.7966\n",
      "Epoch 1534/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2068 - accuracy: 0.9118 - val_loss: 0.3970 - val_accuracy: 0.7966\n",
      "Epoch 1535/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2068 - accuracy: 0.9118 - val_loss: 0.3971 - val_accuracy: 0.7966\n",
      "Epoch 1536/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2068 - accuracy: 0.9118 - val_loss: 0.3971 - val_accuracy: 0.7966\n",
      "Epoch 1537/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2068 - accuracy: 0.9118 - val_loss: 0.3971 - val_accuracy: 0.7966\n",
      "Epoch 1538/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2067 - accuracy: 0.9118 - val_loss: 0.3971 - val_accuracy: 0.7966\n",
      "Epoch 1539/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2067 - accuracy: 0.9118 - val_loss: 0.3971 - val_accuracy: 0.7966\n",
      "Epoch 1540/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2067 - accuracy: 0.9118 - val_loss: 0.3972 - val_accuracy: 0.7966\n",
      "Epoch 1541/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2066 - accuracy: 0.9118 - val_loss: 0.3972 - val_accuracy: 0.7966\n",
      "Epoch 1542/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2066 - accuracy: 0.9118 - val_loss: 0.3972 - val_accuracy: 0.7966\n",
      "Epoch 1543/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2066 - accuracy: 0.9118 - val_loss: 0.3972 - val_accuracy: 0.7966\n",
      "Epoch 1544/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2066 - accuracy: 0.9118 - val_loss: 0.3972 - val_accuracy: 0.7966\n",
      "Epoch 1545/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2065 - accuracy: 0.9118 - val_loss: 0.3972 - val_accuracy: 0.7966\n",
      "Epoch 1546/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2065 - accuracy: 0.9118 - val_loss: 0.3972 - val_accuracy: 0.7966\n",
      "Epoch 1547/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2065 - accuracy: 0.9118 - val_loss: 0.3973 - val_accuracy: 0.7966\n",
      "Epoch 1548/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2064 - accuracy: 0.9118 - val_loss: 0.3973 - val_accuracy: 0.7966\n",
      "Epoch 1549/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2064 - accuracy: 0.9118 - val_loss: 0.3973 - val_accuracy: 0.7966\n",
      "Epoch 1550/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2064 - accuracy: 0.9118 - val_loss: 0.3973 - val_accuracy: 0.7966\n",
      "Epoch 1551/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2064 - accuracy: 0.9118 - val_loss: 0.3973 - val_accuracy: 0.7966\n",
      "Epoch 1552/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2063 - accuracy: 0.9118 - val_loss: 0.3973 - val_accuracy: 0.7966\n",
      "Epoch 1553/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2063 - accuracy: 0.9118 - val_loss: 0.3973 - val_accuracy: 0.7966\n",
      "Epoch 1554/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2063 - accuracy: 0.9118 - val_loss: 0.3973 - val_accuracy: 0.7966\n",
      "Epoch 1555/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2062 - accuracy: 0.9118 - val_loss: 0.3974 - val_accuracy: 0.7966\n",
      "Epoch 1556/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2062 - accuracy: 0.9118 - val_loss: 0.3974 - val_accuracy: 0.7966\n",
      "Epoch 1557/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2062 - accuracy: 0.9118 - val_loss: 0.3974 - val_accuracy: 0.7966\n",
      "Epoch 1558/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2062 - accuracy: 0.9118 - val_loss: 0.3974 - val_accuracy: 0.7966\n",
      "Epoch 1559/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2061 - accuracy: 0.9118 - val_loss: 0.3974 - val_accuracy: 0.7966\n",
      "Epoch 1560/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2061 - accuracy: 0.9118 - val_loss: 0.3974 - val_accuracy: 0.7966\n",
      "Epoch 1561/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2061 - accuracy: 0.9118 - val_loss: 0.3974 - val_accuracy: 0.7966\n",
      "Epoch 1562/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2060 - accuracy: 0.9118 - val_loss: 0.3974 - val_accuracy: 0.7966\n",
      "Epoch 1563/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2060 - accuracy: 0.9118 - val_loss: 0.3975 - val_accuracy: 0.7966\n",
      "Epoch 1564/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2060 - accuracy: 0.9118 - val_loss: 0.3975 - val_accuracy: 0.7966\n",
      "Epoch 1565/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2060 - accuracy: 0.9118 - val_loss: 0.3975 - val_accuracy: 0.7966\n",
      "Epoch 1566/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2059 - accuracy: 0.9118 - val_loss: 0.3975 - val_accuracy: 0.7966\n",
      "Epoch 1567/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2059 - accuracy: 0.9118 - val_loss: 0.3975 - val_accuracy: 0.7966\n",
      "Epoch 1568/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2059 - accuracy: 0.9118 - val_loss: 0.3975 - val_accuracy: 0.7966\n",
      "Epoch 1569/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2059 - accuracy: 0.9118 - val_loss: 0.3975 - val_accuracy: 0.7966\n",
      "Epoch 1570/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2058 - accuracy: 0.9118 - val_loss: 0.3975 - val_accuracy: 0.7966\n",
      "Epoch 1571/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2058 - accuracy: 0.9118 - val_loss: 0.3976 - val_accuracy: 0.7966\n",
      "Epoch 1572/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2058 - accuracy: 0.9118 - val_loss: 0.3976 - val_accuracy: 0.7966\n",
      "Epoch 1573/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2057 - accuracy: 0.9118 - val_loss: 0.3976 - val_accuracy: 0.7966\n",
      "Epoch 1574/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2057 - accuracy: 0.9118 - val_loss: 0.3976 - val_accuracy: 0.7966\n",
      "Epoch 1575/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2057 - accuracy: 0.9118 - val_loss: 0.3976 - val_accuracy: 0.7966\n",
      "Epoch 1576/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2057 - accuracy: 0.9118 - val_loss: 0.3976 - val_accuracy: 0.7966\n",
      "Epoch 1577/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2056 - accuracy: 0.9118 - val_loss: 0.3976 - val_accuracy: 0.7966\n",
      "Epoch 1578/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2056 - accuracy: 0.9118 - val_loss: 0.3977 - val_accuracy: 0.7966\n",
      "Epoch 1579/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2056 - accuracy: 0.9118 - val_loss: 0.3977 - val_accuracy: 0.7966\n",
      "Epoch 1580/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2056 - accuracy: 0.9118 - val_loss: 0.3977 - val_accuracy: 0.7966\n",
      "Epoch 1581/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2055 - accuracy: 0.9118 - val_loss: 0.3977 - val_accuracy: 0.7966\n",
      "Epoch 1582/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2055 - accuracy: 0.9118 - val_loss: 0.3977 - val_accuracy: 0.7966\n",
      "Epoch 1583/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2055 - accuracy: 0.9118 - val_loss: 0.3977 - val_accuracy: 0.7966\n",
      "Epoch 1584/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2054 - accuracy: 0.9118 - val_loss: 0.3977 - val_accuracy: 0.7966\n",
      "Epoch 1585/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2054 - accuracy: 0.9118 - val_loss: 0.3977 - val_accuracy: 0.7966\n",
      "Epoch 1586/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2054 - accuracy: 0.9118 - val_loss: 0.3978 - val_accuracy: 0.7966\n",
      "Epoch 1587/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2054 - accuracy: 0.9118 - val_loss: 0.3978 - val_accuracy: 0.7966\n",
      "Epoch 1588/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2053 - accuracy: 0.9118 - val_loss: 0.3978 - val_accuracy: 0.7966\n",
      "Epoch 1589/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2053 - accuracy: 0.9118 - val_loss: 0.3978 - val_accuracy: 0.7966\n",
      "Epoch 1590/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2053 - accuracy: 0.9118 - val_loss: 0.3978 - val_accuracy: 0.7966\n",
      "Epoch 1591/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2053 - accuracy: 0.9118 - val_loss: 0.3978 - val_accuracy: 0.7966\n",
      "Epoch 1592/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2052 - accuracy: 0.9118 - val_loss: 0.3978 - val_accuracy: 0.7966\n",
      "Epoch 1593/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2052 - accuracy: 0.9118 - val_loss: 0.3979 - val_accuracy: 0.7966\n",
      "Epoch 1594/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2052 - accuracy: 0.9118 - val_loss: 0.3979 - val_accuracy: 0.7966\n",
      "Epoch 1595/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2052 - accuracy: 0.9118 - val_loss: 0.3979 - val_accuracy: 0.7966\n",
      "Epoch 1596/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2051 - accuracy: 0.9118 - val_loss: 0.3979 - val_accuracy: 0.7966\n",
      "Epoch 1597/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2051 - accuracy: 0.9118 - val_loss: 0.3979 - val_accuracy: 0.7966\n",
      "Epoch 1598/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2051 - accuracy: 0.9118 - val_loss: 0.3979 - val_accuracy: 0.7966\n",
      "Epoch 1599/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2051 - accuracy: 0.9118 - val_loss: 0.3979 - val_accuracy: 0.7966\n",
      "Epoch 1600/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2050 - accuracy: 0.9118 - val_loss: 0.3980 - val_accuracy: 0.7966\n",
      "Epoch 1601/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2050 - accuracy: 0.9118 - val_loss: 0.3980 - val_accuracy: 0.7966\n",
      "Epoch 1602/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2050 - accuracy: 0.9118 - val_loss: 0.3980 - val_accuracy: 0.7966\n",
      "Epoch 1603/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2049 - accuracy: 0.9118 - val_loss: 0.3980 - val_accuracy: 0.7966\n",
      "Epoch 1604/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2049 - accuracy: 0.9118 - val_loss: 0.3980 - val_accuracy: 0.7966\n",
      "Epoch 1605/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2049 - accuracy: 0.9118 - val_loss: 0.3980 - val_accuracy: 0.7966\n",
      "Epoch 1606/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2049 - accuracy: 0.9118 - val_loss: 0.3980 - val_accuracy: 0.7966\n",
      "Epoch 1607/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2048 - accuracy: 0.9118 - val_loss: 0.3981 - val_accuracy: 0.7966\n",
      "Epoch 1608/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2048 - accuracy: 0.9118 - val_loss: 0.3981 - val_accuracy: 0.7966\n",
      "Epoch 1609/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2048 - accuracy: 0.9118 - val_loss: 0.3981 - val_accuracy: 0.7966\n",
      "Epoch 1610/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2048 - accuracy: 0.9118 - val_loss: 0.3981 - val_accuracy: 0.7966\n",
      "Epoch 1611/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2047 - accuracy: 0.9118 - val_loss: 0.3981 - val_accuracy: 0.7966\n",
      "Epoch 1612/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2047 - accuracy: 0.9118 - val_loss: 0.3981 - val_accuracy: 0.7966\n",
      "Epoch 1613/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2047 - accuracy: 0.9118 - val_loss: 0.3982 - val_accuracy: 0.7966\n",
      "Epoch 1614/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2047 - accuracy: 0.9118 - val_loss: 0.3982 - val_accuracy: 0.7966\n",
      "Epoch 1615/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2046 - accuracy: 0.9118 - val_loss: 0.3982 - val_accuracy: 0.7966\n",
      "Epoch 1616/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2046 - accuracy: 0.9118 - val_loss: 0.3982 - val_accuracy: 0.7966\n",
      "Epoch 1617/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2046 - accuracy: 0.9118 - val_loss: 0.3982 - val_accuracy: 0.7966\n",
      "Epoch 1618/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2046 - accuracy: 0.9118 - val_loss: 0.3982 - val_accuracy: 0.7966\n",
      "Epoch 1619/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2045 - accuracy: 0.9118 - val_loss: 0.3982 - val_accuracy: 0.7966\n",
      "Epoch 1620/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2045 - accuracy: 0.9118 - val_loss: 0.3983 - val_accuracy: 0.7966\n",
      "Epoch 1621/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2045 - accuracy: 0.9118 - val_loss: 0.3983 - val_accuracy: 0.7966\n",
      "Epoch 1622/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2045 - accuracy: 0.9118 - val_loss: 0.3983 - val_accuracy: 0.7966\n",
      "Epoch 1623/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2044 - accuracy: 0.9118 - val_loss: 0.3983 - val_accuracy: 0.7966\n",
      "Epoch 1624/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2044 - accuracy: 0.9118 - val_loss: 0.3983 - val_accuracy: 0.7966\n",
      "Epoch 1625/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2044 - accuracy: 0.9118 - val_loss: 0.3983 - val_accuracy: 0.7966\n",
      "Epoch 1626/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2044 - accuracy: 0.9118 - val_loss: 0.3984 - val_accuracy: 0.7966\n",
      "Epoch 1627/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2043 - accuracy: 0.9118 - val_loss: 0.3984 - val_accuracy: 0.7966\n",
      "Epoch 1628/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2043 - accuracy: 0.9118 - val_loss: 0.3984 - val_accuracy: 0.7966\n",
      "Epoch 1629/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2043 - accuracy: 0.9118 - val_loss: 0.3984 - val_accuracy: 0.7966\n",
      "Epoch 1630/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2043 - accuracy: 0.9118 - val_loss: 0.3984 - val_accuracy: 0.7966\n",
      "Epoch 1631/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2042 - accuracy: 0.9118 - val_loss: 0.3984 - val_accuracy: 0.7966\n",
      "Epoch 1632/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2042 - accuracy: 0.9118 - val_loss: 0.3984 - val_accuracy: 0.7966\n",
      "Epoch 1633/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2042 - accuracy: 0.9118 - val_loss: 0.3985 - val_accuracy: 0.7966\n",
      "Epoch 1634/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2041 - accuracy: 0.9118 - val_loss: 0.3985 - val_accuracy: 0.7966\n",
      "Epoch 1635/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2041 - accuracy: 0.9118 - val_loss: 0.3985 - val_accuracy: 0.7966\n",
      "Epoch 1636/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2041 - accuracy: 0.9118 - val_loss: 0.3985 - val_accuracy: 0.7966\n",
      "Epoch 1637/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2041 - accuracy: 0.9118 - val_loss: 0.3985 - val_accuracy: 0.7966\n",
      "Epoch 1638/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2040 - accuracy: 0.9118 - val_loss: 0.3985 - val_accuracy: 0.7966\n",
      "Epoch 1639/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2040 - accuracy: 0.9118 - val_loss: 0.3986 - val_accuracy: 0.7966\n",
      "Epoch 1640/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2040 - accuracy: 0.9118 - val_loss: 0.3986 - val_accuracy: 0.7966\n",
      "Epoch 1641/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2040 - accuracy: 0.9118 - val_loss: 0.3986 - val_accuracy: 0.7966\n",
      "Epoch 1642/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2039 - accuracy: 0.9118 - val_loss: 0.3986 - val_accuracy: 0.7966\n",
      "Epoch 1643/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2039 - accuracy: 0.9118 - val_loss: 0.3986 - val_accuracy: 0.7966\n",
      "Epoch 1644/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2039 - accuracy: 0.9118 - val_loss: 0.3986 - val_accuracy: 0.7966\n",
      "Epoch 1645/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2039 - accuracy: 0.9118 - val_loss: 0.3987 - val_accuracy: 0.7966\n",
      "Epoch 1646/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2038 - accuracy: 0.9118 - val_loss: 0.3987 - val_accuracy: 0.7966\n",
      "Epoch 1647/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2038 - accuracy: 0.9118 - val_loss: 0.3987 - val_accuracy: 0.7966\n",
      "Epoch 1648/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2038 - accuracy: 0.9118 - val_loss: 0.3987 - val_accuracy: 0.7966\n",
      "Epoch 1649/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2038 - accuracy: 0.9118 - val_loss: 0.3987 - val_accuracy: 0.7966\n",
      "Epoch 1650/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2037 - accuracy: 0.9118 - val_loss: 0.3987 - val_accuracy: 0.7966\n",
      "Epoch 1651/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2037 - accuracy: 0.9118 - val_loss: 0.3988 - val_accuracy: 0.7966\n",
      "Epoch 1652/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2037 - accuracy: 0.9118 - val_loss: 0.3988 - val_accuracy: 0.7966\n",
      "Epoch 1653/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2037 - accuracy: 0.9118 - val_loss: 0.3988 - val_accuracy: 0.7966\n",
      "Epoch 1654/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2036 - accuracy: 0.9118 - val_loss: 0.3988 - val_accuracy: 0.7966\n",
      "Epoch 1655/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2036 - accuracy: 0.9118 - val_loss: 0.3988 - val_accuracy: 0.7966\n",
      "Epoch 1656/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2036 - accuracy: 0.9118 - val_loss: 0.3988 - val_accuracy: 0.7966\n",
      "Epoch 1657/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2036 - accuracy: 0.9118 - val_loss: 0.3989 - val_accuracy: 0.7966\n",
      "Epoch 1658/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2036 - accuracy: 0.9118 - val_loss: 0.3989 - val_accuracy: 0.7966\n",
      "Epoch 1659/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2035 - accuracy: 0.9118 - val_loss: 0.3989 - val_accuracy: 0.7966\n",
      "Epoch 1660/4000\n",
      "136/136 [==============================] - 0s 95us/step - loss: 0.2035 - accuracy: 0.9118 - val_loss: 0.3989 - val_accuracy: 0.7966\n",
      "Epoch 1661/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2035 - accuracy: 0.9118 - val_loss: 0.3989 - val_accuracy: 0.7966\n",
      "Epoch 1662/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2035 - accuracy: 0.9118 - val_loss: 0.3989 - val_accuracy: 0.7966\n",
      "Epoch 1663/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2034 - accuracy: 0.9118 - val_loss: 0.3990 - val_accuracy: 0.7966\n",
      "Epoch 1664/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2034 - accuracy: 0.9118 - val_loss: 0.3990 - val_accuracy: 0.7966\n",
      "Epoch 1665/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2034 - accuracy: 0.9118 - val_loss: 0.3990 - val_accuracy: 0.7966\n",
      "Epoch 1666/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2034 - accuracy: 0.9118 - val_loss: 0.3990 - val_accuracy: 0.7966\n",
      "Epoch 1667/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2033 - accuracy: 0.9118 - val_loss: 0.3990 - val_accuracy: 0.7966\n",
      "Epoch 1668/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2033 - accuracy: 0.9118 - val_loss: 0.3990 - val_accuracy: 0.7966\n",
      "Epoch 1669/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2033 - accuracy: 0.9118 - val_loss: 0.3991 - val_accuracy: 0.7966\n",
      "Epoch 1670/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2033 - accuracy: 0.9118 - val_loss: 0.3991 - val_accuracy: 0.7966\n",
      "Epoch 1671/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2032 - accuracy: 0.9118 - val_loss: 0.3991 - val_accuracy: 0.7966\n",
      "Epoch 1672/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2032 - accuracy: 0.9118 - val_loss: 0.3991 - val_accuracy: 0.7966\n",
      "Epoch 1673/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2032 - accuracy: 0.9118 - val_loss: 0.3991 - val_accuracy: 0.7966\n",
      "Epoch 1674/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2032 - accuracy: 0.9118 - val_loss: 0.3991 - val_accuracy: 0.7966\n",
      "Epoch 1675/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2031 - accuracy: 0.9118 - val_loss: 0.3992 - val_accuracy: 0.7966\n",
      "Epoch 1676/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2031 - accuracy: 0.9118 - val_loss: 0.3992 - val_accuracy: 0.7966\n",
      "Epoch 1677/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2031 - accuracy: 0.9118 - val_loss: 0.3992 - val_accuracy: 0.7966\n",
      "Epoch 1678/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2031 - accuracy: 0.9118 - val_loss: 0.3992 - val_accuracy: 0.7966\n",
      "Epoch 1679/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2030 - accuracy: 0.9118 - val_loss: 0.3992 - val_accuracy: 0.7966\n",
      "Epoch 1680/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2030 - accuracy: 0.9118 - val_loss: 0.3992 - val_accuracy: 0.7966\n",
      "Epoch 1681/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2030 - accuracy: 0.9118 - val_loss: 0.3993 - val_accuracy: 0.7966\n",
      "Epoch 1682/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2030 - accuracy: 0.9118 - val_loss: 0.3993 - val_accuracy: 0.7966\n",
      "Epoch 1683/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2029 - accuracy: 0.9118 - val_loss: 0.3993 - val_accuracy: 0.7966\n",
      "Epoch 1684/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2029 - accuracy: 0.9118 - val_loss: 0.3993 - val_accuracy: 0.7966\n",
      "Epoch 1685/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2029 - accuracy: 0.9118 - val_loss: 0.3993 - val_accuracy: 0.7966\n",
      "Epoch 1686/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2029 - accuracy: 0.9118 - val_loss: 0.3993 - val_accuracy: 0.7966\n",
      "Epoch 1687/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2028 - accuracy: 0.9118 - val_loss: 0.3994 - val_accuracy: 0.7966\n",
      "Epoch 1688/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2028 - accuracy: 0.9118 - val_loss: 0.3994 - val_accuracy: 0.7966\n",
      "Epoch 1689/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2028 - accuracy: 0.9118 - val_loss: 0.3994 - val_accuracy: 0.7966\n",
      "Epoch 1690/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2028 - accuracy: 0.9118 - val_loss: 0.3994 - val_accuracy: 0.7966\n",
      "Epoch 1691/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2028 - accuracy: 0.9118 - val_loss: 0.3994 - val_accuracy: 0.7966\n",
      "Epoch 1692/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2027 - accuracy: 0.9118 - val_loss: 0.3995 - val_accuracy: 0.7966\n",
      "Epoch 1693/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2027 - accuracy: 0.9118 - val_loss: 0.3995 - val_accuracy: 0.7966\n",
      "Epoch 1694/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2027 - accuracy: 0.9118 - val_loss: 0.3995 - val_accuracy: 0.7966\n",
      "Epoch 1695/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2027 - accuracy: 0.9118 - val_loss: 0.3995 - val_accuracy: 0.7966\n",
      "Epoch 1696/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2026 - accuracy: 0.9118 - val_loss: 0.3995 - val_accuracy: 0.7966\n",
      "Epoch 1697/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2026 - accuracy: 0.9118 - val_loss: 0.3995 - val_accuracy: 0.7966\n",
      "Epoch 1698/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2026 - accuracy: 0.9118 - val_loss: 0.3996 - val_accuracy: 0.7966\n",
      "Epoch 1699/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2026 - accuracy: 0.9118 - val_loss: 0.3996 - val_accuracy: 0.7966\n",
      "Epoch 1700/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2025 - accuracy: 0.9118 - val_loss: 0.3996 - val_accuracy: 0.7966\n",
      "Epoch 1701/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2025 - accuracy: 0.9118 - val_loss: 0.3996 - val_accuracy: 0.7966\n",
      "Epoch 1702/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2025 - accuracy: 0.9118 - val_loss: 0.3996 - val_accuracy: 0.7966\n",
      "Epoch 1703/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2025 - accuracy: 0.9118 - val_loss: 0.3996 - val_accuracy: 0.7966\n",
      "Epoch 1704/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2024 - accuracy: 0.9118 - val_loss: 0.3997 - val_accuracy: 0.7966\n",
      "Epoch 1705/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2024 - accuracy: 0.9118 - val_loss: 0.3997 - val_accuracy: 0.7966\n",
      "Epoch 1706/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2024 - accuracy: 0.9118 - val_loss: 0.3997 - val_accuracy: 0.7966\n",
      "Epoch 1707/4000\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.1961 - accuracy: 0.93 - 0s 52us/step - loss: 0.2024 - accuracy: 0.9118 - val_loss: 0.3997 - val_accuracy: 0.7966\n",
      "Epoch 1708/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2024 - accuracy: 0.9118 - val_loss: 0.3997 - val_accuracy: 0.7966\n",
      "Epoch 1709/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2023 - accuracy: 0.9118 - val_loss: 0.3997 - val_accuracy: 0.7966\n",
      "Epoch 1710/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2023 - accuracy: 0.9118 - val_loss: 0.3998 - val_accuracy: 0.7966\n",
      "Epoch 1711/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2023 - accuracy: 0.9118 - val_loss: 0.3998 - val_accuracy: 0.7966\n",
      "Epoch 1712/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2023 - accuracy: 0.9118 - val_loss: 0.3998 - val_accuracy: 0.7966\n",
      "Epoch 1713/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2022 - accuracy: 0.9118 - val_loss: 0.3998 - val_accuracy: 0.7966\n",
      "Epoch 1714/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2022 - accuracy: 0.9118 - val_loss: 0.3998 - val_accuracy: 0.7966\n",
      "Epoch 1715/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2022 - accuracy: 0.9118 - val_loss: 0.3999 - val_accuracy: 0.7966\n",
      "Epoch 1716/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2022 - accuracy: 0.9118 - val_loss: 0.3999 - val_accuracy: 0.7966\n",
      "Epoch 1717/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2021 - accuracy: 0.9118 - val_loss: 0.3999 - val_accuracy: 0.7966\n",
      "Epoch 1718/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2021 - accuracy: 0.9118 - val_loss: 0.3999 - val_accuracy: 0.7966\n",
      "Epoch 1719/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2021 - accuracy: 0.9118 - val_loss: 0.3999 - val_accuracy: 0.7966\n",
      "Epoch 1720/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2021 - accuracy: 0.9118 - val_loss: 0.3999 - val_accuracy: 0.7966\n",
      "Epoch 1721/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2020 - accuracy: 0.9118 - val_loss: 0.4000 - val_accuracy: 0.7966\n",
      "Epoch 1722/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2020 - accuracy: 0.9118 - val_loss: 0.4000 - val_accuracy: 0.7966\n",
      "Epoch 1723/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2020 - accuracy: 0.9118 - val_loss: 0.4000 - val_accuracy: 0.7966\n",
      "Epoch 1724/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2020 - accuracy: 0.9118 - val_loss: 0.4000 - val_accuracy: 0.7966\n",
      "Epoch 1725/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2020 - accuracy: 0.9118 - val_loss: 0.4000 - val_accuracy: 0.7966\n",
      "Epoch 1726/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2019 - accuracy: 0.9118 - val_loss: 0.4000 - val_accuracy: 0.7966\n",
      "Epoch 1727/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2019 - accuracy: 0.9118 - val_loss: 0.4001 - val_accuracy: 0.7966\n",
      "Epoch 1728/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2019 - accuracy: 0.9118 - val_loss: 0.4001 - val_accuracy: 0.7966\n",
      "Epoch 1729/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2019 - accuracy: 0.9118 - val_loss: 0.4001 - val_accuracy: 0.7966\n",
      "Epoch 1730/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2018 - accuracy: 0.9118 - val_loss: 0.4001 - val_accuracy: 0.7966\n",
      "Epoch 1731/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2018 - accuracy: 0.9118 - val_loss: 0.4001 - val_accuracy: 0.7966\n",
      "Epoch 1732/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2018 - accuracy: 0.9118 - val_loss: 0.4002 - val_accuracy: 0.7966\n",
      "Epoch 1733/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2018 - accuracy: 0.9118 - val_loss: 0.4002 - val_accuracy: 0.7966\n",
      "Epoch 1734/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2018 - accuracy: 0.9118 - val_loss: 0.4002 - val_accuracy: 0.7966\n",
      "Epoch 1735/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2017 - accuracy: 0.9118 - val_loss: 0.4002 - val_accuracy: 0.7966\n",
      "Epoch 1736/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2017 - accuracy: 0.9118 - val_loss: 0.4002 - val_accuracy: 0.7966\n",
      "Epoch 1737/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2017 - accuracy: 0.9118 - val_loss: 0.4002 - val_accuracy: 0.7966\n",
      "Epoch 1738/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2017 - accuracy: 0.9118 - val_loss: 0.4003 - val_accuracy: 0.7966\n",
      "Epoch 1739/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2016 - accuracy: 0.9118 - val_loss: 0.4003 - val_accuracy: 0.7966\n",
      "Epoch 1740/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2016 - accuracy: 0.9118 - val_loss: 0.4003 - val_accuracy: 0.7966\n",
      "Epoch 1741/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2016 - accuracy: 0.9118 - val_loss: 0.4003 - val_accuracy: 0.7966\n",
      "Epoch 1742/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2016 - accuracy: 0.9118 - val_loss: 0.4003 - val_accuracy: 0.7966\n",
      "Epoch 1743/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2015 - accuracy: 0.9118 - val_loss: 0.4003 - val_accuracy: 0.7966\n",
      "Epoch 1744/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2015 - accuracy: 0.9118 - val_loss: 0.4004 - val_accuracy: 0.7966\n",
      "Epoch 1745/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2015 - accuracy: 0.9118 - val_loss: 0.4004 - val_accuracy: 0.7966\n",
      "Epoch 1746/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2015 - accuracy: 0.9118 - val_loss: 0.4004 - val_accuracy: 0.7966\n",
      "Epoch 1747/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2015 - accuracy: 0.9118 - val_loss: 0.4004 - val_accuracy: 0.7966\n",
      "Epoch 1748/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2014 - accuracy: 0.9118 - val_loss: 0.4004 - val_accuracy: 0.7966\n",
      "Epoch 1749/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2014 - accuracy: 0.9118 - val_loss: 0.4005 - val_accuracy: 0.7966\n",
      "Epoch 1750/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2014 - accuracy: 0.9118 - val_loss: 0.4005 - val_accuracy: 0.7966\n",
      "Epoch 1751/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2014 - accuracy: 0.9118 - val_loss: 0.4005 - val_accuracy: 0.7966\n",
      "Epoch 1752/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2013 - accuracy: 0.9118 - val_loss: 0.4005 - val_accuracy: 0.7966\n",
      "Epoch 1753/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2013 - accuracy: 0.9118 - val_loss: 0.4005 - val_accuracy: 0.7966\n",
      "Epoch 1754/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2013 - accuracy: 0.9118 - val_loss: 0.4005 - val_accuracy: 0.7966\n",
      "Epoch 1755/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2013 - accuracy: 0.9118 - val_loss: 0.4006 - val_accuracy: 0.7966\n",
      "Epoch 1756/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2013 - accuracy: 0.9118 - val_loss: 0.4006 - val_accuracy: 0.7966\n",
      "Epoch 1757/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2012 - accuracy: 0.9118 - val_loss: 0.4006 - val_accuracy: 0.7966\n",
      "Epoch 1758/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2012 - accuracy: 0.9118 - val_loss: 0.4006 - val_accuracy: 0.7966\n",
      "Epoch 1759/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2012 - accuracy: 0.9118 - val_loss: 0.4006 - val_accuracy: 0.7966\n",
      "Epoch 1760/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2012 - accuracy: 0.9118 - val_loss: 0.4007 - val_accuracy: 0.7966\n",
      "Epoch 1761/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2011 - accuracy: 0.9118 - val_loss: 0.4007 - val_accuracy: 0.7966\n",
      "Epoch 1762/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2011 - accuracy: 0.9118 - val_loss: 0.4007 - val_accuracy: 0.7966\n",
      "Epoch 1763/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2011 - accuracy: 0.9118 - val_loss: 0.4007 - val_accuracy: 0.7966\n",
      "Epoch 1764/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2011 - accuracy: 0.9118 - val_loss: 0.4007 - val_accuracy: 0.7966\n",
      "Epoch 1765/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2011 - accuracy: 0.9118 - val_loss: 0.4008 - val_accuracy: 0.7966\n",
      "Epoch 1766/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2010 - accuracy: 0.9118 - val_loss: 0.4008 - val_accuracy: 0.7966\n",
      "Epoch 1767/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2010 - accuracy: 0.9118 - val_loss: 0.4008 - val_accuracy: 0.7966\n",
      "Epoch 1768/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2010 - accuracy: 0.9118 - val_loss: 0.4008 - val_accuracy: 0.7966\n",
      "Epoch 1769/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2010 - accuracy: 0.9118 - val_loss: 0.4008 - val_accuracy: 0.7966\n",
      "Epoch 1770/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2009 - accuracy: 0.9118 - val_loss: 0.4008 - val_accuracy: 0.7966\n",
      "Epoch 1771/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2009 - accuracy: 0.9118 - val_loss: 0.4009 - val_accuracy: 0.7966\n",
      "Epoch 1772/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2009 - accuracy: 0.9118 - val_loss: 0.4009 - val_accuracy: 0.7966\n",
      "Epoch 1773/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2009 - accuracy: 0.9118 - val_loss: 0.4009 - val_accuracy: 0.7966\n",
      "Epoch 1774/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2009 - accuracy: 0.9118 - val_loss: 0.4009 - val_accuracy: 0.7966\n",
      "Epoch 1775/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2008 - accuracy: 0.9118 - val_loss: 0.4009 - val_accuracy: 0.7966\n",
      "Epoch 1776/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2008 - accuracy: 0.9118 - val_loss: 0.4010 - val_accuracy: 0.7966\n",
      "Epoch 1777/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2008 - accuracy: 0.9118 - val_loss: 0.4010 - val_accuracy: 0.7966\n",
      "Epoch 1778/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2008 - accuracy: 0.9118 - val_loss: 0.4010 - val_accuracy: 0.7966\n",
      "Epoch 1779/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2007 - accuracy: 0.9118 - val_loss: 0.4010 - val_accuracy: 0.7966\n",
      "Epoch 1780/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2007 - accuracy: 0.9118 - val_loss: 0.4010 - val_accuracy: 0.7966\n",
      "Epoch 1781/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.2007 - accuracy: 0.9118 - val_loss: 0.4011 - val_accuracy: 0.7966\n",
      "Epoch 1782/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2007 - accuracy: 0.9118 - val_loss: 0.4011 - val_accuracy: 0.7966\n",
      "Epoch 1783/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2007 - accuracy: 0.9118 - val_loss: 0.4011 - val_accuracy: 0.7966\n",
      "Epoch 1784/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2006 - accuracy: 0.9118 - val_loss: 0.4011 - val_accuracy: 0.7966\n",
      "Epoch 1785/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2006 - accuracy: 0.9118 - val_loss: 0.4011 - val_accuracy: 0.7966\n",
      "Epoch 1786/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2006 - accuracy: 0.9118 - val_loss: 0.4011 - val_accuracy: 0.7966\n",
      "Epoch 1787/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2006 - accuracy: 0.9118 - val_loss: 0.4012 - val_accuracy: 0.7966\n",
      "Epoch 1788/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2006 - accuracy: 0.9118 - val_loss: 0.4012 - val_accuracy: 0.7966\n",
      "Epoch 1789/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2005 - accuracy: 0.9118 - val_loss: 0.4012 - val_accuracy: 0.7966\n",
      "Epoch 1790/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2005 - accuracy: 0.9118 - val_loss: 0.4012 - val_accuracy: 0.7966\n",
      "Epoch 1791/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.2005 - accuracy: 0.9118 - val_loss: 0.4012 - val_accuracy: 0.7966\n",
      "Epoch 1792/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2005 - accuracy: 0.9118 - val_loss: 0.4012 - val_accuracy: 0.7966\n",
      "Epoch 1793/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2004 - accuracy: 0.9118 - val_loss: 0.4013 - val_accuracy: 0.7966\n",
      "Epoch 1794/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2004 - accuracy: 0.9118 - val_loss: 0.4013 - val_accuracy: 0.7966\n",
      "Epoch 1795/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2004 - accuracy: 0.9118 - val_loss: 0.4013 - val_accuracy: 0.7966\n",
      "Epoch 1796/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2004 - accuracy: 0.9118 - val_loss: 0.4013 - val_accuracy: 0.7966\n",
      "Epoch 1797/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2004 - accuracy: 0.9118 - val_loss: 0.4014 - val_accuracy: 0.7966\n",
      "Epoch 1798/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2003 - accuracy: 0.9118 - val_loss: 0.4014 - val_accuracy: 0.7966\n",
      "Epoch 1799/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2003 - accuracy: 0.9118 - val_loss: 0.4014 - val_accuracy: 0.7966\n",
      "Epoch 1800/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2003 - accuracy: 0.9118 - val_loss: 0.4014 - val_accuracy: 0.7966\n",
      "Epoch 1801/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2003 - accuracy: 0.9118 - val_loss: 0.4014 - val_accuracy: 0.7966\n",
      "Epoch 1802/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2003 - accuracy: 0.9118 - val_loss: 0.4014 - val_accuracy: 0.7966\n",
      "Epoch 1803/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2002 - accuracy: 0.9118 - val_loss: 0.4015 - val_accuracy: 0.7966\n",
      "Epoch 1804/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2002 - accuracy: 0.9118 - val_loss: 0.4015 - val_accuracy: 0.7966\n",
      "Epoch 1805/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2002 - accuracy: 0.9118 - val_loss: 0.4015 - val_accuracy: 0.7966\n",
      "Epoch 1806/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2002 - accuracy: 0.9118 - val_loss: 0.4015 - val_accuracy: 0.7966\n",
      "Epoch 1807/4000\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.1939 - accuracy: 0.93 - 0s 59us/step - loss: 0.2001 - accuracy: 0.9118 - val_loss: 0.4015 - val_accuracy: 0.7966\n",
      "Epoch 1808/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2001 - accuracy: 0.9118 - val_loss: 0.4016 - val_accuracy: 0.7966\n",
      "Epoch 1809/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2001 - accuracy: 0.9118 - val_loss: 0.4016 - val_accuracy: 0.7966\n",
      "Epoch 1810/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2001 - accuracy: 0.9118 - val_loss: 0.4016 - val_accuracy: 0.7966\n",
      "Epoch 1811/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.2001 - accuracy: 0.9118 - val_loss: 0.4016 - val_accuracy: 0.7966\n",
      "Epoch 1812/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2000 - accuracy: 0.9118 - val_loss: 0.4016 - val_accuracy: 0.7966\n",
      "Epoch 1813/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.2000 - accuracy: 0.9118 - val_loss: 0.4017 - val_accuracy: 0.7966\n",
      "Epoch 1814/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2000 - accuracy: 0.9118 - val_loss: 0.4017 - val_accuracy: 0.7966\n",
      "Epoch 1815/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.2000 - accuracy: 0.9118 - val_loss: 0.4017 - val_accuracy: 0.7966\n",
      "Epoch 1816/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.2000 - accuracy: 0.9118 - val_loss: 0.4017 - val_accuracy: 0.7966\n",
      "Epoch 1817/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1999 - accuracy: 0.9118 - val_loss: 0.4017 - val_accuracy: 0.7966\n",
      "Epoch 1818/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1999 - accuracy: 0.9118 - val_loss: 0.4017 - val_accuracy: 0.7966\n",
      "Epoch 1819/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1999 - accuracy: 0.9118 - val_loss: 0.4018 - val_accuracy: 0.7966\n",
      "Epoch 1820/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1999 - accuracy: 0.9118 - val_loss: 0.4018 - val_accuracy: 0.7966\n",
      "Epoch 1821/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1999 - accuracy: 0.9118 - val_loss: 0.4018 - val_accuracy: 0.7966\n",
      "Epoch 1822/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1998 - accuracy: 0.9118 - val_loss: 0.4018 - val_accuracy: 0.7966\n",
      "Epoch 1823/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1998 - accuracy: 0.9118 - val_loss: 0.4018 - val_accuracy: 0.7966\n",
      "Epoch 1824/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1998 - accuracy: 0.9118 - val_loss: 0.4019 - val_accuracy: 0.7966\n",
      "Epoch 1825/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1998 - accuracy: 0.9118 - val_loss: 0.4019 - val_accuracy: 0.7966\n",
      "Epoch 1826/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1997 - accuracy: 0.9118 - val_loss: 0.4019 - val_accuracy: 0.7966\n",
      "Epoch 1827/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1997 - accuracy: 0.9118 - val_loss: 0.4019 - val_accuracy: 0.7966\n",
      "Epoch 1828/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1997 - accuracy: 0.9118 - val_loss: 0.4019 - val_accuracy: 0.7966\n",
      "Epoch 1829/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1997 - accuracy: 0.9118 - val_loss: 0.4020 - val_accuracy: 0.7966\n",
      "Epoch 1830/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1997 - accuracy: 0.9118 - val_loss: 0.4020 - val_accuracy: 0.7966\n",
      "Epoch 1831/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1996 - accuracy: 0.9118 - val_loss: 0.4020 - val_accuracy: 0.7966\n",
      "Epoch 1832/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1996 - accuracy: 0.9118 - val_loss: 0.4020 - val_accuracy: 0.7966\n",
      "Epoch 1833/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1996 - accuracy: 0.9118 - val_loss: 0.4020 - val_accuracy: 0.7966\n",
      "Epoch 1834/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1996 - accuracy: 0.9118 - val_loss: 0.4021 - val_accuracy: 0.7966\n",
      "Epoch 1835/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1996 - accuracy: 0.9118 - val_loss: 0.4021 - val_accuracy: 0.7966\n",
      "Epoch 1836/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1995 - accuracy: 0.9118 - val_loss: 0.4021 - val_accuracy: 0.7966\n",
      "Epoch 1837/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1995 - accuracy: 0.9118 - val_loss: 0.4021 - val_accuracy: 0.7966\n",
      "Epoch 1838/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1995 - accuracy: 0.9118 - val_loss: 0.4021 - val_accuracy: 0.7966\n",
      "Epoch 1839/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1995 - accuracy: 0.9118 - val_loss: 0.4021 - val_accuracy: 0.7966\n",
      "Epoch 1840/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1995 - accuracy: 0.9118 - val_loss: 0.4022 - val_accuracy: 0.7966\n",
      "Epoch 1841/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1994 - accuracy: 0.9118 - val_loss: 0.4022 - val_accuracy: 0.7966\n",
      "Epoch 1842/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1994 - accuracy: 0.9118 - val_loss: 0.4022 - val_accuracy: 0.7966\n",
      "Epoch 1843/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1994 - accuracy: 0.9118 - val_loss: 0.4022 - val_accuracy: 0.7966\n",
      "Epoch 1844/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1994 - accuracy: 0.9118 - val_loss: 0.4022 - val_accuracy: 0.7966\n",
      "Epoch 1845/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1994 - accuracy: 0.9118 - val_loss: 0.4023 - val_accuracy: 0.7966\n",
      "Epoch 1846/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1993 - accuracy: 0.9118 - val_loss: 0.4023 - val_accuracy: 0.7966\n",
      "Epoch 1847/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1993 - accuracy: 0.9118 - val_loss: 0.4023 - val_accuracy: 0.7966\n",
      "Epoch 1848/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1993 - accuracy: 0.9118 - val_loss: 0.4023 - val_accuracy: 0.7966\n",
      "Epoch 1849/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1993 - accuracy: 0.9118 - val_loss: 0.4023 - val_accuracy: 0.7966\n",
      "Epoch 1850/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1993 - accuracy: 0.9118 - val_loss: 0.4024 - val_accuracy: 0.7966\n",
      "Epoch 1851/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1992 - accuracy: 0.9118 - val_loss: 0.4024 - val_accuracy: 0.7966\n",
      "Epoch 1852/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1992 - accuracy: 0.9118 - val_loss: 0.4024 - val_accuracy: 0.7966\n",
      "Epoch 1853/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1992 - accuracy: 0.9118 - val_loss: 0.4024 - val_accuracy: 0.7966\n",
      "Epoch 1854/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1992 - accuracy: 0.9118 - val_loss: 0.4024 - val_accuracy: 0.7966\n",
      "Epoch 1855/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1992 - accuracy: 0.9118 - val_loss: 0.4024 - val_accuracy: 0.7966\n",
      "Epoch 1856/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1991 - accuracy: 0.9118 - val_loss: 0.4025 - val_accuracy: 0.7966\n",
      "Epoch 1857/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1991 - accuracy: 0.9118 - val_loss: 0.4025 - val_accuracy: 0.7966\n",
      "Epoch 1858/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1991 - accuracy: 0.9118 - val_loss: 0.4025 - val_accuracy: 0.7966\n",
      "Epoch 1859/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1991 - accuracy: 0.9118 - val_loss: 0.4025 - val_accuracy: 0.7966\n",
      "Epoch 1860/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1990 - accuracy: 0.9118 - val_loss: 0.4025 - val_accuracy: 0.7966\n",
      "Epoch 1861/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1990 - accuracy: 0.9118 - val_loss: 0.4026 - val_accuracy: 0.7966\n",
      "Epoch 1862/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1990 - accuracy: 0.9118 - val_loss: 0.4026 - val_accuracy: 0.7966\n",
      "Epoch 1863/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1990 - accuracy: 0.9118 - val_loss: 0.4026 - val_accuracy: 0.7966\n",
      "Epoch 1864/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1990 - accuracy: 0.9118 - val_loss: 0.4026 - val_accuracy: 0.7966\n",
      "Epoch 1865/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1989 - accuracy: 0.9118 - val_loss: 0.4026 - val_accuracy: 0.7966\n",
      "Epoch 1866/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1989 - accuracy: 0.9118 - val_loss: 0.4027 - val_accuracy: 0.7966\n",
      "Epoch 1867/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1989 - accuracy: 0.9118 - val_loss: 0.4027 - val_accuracy: 0.7966\n",
      "Epoch 1868/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1989 - accuracy: 0.9118 - val_loss: 0.4027 - val_accuracy: 0.7966\n",
      "Epoch 1869/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1989 - accuracy: 0.9118 - val_loss: 0.4027 - val_accuracy: 0.7966\n",
      "Epoch 1870/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1988 - accuracy: 0.9118 - val_loss: 0.4027 - val_accuracy: 0.7966\n",
      "Epoch 1871/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1988 - accuracy: 0.9118 - val_loss: 0.4028 - val_accuracy: 0.7966\n",
      "Epoch 1872/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1988 - accuracy: 0.9118 - val_loss: 0.4028 - val_accuracy: 0.7966\n",
      "Epoch 1873/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1988 - accuracy: 0.9118 - val_loss: 0.4028 - val_accuracy: 0.7966\n",
      "Epoch 1874/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1988 - accuracy: 0.9118 - val_loss: 0.4028 - val_accuracy: 0.7966\n",
      "Epoch 1875/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1987 - accuracy: 0.9118 - val_loss: 0.4028 - val_accuracy: 0.7966\n",
      "Epoch 1876/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1987 - accuracy: 0.9118 - val_loss: 0.4029 - val_accuracy: 0.7966\n",
      "Epoch 1877/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1987 - accuracy: 0.9118 - val_loss: 0.4029 - val_accuracy: 0.7966\n",
      "Epoch 1878/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1987 - accuracy: 0.9118 - val_loss: 0.4029 - val_accuracy: 0.7966\n",
      "Epoch 1879/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1987 - accuracy: 0.9118 - val_loss: 0.4029 - val_accuracy: 0.7966\n",
      "Epoch 1880/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1986 - accuracy: 0.9118 - val_loss: 0.4029 - val_accuracy: 0.7966\n",
      "Epoch 1881/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1986 - accuracy: 0.9118 - val_loss: 0.4030 - val_accuracy: 0.7966\n",
      "Epoch 1882/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1986 - accuracy: 0.9118 - val_loss: 0.4030 - val_accuracy: 0.7966\n",
      "Epoch 1883/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1986 - accuracy: 0.9118 - val_loss: 0.4030 - val_accuracy: 0.7966\n",
      "Epoch 1884/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1986 - accuracy: 0.9118 - val_loss: 0.4030 - val_accuracy: 0.7966\n",
      "Epoch 1885/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1985 - accuracy: 0.9118 - val_loss: 0.4030 - val_accuracy: 0.7966\n",
      "Epoch 1886/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1985 - accuracy: 0.9118 - val_loss: 0.4031 - val_accuracy: 0.7966\n",
      "Epoch 1887/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1985 - accuracy: 0.9118 - val_loss: 0.4031 - val_accuracy: 0.7966\n",
      "Epoch 1888/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1985 - accuracy: 0.9118 - val_loss: 0.4031 - val_accuracy: 0.7966\n",
      "Epoch 1889/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1985 - accuracy: 0.9118 - val_loss: 0.4031 - val_accuracy: 0.7966\n",
      "Epoch 1890/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1984 - accuracy: 0.9118 - val_loss: 0.4031 - val_accuracy: 0.7966\n",
      "Epoch 1891/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1984 - accuracy: 0.9118 - val_loss: 0.4032 - val_accuracy: 0.7966\n",
      "Epoch 1892/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1984 - accuracy: 0.9118 - val_loss: 0.4032 - val_accuracy: 0.7966\n",
      "Epoch 1893/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1984 - accuracy: 0.9118 - val_loss: 0.4032 - val_accuracy: 0.7966\n",
      "Epoch 1894/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1984 - accuracy: 0.9118 - val_loss: 0.4032 - val_accuracy: 0.7966\n",
      "Epoch 1895/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1984 - accuracy: 0.9118 - val_loss: 0.4032 - val_accuracy: 0.7966\n",
      "Epoch 1896/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1983 - accuracy: 0.9118 - val_loss: 0.4033 - val_accuracy: 0.7966\n",
      "Epoch 1897/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1983 - accuracy: 0.9118 - val_loss: 0.4033 - val_accuracy: 0.7966\n",
      "Epoch 1898/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1983 - accuracy: 0.9118 - val_loss: 0.4033 - val_accuracy: 0.7966\n",
      "Epoch 1899/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1983 - accuracy: 0.9118 - val_loss: 0.4033 - val_accuracy: 0.7966\n",
      "Epoch 1900/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1983 - accuracy: 0.9118 - val_loss: 0.4033 - val_accuracy: 0.7966\n",
      "Epoch 1901/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1982 - accuracy: 0.9118 - val_loss: 0.4034 - val_accuracy: 0.7966\n",
      "Epoch 1902/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1982 - accuracy: 0.9118 - val_loss: 0.4034 - val_accuracy: 0.7966\n",
      "Epoch 1903/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1982 - accuracy: 0.9118 - val_loss: 0.4034 - val_accuracy: 0.7966\n",
      "Epoch 1904/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1982 - accuracy: 0.9118 - val_loss: 0.4034 - val_accuracy: 0.7966\n",
      "Epoch 1905/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1982 - accuracy: 0.9118 - val_loss: 0.4034 - val_accuracy: 0.7966\n",
      "Epoch 1906/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1981 - accuracy: 0.9118 - val_loss: 0.4035 - val_accuracy: 0.7966\n",
      "Epoch 1907/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1981 - accuracy: 0.9118 - val_loss: 0.4035 - val_accuracy: 0.7966\n",
      "Epoch 1908/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1981 - accuracy: 0.9118 - val_loss: 0.4035 - val_accuracy: 0.7966\n",
      "Epoch 1909/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1981 - accuracy: 0.9118 - val_loss: 0.4035 - val_accuracy: 0.7966\n",
      "Epoch 1910/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1981 - accuracy: 0.9118 - val_loss: 0.4035 - val_accuracy: 0.7966\n",
      "Epoch 1911/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1980 - accuracy: 0.9118 - val_loss: 0.4036 - val_accuracy: 0.7966\n",
      "Epoch 1912/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1980 - accuracy: 0.9118 - val_loss: 0.4036 - val_accuracy: 0.7966\n",
      "Epoch 1913/4000\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.1919 - accuracy: 0.93 - 0s 66us/step - loss: 0.1980 - accuracy: 0.9118 - val_loss: 0.4036 - val_accuracy: 0.7966\n",
      "Epoch 1914/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1980 - accuracy: 0.9118 - val_loss: 0.4036 - val_accuracy: 0.7966\n",
      "Epoch 1915/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1980 - accuracy: 0.9118 - val_loss: 0.4036 - val_accuracy: 0.7966\n",
      "Epoch 1916/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1979 - accuracy: 0.9118 - val_loss: 0.4037 - val_accuracy: 0.7966\n",
      "Epoch 1917/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1979 - accuracy: 0.9118 - val_loss: 0.4037 - val_accuracy: 0.7966\n",
      "Epoch 1918/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1979 - accuracy: 0.9118 - val_loss: 0.4037 - val_accuracy: 0.7966\n",
      "Epoch 1919/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1979 - accuracy: 0.9118 - val_loss: 0.4037 - val_accuracy: 0.7966\n",
      "Epoch 1920/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1979 - accuracy: 0.9118 - val_loss: 0.4037 - val_accuracy: 0.7966\n",
      "Epoch 1921/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1978 - accuracy: 0.9118 - val_loss: 0.4038 - val_accuracy: 0.7966\n",
      "Epoch 1922/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1978 - accuracy: 0.9118 - val_loss: 0.4038 - val_accuracy: 0.7966\n",
      "Epoch 1923/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1978 - accuracy: 0.9118 - val_loss: 0.4038 - val_accuracy: 0.7966\n",
      "Epoch 1924/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1978 - accuracy: 0.9118 - val_loss: 0.4038 - val_accuracy: 0.7966\n",
      "Epoch 1925/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1978 - accuracy: 0.9118 - val_loss: 0.4038 - val_accuracy: 0.7966\n",
      "Epoch 1926/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1978 - accuracy: 0.9118 - val_loss: 0.4038 - val_accuracy: 0.7966\n",
      "Epoch 1927/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1977 - accuracy: 0.9118 - val_loss: 0.4039 - val_accuracy: 0.7966\n",
      "Epoch 1928/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1977 - accuracy: 0.9118 - val_loss: 0.4039 - val_accuracy: 0.7966\n",
      "Epoch 1929/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1977 - accuracy: 0.9118 - val_loss: 0.4039 - val_accuracy: 0.7966\n",
      "Epoch 1930/4000\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.1916 - accuracy: 0.93 - 0s 59us/step - loss: 0.1977 - accuracy: 0.9118 - val_loss: 0.4039 - val_accuracy: 0.7966\n",
      "Epoch 1931/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1977 - accuracy: 0.9118 - val_loss: 0.4039 - val_accuracy: 0.7966\n",
      "Epoch 1932/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1976 - accuracy: 0.9118 - val_loss: 0.4039 - val_accuracy: 0.7966\n",
      "Epoch 1933/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1976 - accuracy: 0.9118 - val_loss: 0.4040 - val_accuracy: 0.7966\n",
      "Epoch 1934/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1976 - accuracy: 0.9118 - val_loss: 0.4040 - val_accuracy: 0.7966\n",
      "Epoch 1935/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1976 - accuracy: 0.9118 - val_loss: 0.4040 - val_accuracy: 0.7966\n",
      "Epoch 1936/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1976 - accuracy: 0.9118 - val_loss: 0.4040 - val_accuracy: 0.7966\n",
      "Epoch 1937/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1975 - accuracy: 0.9118 - val_loss: 0.4040 - val_accuracy: 0.7966\n",
      "Epoch 1938/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1975 - accuracy: 0.9118 - val_loss: 0.4040 - val_accuracy: 0.7966\n",
      "Epoch 1939/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1975 - accuracy: 0.9118 - val_loss: 0.4040 - val_accuracy: 0.7966\n",
      "Epoch 1940/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1975 - accuracy: 0.9118 - val_loss: 0.4041 - val_accuracy: 0.7966\n",
      "Epoch 1941/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1975 - accuracy: 0.9118 - val_loss: 0.4041 - val_accuracy: 0.7966\n",
      "Epoch 1942/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1974 - accuracy: 0.9118 - val_loss: 0.4041 - val_accuracy: 0.7966\n",
      "Epoch 1943/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1974 - accuracy: 0.9118 - val_loss: 0.4041 - val_accuracy: 0.7966\n",
      "Epoch 1944/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1974 - accuracy: 0.9118 - val_loss: 0.4041 - val_accuracy: 0.7966\n",
      "Epoch 1945/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1974 - accuracy: 0.9118 - val_loss: 0.4042 - val_accuracy: 0.7966\n",
      "Epoch 1946/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1974 - accuracy: 0.9118 - val_loss: 0.4042 - val_accuracy: 0.7966\n",
      "Epoch 1947/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1973 - accuracy: 0.9118 - val_loss: 0.4042 - val_accuracy: 0.7966\n",
      "Epoch 1948/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1973 - accuracy: 0.9118 - val_loss: 0.4042 - val_accuracy: 0.7966\n",
      "Epoch 1949/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1973 - accuracy: 0.9118 - val_loss: 0.4042 - val_accuracy: 0.7966\n",
      "Epoch 1950/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1973 - accuracy: 0.9118 - val_loss: 0.4042 - val_accuracy: 0.7966\n",
      "Epoch 1951/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1973 - accuracy: 0.9118 - val_loss: 0.4042 - val_accuracy: 0.7966\n",
      "Epoch 1952/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1972 - accuracy: 0.9118 - val_loss: 0.4043 - val_accuracy: 0.7966\n",
      "Epoch 1953/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1972 - accuracy: 0.9118 - val_loss: 0.4043 - val_accuracy: 0.7966\n",
      "Epoch 1954/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1972 - accuracy: 0.9118 - val_loss: 0.4043 - val_accuracy: 0.7966\n",
      "Epoch 1955/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1972 - accuracy: 0.9118 - val_loss: 0.4043 - val_accuracy: 0.7966\n",
      "Epoch 1956/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1972 - accuracy: 0.9118 - val_loss: 0.4043 - val_accuracy: 0.7966\n",
      "Epoch 1957/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1971 - accuracy: 0.9118 - val_loss: 0.4043 - val_accuracy: 0.7966\n",
      "Epoch 1958/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1971 - accuracy: 0.9118 - val_loss: 0.4044 - val_accuracy: 0.7966\n",
      "Epoch 1959/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1971 - accuracy: 0.9118 - val_loss: 0.4044 - val_accuracy: 0.7966\n",
      "Epoch 1960/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1971 - accuracy: 0.9118 - val_loss: 0.4044 - val_accuracy: 0.7966\n",
      "Epoch 1961/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1971 - accuracy: 0.9118 - val_loss: 0.4044 - val_accuracy: 0.7966\n",
      "Epoch 1962/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1971 - accuracy: 0.9118 - val_loss: 0.4044 - val_accuracy: 0.7966\n",
      "Epoch 1963/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1970 - accuracy: 0.9118 - val_loss: 0.4044 - val_accuracy: 0.7966\n",
      "Epoch 1964/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1970 - accuracy: 0.9118 - val_loss: 0.4045 - val_accuracy: 0.7966\n",
      "Epoch 1965/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1970 - accuracy: 0.9118 - val_loss: 0.4045 - val_accuracy: 0.7966\n",
      "Epoch 1966/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1970 - accuracy: 0.9118 - val_loss: 0.4045 - val_accuracy: 0.7966\n",
      "Epoch 1967/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1970 - accuracy: 0.9118 - val_loss: 0.4045 - val_accuracy: 0.7966\n",
      "Epoch 1968/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1969 - accuracy: 0.9118 - val_loss: 0.4045 - val_accuracy: 0.7966\n",
      "Epoch 1969/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1969 - accuracy: 0.9118 - val_loss: 0.4045 - val_accuracy: 0.7966\n",
      "Epoch 1970/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1969 - accuracy: 0.9118 - val_loss: 0.4046 - val_accuracy: 0.7966\n",
      "Epoch 1971/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1969 - accuracy: 0.9118 - val_loss: 0.4046 - val_accuracy: 0.7966\n",
      "Epoch 1972/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1969 - accuracy: 0.9118 - val_loss: 0.4046 - val_accuracy: 0.7966\n",
      "Epoch 1973/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1968 - accuracy: 0.9118 - val_loss: 0.4046 - val_accuracy: 0.7966\n",
      "Epoch 1974/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1968 - accuracy: 0.9118 - val_loss: 0.4046 - val_accuracy: 0.7966\n",
      "Epoch 1975/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1968 - accuracy: 0.9118 - val_loss: 0.4046 - val_accuracy: 0.7966\n",
      "Epoch 1976/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1968 - accuracy: 0.9118 - val_loss: 0.4047 - val_accuracy: 0.7966\n",
      "Epoch 1977/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1968 - accuracy: 0.9118 - val_loss: 0.4047 - val_accuracy: 0.7966\n",
      "Epoch 1978/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1968 - accuracy: 0.9118 - val_loss: 0.4047 - val_accuracy: 0.7966\n",
      "Epoch 1979/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1967 - accuracy: 0.9118 - val_loss: 0.4047 - val_accuracy: 0.7966\n",
      "Epoch 1980/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1967 - accuracy: 0.9118 - val_loss: 0.4047 - val_accuracy: 0.7966\n",
      "Epoch 1981/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1967 - accuracy: 0.9118 - val_loss: 0.4047 - val_accuracy: 0.7966\n",
      "Epoch 1982/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1967 - accuracy: 0.9118 - val_loss: 0.4048 - val_accuracy: 0.7966\n",
      "Epoch 1983/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1967 - accuracy: 0.9118 - val_loss: 0.4048 - val_accuracy: 0.7966\n",
      "Epoch 1984/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1966 - accuracy: 0.9118 - val_loss: 0.4048 - val_accuracy: 0.7966\n",
      "Epoch 1985/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1966 - accuracy: 0.9118 - val_loss: 0.4048 - val_accuracy: 0.7966\n",
      "Epoch 1986/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1966 - accuracy: 0.9118 - val_loss: 0.4048 - val_accuracy: 0.7966\n",
      "Epoch 1987/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1966 - accuracy: 0.9118 - val_loss: 0.4048 - val_accuracy: 0.7966\n",
      "Epoch 1988/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1966 - accuracy: 0.9118 - val_loss: 0.4049 - val_accuracy: 0.7966\n",
      "Epoch 1989/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1965 - accuracy: 0.9118 - val_loss: 0.4049 - val_accuracy: 0.7966\n",
      "Epoch 1990/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1965 - accuracy: 0.9118 - val_loss: 0.4049 - val_accuracy: 0.7966\n",
      "Epoch 1991/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1965 - accuracy: 0.9118 - val_loss: 0.4049 - val_accuracy: 0.7966\n",
      "Epoch 1992/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1965 - accuracy: 0.9118 - val_loss: 0.4049 - val_accuracy: 0.7966\n",
      "Epoch 1993/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1965 - accuracy: 0.9118 - val_loss: 0.4049 - val_accuracy: 0.7966\n",
      "Epoch 1994/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1965 - accuracy: 0.9118 - val_loss: 0.4050 - val_accuracy: 0.7966\n",
      "Epoch 1995/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1964 - accuracy: 0.9118 - val_loss: 0.4050 - val_accuracy: 0.7966\n",
      "Epoch 1996/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1964 - accuracy: 0.9118 - val_loss: 0.4050 - val_accuracy: 0.7966\n",
      "Epoch 1997/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1964 - accuracy: 0.9118 - val_loss: 0.4050 - val_accuracy: 0.7966\n",
      "Epoch 1998/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1964 - accuracy: 0.9118 - val_loss: 0.4050 - val_accuracy: 0.7966\n",
      "Epoch 1999/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1964 - accuracy: 0.9118 - val_loss: 0.4050 - val_accuracy: 0.7966\n",
      "Epoch 2000/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1963 - accuracy: 0.9118 - val_loss: 0.4051 - val_accuracy: 0.7966\n",
      "Epoch 2001/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1963 - accuracy: 0.9118 - val_loss: 0.4051 - val_accuracy: 0.7966\n",
      "Epoch 2002/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1963 - accuracy: 0.9118 - val_loss: 0.4051 - val_accuracy: 0.7966\n",
      "Epoch 2003/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1963 - accuracy: 0.9118 - val_loss: 0.4051 - val_accuracy: 0.7966\n",
      "Epoch 2004/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1963 - accuracy: 0.9118 - val_loss: 0.4051 - val_accuracy: 0.7966\n",
      "Epoch 2005/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1962 - accuracy: 0.9118 - val_loss: 0.4051 - val_accuracy: 0.7966\n",
      "Epoch 2006/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1962 - accuracy: 0.9118 - val_loss: 0.4052 - val_accuracy: 0.7966\n",
      "Epoch 2007/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1962 - accuracy: 0.9118 - val_loss: 0.4052 - val_accuracy: 0.7966\n",
      "Epoch 2008/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1962 - accuracy: 0.9118 - val_loss: 0.4052 - val_accuracy: 0.7966\n",
      "Epoch 2009/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1962 - accuracy: 0.9118 - val_loss: 0.4052 - val_accuracy: 0.7966\n",
      "Epoch 2010/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1962 - accuracy: 0.9118 - val_loss: 0.4052 - val_accuracy: 0.7966\n",
      "Epoch 2011/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1961 - accuracy: 0.9118 - val_loss: 0.4052 - val_accuracy: 0.7966\n",
      "Epoch 2012/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1961 - accuracy: 0.9118 - val_loss: 0.4053 - val_accuracy: 0.7966\n",
      "Epoch 2013/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1961 - accuracy: 0.9118 - val_loss: 0.4053 - val_accuracy: 0.7966\n",
      "Epoch 2014/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1961 - accuracy: 0.9118 - val_loss: 0.4053 - val_accuracy: 0.7966\n",
      "Epoch 2015/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1961 - accuracy: 0.9118 - val_loss: 0.4053 - val_accuracy: 0.7966\n",
      "Epoch 2016/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1960 - accuracy: 0.9118 - val_loss: 0.4053 - val_accuracy: 0.7966\n",
      "Epoch 2017/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1960 - accuracy: 0.9118 - val_loss: 0.4053 - val_accuracy: 0.7966\n",
      "Epoch 2018/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1960 - accuracy: 0.9118 - val_loss: 0.4054 - val_accuracy: 0.7966\n",
      "Epoch 2019/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1960 - accuracy: 0.9118 - val_loss: 0.4054 - val_accuracy: 0.7966\n",
      "Epoch 2020/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1960 - accuracy: 0.9118 - val_loss: 0.4054 - val_accuracy: 0.7966\n",
      "Epoch 2021/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1960 - accuracy: 0.9118 - val_loss: 0.4054 - val_accuracy: 0.7966\n",
      "Epoch 2022/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1959 - accuracy: 0.9118 - val_loss: 0.4054 - val_accuracy: 0.7966\n",
      "Epoch 2023/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1959 - accuracy: 0.9118 - val_loss: 0.4054 - val_accuracy: 0.7966\n",
      "Epoch 2024/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1959 - accuracy: 0.9118 - val_loss: 0.4055 - val_accuracy: 0.7966\n",
      "Epoch 2025/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1959 - accuracy: 0.9118 - val_loss: 0.4055 - val_accuracy: 0.7966\n",
      "Epoch 2026/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1959 - accuracy: 0.9118 - val_loss: 0.4055 - val_accuracy: 0.7966\n",
      "Epoch 2027/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1958 - accuracy: 0.9118 - val_loss: 0.4055 - val_accuracy: 0.7966\n",
      "Epoch 2028/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1958 - accuracy: 0.9118 - val_loss: 0.4055 - val_accuracy: 0.7966\n",
      "Epoch 2029/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1958 - accuracy: 0.9118 - val_loss: 0.4055 - val_accuracy: 0.7966\n",
      "Epoch 2030/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1958 - accuracy: 0.9118 - val_loss: 0.4056 - val_accuracy: 0.7966\n",
      "Epoch 2031/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1958 - accuracy: 0.9118 - val_loss: 0.4056 - val_accuracy: 0.7966\n",
      "Epoch 2032/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1958 - accuracy: 0.9118 - val_loss: 0.4056 - val_accuracy: 0.7966\n",
      "Epoch 2033/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1957 - accuracy: 0.9118 - val_loss: 0.4056 - val_accuracy: 0.7966\n",
      "Epoch 2034/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1957 - accuracy: 0.9118 - val_loss: 0.4056 - val_accuracy: 0.7966\n",
      "Epoch 2035/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1957 - accuracy: 0.9118 - val_loss: 0.4056 - val_accuracy: 0.7966\n",
      "Epoch 2036/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1957 - accuracy: 0.9118 - val_loss: 0.4057 - val_accuracy: 0.7966\n",
      "Epoch 2037/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1957 - accuracy: 0.9118 - val_loss: 0.4057 - val_accuracy: 0.7966\n",
      "Epoch 2038/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1956 - accuracy: 0.9118 - val_loss: 0.4057 - val_accuracy: 0.7966\n",
      "Epoch 2039/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1956 - accuracy: 0.9118 - val_loss: 0.4057 - val_accuracy: 0.7966\n",
      "Epoch 2040/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1956 - accuracy: 0.9118 - val_loss: 0.4057 - val_accuracy: 0.7966\n",
      "Epoch 2041/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1956 - accuracy: 0.9118 - val_loss: 0.4057 - val_accuracy: 0.7966\n",
      "Epoch 2042/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1956 - accuracy: 0.9118 - val_loss: 0.4057 - val_accuracy: 0.7966\n",
      "Epoch 2043/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1956 - accuracy: 0.9118 - val_loss: 0.4058 - val_accuracy: 0.7966\n",
      "Epoch 2044/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1955 - accuracy: 0.9118 - val_loss: 0.4058 - val_accuracy: 0.7966\n",
      "Epoch 2045/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1955 - accuracy: 0.9118 - val_loss: 0.4058 - val_accuracy: 0.7966\n",
      "Epoch 2046/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1955 - accuracy: 0.9118 - val_loss: 0.4058 - val_accuracy: 0.7966\n",
      "Epoch 2047/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1955 - accuracy: 0.9118 - val_loss: 0.4058 - val_accuracy: 0.7966\n",
      "Epoch 2048/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1955 - accuracy: 0.9118 - val_loss: 0.4058 - val_accuracy: 0.7966\n",
      "Epoch 2049/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1955 - accuracy: 0.9118 - val_loss: 0.4058 - val_accuracy: 0.7966\n",
      "Epoch 2050/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1954 - accuracy: 0.9118 - val_loss: 0.4058 - val_accuracy: 0.7966\n",
      "Epoch 2051/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1954 - accuracy: 0.9118 - val_loss: 0.4058 - val_accuracy: 0.7966\n",
      "Epoch 2052/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1954 - accuracy: 0.9118 - val_loss: 0.4058 - val_accuracy: 0.7966\n",
      "Epoch 2053/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1954 - accuracy: 0.9118 - val_loss: 0.4058 - val_accuracy: 0.7966\n",
      "Epoch 2054/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1954 - accuracy: 0.9118 - val_loss: 0.4058 - val_accuracy: 0.7966\n",
      "Epoch 2055/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1954 - accuracy: 0.9118 - val_loss: 0.4058 - val_accuracy: 0.7966\n",
      "Epoch 2056/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1953 - accuracy: 0.9118 - val_loss: 0.4059 - val_accuracy: 0.7966\n",
      "Epoch 2057/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1953 - accuracy: 0.9118 - val_loss: 0.4059 - val_accuracy: 0.7966\n",
      "Epoch 2058/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1953 - accuracy: 0.9118 - val_loss: 0.4059 - val_accuracy: 0.7966\n",
      "Epoch 2059/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1953 - accuracy: 0.9118 - val_loss: 0.4059 - val_accuracy: 0.7966\n",
      "Epoch 2060/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1953 - accuracy: 0.9118 - val_loss: 0.4059 - val_accuracy: 0.7966\n",
      "Epoch 2061/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1953 - accuracy: 0.9118 - val_loss: 0.4059 - val_accuracy: 0.7966\n",
      "Epoch 2062/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1952 - accuracy: 0.9118 - val_loss: 0.4059 - val_accuracy: 0.7966\n",
      "Epoch 2063/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1952 - accuracy: 0.9118 - val_loss: 0.4059 - val_accuracy: 0.7966\n",
      "Epoch 2064/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1952 - accuracy: 0.9118 - val_loss: 0.4059 - val_accuracy: 0.7966\n",
      "Epoch 2065/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1952 - accuracy: 0.9118 - val_loss: 0.4059 - val_accuracy: 0.7966\n",
      "Epoch 2066/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1952 - accuracy: 0.9118 - val_loss: 0.4060 - val_accuracy: 0.7966\n",
      "Epoch 2067/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1952 - accuracy: 0.9118 - val_loss: 0.4060 - val_accuracy: 0.7966\n",
      "Epoch 2068/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1951 - accuracy: 0.9118 - val_loss: 0.4060 - val_accuracy: 0.7966\n",
      "Epoch 2069/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1951 - accuracy: 0.9118 - val_loss: 0.4060 - val_accuracy: 0.7966\n",
      "Epoch 2070/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1951 - accuracy: 0.9118 - val_loss: 0.4060 - val_accuracy: 0.7966\n",
      "Epoch 2071/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1951 - accuracy: 0.9118 - val_loss: 0.4060 - val_accuracy: 0.7966\n",
      "Epoch 2072/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1951 - accuracy: 0.9118 - val_loss: 0.4060 - val_accuracy: 0.7966\n",
      "Epoch 2073/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1951 - accuracy: 0.9118 - val_loss: 0.4060 - val_accuracy: 0.7966\n",
      "Epoch 2074/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1950 - accuracy: 0.9118 - val_loss: 0.4060 - val_accuracy: 0.7966\n",
      "Epoch 2075/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1950 - accuracy: 0.9118 - val_loss: 0.4060 - val_accuracy: 0.7966\n",
      "Epoch 2076/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1950 - accuracy: 0.9118 - val_loss: 0.4060 - val_accuracy: 0.7966\n",
      "Epoch 2077/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1950 - accuracy: 0.9118 - val_loss: 0.4061 - val_accuracy: 0.7966\n",
      "Epoch 2078/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1950 - accuracy: 0.9118 - val_loss: 0.4061 - val_accuracy: 0.7966\n",
      "Epoch 2079/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1950 - accuracy: 0.9118 - val_loss: 0.4061 - val_accuracy: 0.7966\n",
      "Epoch 2080/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1949 - accuracy: 0.9118 - val_loss: 0.4061 - val_accuracy: 0.7966\n",
      "Epoch 2081/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1949 - accuracy: 0.9118 - val_loss: 0.4061 - val_accuracy: 0.7966\n",
      "Epoch 2082/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1949 - accuracy: 0.9118 - val_loss: 0.4061 - val_accuracy: 0.7966\n",
      "Epoch 2083/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1949 - accuracy: 0.9118 - val_loss: 0.4061 - val_accuracy: 0.7966\n",
      "Epoch 2084/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1949 - accuracy: 0.9118 - val_loss: 0.4061 - val_accuracy: 0.7966\n",
      "Epoch 2085/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1949 - accuracy: 0.9118 - val_loss: 0.4061 - val_accuracy: 0.7966\n",
      "Epoch 2086/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1948 - accuracy: 0.9118 - val_loss: 0.4062 - val_accuracy: 0.7966\n",
      "Epoch 2087/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1948 - accuracy: 0.9118 - val_loss: 0.4062 - val_accuracy: 0.7966\n",
      "Epoch 2088/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1948 - accuracy: 0.9118 - val_loss: 0.4062 - val_accuracy: 0.7966\n",
      "Epoch 2089/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1948 - accuracy: 0.9118 - val_loss: 0.4062 - val_accuracy: 0.7966\n",
      "Epoch 2090/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1948 - accuracy: 0.9118 - val_loss: 0.4062 - val_accuracy: 0.7966\n",
      "Epoch 2091/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1948 - accuracy: 0.9118 - val_loss: 0.4062 - val_accuracy: 0.7966\n",
      "Epoch 2092/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1947 - accuracy: 0.9118 - val_loss: 0.4062 - val_accuracy: 0.7966\n",
      "Epoch 2093/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1947 - accuracy: 0.9118 - val_loss: 0.4062 - val_accuracy: 0.7966\n",
      "Epoch 2094/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1947 - accuracy: 0.9118 - val_loss: 0.4062 - val_accuracy: 0.7966\n",
      "Epoch 2095/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1947 - accuracy: 0.9118 - val_loss: 0.4063 - val_accuracy: 0.7966\n",
      "Epoch 2096/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1947 - accuracy: 0.9118 - val_loss: 0.4063 - val_accuracy: 0.7966\n",
      "Epoch 2097/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1947 - accuracy: 0.9118 - val_loss: 0.4063 - val_accuracy: 0.7966\n",
      "Epoch 2098/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1946 - accuracy: 0.9118 - val_loss: 0.4063 - val_accuracy: 0.7966\n",
      "Epoch 2099/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1946 - accuracy: 0.9118 - val_loss: 0.4063 - val_accuracy: 0.7966\n",
      "Epoch 2100/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1946 - accuracy: 0.9118 - val_loss: 0.4063 - val_accuracy: 0.7966\n",
      "Epoch 2101/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1946 - accuracy: 0.9118 - val_loss: 0.4063 - val_accuracy: 0.7966\n",
      "Epoch 2102/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1946 - accuracy: 0.9118 - val_loss: 0.4063 - val_accuracy: 0.7966\n",
      "Epoch 2103/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1946 - accuracy: 0.9118 - val_loss: 0.4063 - val_accuracy: 0.7966\n",
      "Epoch 2104/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1945 - accuracy: 0.9118 - val_loss: 0.4064 - val_accuracy: 0.7966\n",
      "Epoch 2105/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1945 - accuracy: 0.9118 - val_loss: 0.4064 - val_accuracy: 0.7966\n",
      "Epoch 2106/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1945 - accuracy: 0.9118 - val_loss: 0.4064 - val_accuracy: 0.7966\n",
      "Epoch 2107/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1945 - accuracy: 0.9118 - val_loss: 0.4064 - val_accuracy: 0.7966\n",
      "Epoch 2108/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1945 - accuracy: 0.9118 - val_loss: 0.4064 - val_accuracy: 0.7966\n",
      "Epoch 2109/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1945 - accuracy: 0.9118 - val_loss: 0.4064 - val_accuracy: 0.7966\n",
      "Epoch 2110/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1945 - accuracy: 0.9118 - val_loss: 0.4064 - val_accuracy: 0.7966\n",
      "Epoch 2111/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1944 - accuracy: 0.9118 - val_loss: 0.4064 - val_accuracy: 0.7966\n",
      "Epoch 2112/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1944 - accuracy: 0.9118 - val_loss: 0.4064 - val_accuracy: 0.7966\n",
      "Epoch 2113/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1944 - accuracy: 0.9118 - val_loss: 0.4065 - val_accuracy: 0.7966\n",
      "Epoch 2114/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1944 - accuracy: 0.9118 - val_loss: 0.4065 - val_accuracy: 0.7966\n",
      "Epoch 2115/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1944 - accuracy: 0.9118 - val_loss: 0.4065 - val_accuracy: 0.7966\n",
      "Epoch 2116/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1944 - accuracy: 0.9118 - val_loss: 0.4065 - val_accuracy: 0.7966\n",
      "Epoch 2117/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1943 - accuracy: 0.9118 - val_loss: 0.4065 - val_accuracy: 0.7966\n",
      "Epoch 2118/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1943 - accuracy: 0.9118 - val_loss: 0.4065 - val_accuracy: 0.7966\n",
      "Epoch 2119/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1943 - accuracy: 0.9118 - val_loss: 0.4065 - val_accuracy: 0.7966\n",
      "Epoch 2120/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1943 - accuracy: 0.9118 - val_loss: 0.4065 - val_accuracy: 0.7966\n",
      "Epoch 2121/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1943 - accuracy: 0.9118 - val_loss: 0.4066 - val_accuracy: 0.7966\n",
      "Epoch 2122/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1943 - accuracy: 0.9118 - val_loss: 0.4066 - val_accuracy: 0.7966\n",
      "Epoch 2123/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1942 - accuracy: 0.9118 - val_loss: 0.4066 - val_accuracy: 0.7966\n",
      "Epoch 2124/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1942 - accuracy: 0.9118 - val_loss: 0.4066 - val_accuracy: 0.7966\n",
      "Epoch 2125/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1942 - accuracy: 0.9118 - val_loss: 0.4066 - val_accuracy: 0.7966\n",
      "Epoch 2126/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1942 - accuracy: 0.9118 - val_loss: 0.4066 - val_accuracy: 0.7966\n",
      "Epoch 2127/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1942 - accuracy: 0.9118 - val_loss: 0.4066 - val_accuracy: 0.7966\n",
      "Epoch 2128/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1942 - accuracy: 0.9118 - val_loss: 0.4066 - val_accuracy: 0.7966\n",
      "Epoch 2129/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1941 - accuracy: 0.9118 - val_loss: 0.4067 - val_accuracy: 0.7966\n",
      "Epoch 2130/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1941 - accuracy: 0.9118 - val_loss: 0.4067 - val_accuracy: 0.7966\n",
      "Epoch 2131/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1941 - accuracy: 0.9118 - val_loss: 0.4067 - val_accuracy: 0.7966\n",
      "Epoch 2132/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1941 - accuracy: 0.9118 - val_loss: 0.4067 - val_accuracy: 0.7966\n",
      "Epoch 2133/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1941 - accuracy: 0.9118 - val_loss: 0.4067 - val_accuracy: 0.7966\n",
      "Epoch 2134/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1941 - accuracy: 0.9118 - val_loss: 0.4067 - val_accuracy: 0.7966\n",
      "Epoch 2135/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1941 - accuracy: 0.9118 - val_loss: 0.4067 - val_accuracy: 0.7966\n",
      "Epoch 2136/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1940 - accuracy: 0.9118 - val_loss: 0.4067 - val_accuracy: 0.7966\n",
      "Epoch 2137/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1940 - accuracy: 0.9118 - val_loss: 0.4067 - val_accuracy: 0.7966\n",
      "Epoch 2138/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1940 - accuracy: 0.9118 - val_loss: 0.4068 - val_accuracy: 0.7966\n",
      "Epoch 2139/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1940 - accuracy: 0.9118 - val_loss: 0.4068 - val_accuracy: 0.7966\n",
      "Epoch 2140/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1940 - accuracy: 0.9118 - val_loss: 0.4068 - val_accuracy: 0.7966\n",
      "Epoch 2141/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1940 - accuracy: 0.9118 - val_loss: 0.4068 - val_accuracy: 0.7966\n",
      "Epoch 2142/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1939 - accuracy: 0.9118 - val_loss: 0.4068 - val_accuracy: 0.7966\n",
      "Epoch 2143/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1939 - accuracy: 0.9118 - val_loss: 0.4068 - val_accuracy: 0.7966\n",
      "Epoch 2144/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1939 - accuracy: 0.9118 - val_loss: 0.4068 - val_accuracy: 0.7966\n",
      "Epoch 2145/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1939 - accuracy: 0.9118 - val_loss: 0.4069 - val_accuracy: 0.7966\n",
      "Epoch 2146/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1939 - accuracy: 0.9118 - val_loss: 0.4069 - val_accuracy: 0.7966\n",
      "Epoch 2147/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1939 - accuracy: 0.9118 - val_loss: 0.4069 - val_accuracy: 0.7966\n",
      "Epoch 2148/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1938 - accuracy: 0.9118 - val_loss: 0.4069 - val_accuracy: 0.7966\n",
      "Epoch 2149/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1938 - accuracy: 0.9118 - val_loss: 0.4069 - val_accuracy: 0.7966\n",
      "Epoch 2150/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1938 - accuracy: 0.9118 - val_loss: 0.4069 - val_accuracy: 0.7966\n",
      "Epoch 2151/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1938 - accuracy: 0.9118 - val_loss: 0.4069 - val_accuracy: 0.7966\n",
      "Epoch 2152/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1938 - accuracy: 0.9118 - val_loss: 0.4069 - val_accuracy: 0.7966\n",
      "Epoch 2153/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1938 - accuracy: 0.9118 - val_loss: 0.4069 - val_accuracy: 0.7966\n",
      "Epoch 2154/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1938 - accuracy: 0.9118 - val_loss: 0.4070 - val_accuracy: 0.7966\n",
      "Epoch 2155/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1937 - accuracy: 0.9118 - val_loss: 0.4070 - val_accuracy: 0.7966\n",
      "Epoch 2156/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1937 - accuracy: 0.9118 - val_loss: 0.4070 - val_accuracy: 0.7966\n",
      "Epoch 2157/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1937 - accuracy: 0.9118 - val_loss: 0.4070 - val_accuracy: 0.7966\n",
      "Epoch 2158/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1937 - accuracy: 0.9118 - val_loss: 0.4070 - val_accuracy: 0.7966\n",
      "Epoch 2159/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1937 - accuracy: 0.9118 - val_loss: 0.4070 - val_accuracy: 0.7966\n",
      "Epoch 2160/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1937 - accuracy: 0.9118 - val_loss: 0.4070 - val_accuracy: 0.7966\n",
      "Epoch 2161/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1936 - accuracy: 0.9118 - val_loss: 0.4071 - val_accuracy: 0.7966\n",
      "Epoch 2162/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1936 - accuracy: 0.9118 - val_loss: 0.4071 - val_accuracy: 0.7966\n",
      "Epoch 2163/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1936 - accuracy: 0.9118 - val_loss: 0.4071 - val_accuracy: 0.7966\n",
      "Epoch 2164/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1936 - accuracy: 0.9118 - val_loss: 0.4071 - val_accuracy: 0.7966\n",
      "Epoch 2165/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1936 - accuracy: 0.9118 - val_loss: 0.4071 - val_accuracy: 0.7966\n",
      "Epoch 2166/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1936 - accuracy: 0.9118 - val_loss: 0.4071 - val_accuracy: 0.7966\n",
      "Epoch 2167/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1935 - accuracy: 0.9118 - val_loss: 0.4071 - val_accuracy: 0.7966\n",
      "Epoch 2168/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1935 - accuracy: 0.9118 - val_loss: 0.4071 - val_accuracy: 0.7966\n",
      "Epoch 2169/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1935 - accuracy: 0.9118 - val_loss: 0.4072 - val_accuracy: 0.7966\n",
      "Epoch 2170/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1935 - accuracy: 0.9118 - val_loss: 0.4072 - val_accuracy: 0.7966\n",
      "Epoch 2171/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1935 - accuracy: 0.9118 - val_loss: 0.4072 - val_accuracy: 0.7966\n",
      "Epoch 2172/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1935 - accuracy: 0.9118 - val_loss: 0.4072 - val_accuracy: 0.7966\n",
      "Epoch 2173/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1935 - accuracy: 0.9118 - val_loss: 0.4072 - val_accuracy: 0.7966\n",
      "Epoch 2174/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1934 - accuracy: 0.9118 - val_loss: 0.4072 - val_accuracy: 0.7966\n",
      "Epoch 2175/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1934 - accuracy: 0.9118 - val_loss: 0.4072 - val_accuracy: 0.7966\n",
      "Epoch 2176/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1934 - accuracy: 0.9118 - val_loss: 0.4072 - val_accuracy: 0.7966\n",
      "Epoch 2177/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1934 - accuracy: 0.9118 - val_loss: 0.4073 - val_accuracy: 0.7966\n",
      "Epoch 2178/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1934 - accuracy: 0.9118 - val_loss: 0.4073 - val_accuracy: 0.7966\n",
      "Epoch 2179/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1934 - accuracy: 0.9118 - val_loss: 0.4073 - val_accuracy: 0.7966\n",
      "Epoch 2180/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1933 - accuracy: 0.9118 - val_loss: 0.4073 - val_accuracy: 0.7966\n",
      "Epoch 2181/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1933 - accuracy: 0.9118 - val_loss: 0.4073 - val_accuracy: 0.7966\n",
      "Epoch 2182/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1933 - accuracy: 0.9118 - val_loss: 0.4073 - val_accuracy: 0.7966\n",
      "Epoch 2183/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1933 - accuracy: 0.9118 - val_loss: 0.4073 - val_accuracy: 0.7966\n",
      "Epoch 2184/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1933 - accuracy: 0.9118 - val_loss: 0.4074 - val_accuracy: 0.7966\n",
      "Epoch 2185/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1933 - accuracy: 0.9118 - val_loss: 0.4074 - val_accuracy: 0.7966\n",
      "Epoch 2186/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1933 - accuracy: 0.9118 - val_loss: 0.4074 - val_accuracy: 0.7966\n",
      "Epoch 2187/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1932 - accuracy: 0.9118 - val_loss: 0.4074 - val_accuracy: 0.7966\n",
      "Epoch 2188/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1932 - accuracy: 0.9118 - val_loss: 0.4074 - val_accuracy: 0.7966\n",
      "Epoch 2189/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1932 - accuracy: 0.9118 - val_loss: 0.4074 - val_accuracy: 0.7966\n",
      "Epoch 2190/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1932 - accuracy: 0.9118 - val_loss: 0.4074 - val_accuracy: 0.7966\n",
      "Epoch 2191/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1932 - accuracy: 0.9118 - val_loss: 0.4075 - val_accuracy: 0.7966\n",
      "Epoch 2192/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1932 - accuracy: 0.9118 - val_loss: 0.4075 - val_accuracy: 0.7966\n",
      "Epoch 2193/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1931 - accuracy: 0.9118 - val_loss: 0.4075 - val_accuracy: 0.7966\n",
      "Epoch 2194/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1931 - accuracy: 0.9118 - val_loss: 0.4075 - val_accuracy: 0.7966\n",
      "Epoch 2195/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1931 - accuracy: 0.9118 - val_loss: 0.4075 - val_accuracy: 0.7966\n",
      "Epoch 2196/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1931 - accuracy: 0.9118 - val_loss: 0.4075 - val_accuracy: 0.7966\n",
      "Epoch 2197/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1931 - accuracy: 0.9118 - val_loss: 0.4075 - val_accuracy: 0.7966\n",
      "Epoch 2198/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1931 - accuracy: 0.9118 - val_loss: 0.4075 - val_accuracy: 0.7966\n",
      "Epoch 2199/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1931 - accuracy: 0.9118 - val_loss: 0.4076 - val_accuracy: 0.7966\n",
      "Epoch 2200/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1930 - accuracy: 0.9118 - val_loss: 0.4076 - val_accuracy: 0.7966\n",
      "Epoch 2201/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1930 - accuracy: 0.9118 - val_loss: 0.4076 - val_accuracy: 0.7966\n",
      "Epoch 2202/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1930 - accuracy: 0.9118 - val_loss: 0.4076 - val_accuracy: 0.7966\n",
      "Epoch 2203/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1930 - accuracy: 0.9118 - val_loss: 0.4076 - val_accuracy: 0.7966\n",
      "Epoch 2204/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1930 - accuracy: 0.9118 - val_loss: 0.4076 - val_accuracy: 0.7966\n",
      "Epoch 2205/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1930 - accuracy: 0.9118 - val_loss: 0.4076 - val_accuracy: 0.7966\n",
      "Epoch 2206/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1930 - accuracy: 0.9118 - val_loss: 0.4077 - val_accuracy: 0.7966\n",
      "Epoch 2207/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1929 - accuracy: 0.9118 - val_loss: 0.4077 - val_accuracy: 0.7966\n",
      "Epoch 2208/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1929 - accuracy: 0.9118 - val_loss: 0.4077 - val_accuracy: 0.7966\n",
      "Epoch 2209/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1929 - accuracy: 0.9118 - val_loss: 0.4077 - val_accuracy: 0.7966\n",
      "Epoch 2210/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1929 - accuracy: 0.9118 - val_loss: 0.4077 - val_accuracy: 0.7966\n",
      "Epoch 2211/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1929 - accuracy: 0.9118 - val_loss: 0.4077 - val_accuracy: 0.7966\n",
      "Epoch 2212/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1929 - accuracy: 0.9118 - val_loss: 0.4077 - val_accuracy: 0.7966\n",
      "Epoch 2213/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1928 - accuracy: 0.9118 - val_loss: 0.4077 - val_accuracy: 0.7966\n",
      "Epoch 2214/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1928 - accuracy: 0.9118 - val_loss: 0.4078 - val_accuracy: 0.7966\n",
      "Epoch 2215/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1928 - accuracy: 0.9118 - val_loss: 0.4078 - val_accuracy: 0.7966\n",
      "Epoch 2216/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1928 - accuracy: 0.9118 - val_loss: 0.4078 - val_accuracy: 0.7966\n",
      "Epoch 2217/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1928 - accuracy: 0.9118 - val_loss: 0.4078 - val_accuracy: 0.7966\n",
      "Epoch 2218/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1928 - accuracy: 0.9118 - val_loss: 0.4078 - val_accuracy: 0.7966\n",
      "Epoch 2219/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1928 - accuracy: 0.9118 - val_loss: 0.4078 - val_accuracy: 0.7966\n",
      "Epoch 2220/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1927 - accuracy: 0.9118 - val_loss: 0.4078 - val_accuracy: 0.7966\n",
      "Epoch 2221/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1927 - accuracy: 0.9118 - val_loss: 0.4079 - val_accuracy: 0.7966\n",
      "Epoch 2222/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1927 - accuracy: 0.9118 - val_loss: 0.4079 - val_accuracy: 0.7966\n",
      "Epoch 2223/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1927 - accuracy: 0.9118 - val_loss: 0.4079 - val_accuracy: 0.7966\n",
      "Epoch 2224/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1927 - accuracy: 0.9118 - val_loss: 0.4079 - val_accuracy: 0.7966\n",
      "Epoch 2225/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1927 - accuracy: 0.9118 - val_loss: 0.4079 - val_accuracy: 0.7966\n",
      "Epoch 2226/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1927 - accuracy: 0.9118 - val_loss: 0.4079 - val_accuracy: 0.7966\n",
      "Epoch 2227/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1926 - accuracy: 0.9118 - val_loss: 0.4079 - val_accuracy: 0.7966\n",
      "Epoch 2228/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1926 - accuracy: 0.9118 - val_loss: 0.4079 - val_accuracy: 0.7966\n",
      "Epoch 2229/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1926 - accuracy: 0.9118 - val_loss: 0.4080 - val_accuracy: 0.7966\n",
      "Epoch 2230/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1926 - accuracy: 0.9118 - val_loss: 0.4080 - val_accuracy: 0.7966\n",
      "Epoch 2231/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1926 - accuracy: 0.9118 - val_loss: 0.4080 - val_accuracy: 0.7966\n",
      "Epoch 2232/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1926 - accuracy: 0.9118 - val_loss: 0.4080 - val_accuracy: 0.7966\n",
      "Epoch 2233/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1925 - accuracy: 0.9118 - val_loss: 0.4080 - val_accuracy: 0.7966\n",
      "Epoch 2234/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1925 - accuracy: 0.9118 - val_loss: 0.4080 - val_accuracy: 0.7966\n",
      "Epoch 2235/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1925 - accuracy: 0.9118 - val_loss: 0.4080 - val_accuracy: 0.7966\n",
      "Epoch 2236/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1925 - accuracy: 0.9118 - val_loss: 0.4081 - val_accuracy: 0.7966\n",
      "Epoch 2237/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1925 - accuracy: 0.9118 - val_loss: 0.4081 - val_accuracy: 0.7966\n",
      "Epoch 2238/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1925 - accuracy: 0.9118 - val_loss: 0.4081 - val_accuracy: 0.7966\n",
      "Epoch 2239/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1925 - accuracy: 0.9118 - val_loss: 0.4081 - val_accuracy: 0.7966\n",
      "Epoch 2240/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1924 - accuracy: 0.9118 - val_loss: 0.4081 - val_accuracy: 0.7966\n",
      "Epoch 2241/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1924 - accuracy: 0.9118 - val_loss: 0.4081 - val_accuracy: 0.7966\n",
      "Epoch 2242/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1924 - accuracy: 0.9118 - val_loss: 0.4081 - val_accuracy: 0.7966\n",
      "Epoch 2243/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1924 - accuracy: 0.9118 - val_loss: 0.4082 - val_accuracy: 0.7966\n",
      "Epoch 2244/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1924 - accuracy: 0.9118 - val_loss: 0.4082 - val_accuracy: 0.7966\n",
      "Epoch 2245/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1924 - accuracy: 0.9118 - val_loss: 0.4082 - val_accuracy: 0.7966\n",
      "Epoch 2246/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1924 - accuracy: 0.9118 - val_loss: 0.4082 - val_accuracy: 0.7966\n",
      "Epoch 2247/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1923 - accuracy: 0.9118 - val_loss: 0.4082 - val_accuracy: 0.7966\n",
      "Epoch 2248/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1923 - accuracy: 0.9118 - val_loss: 0.4082 - val_accuracy: 0.7966\n",
      "Epoch 2249/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1923 - accuracy: 0.9118 - val_loss: 0.4082 - val_accuracy: 0.7966\n",
      "Epoch 2250/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1923 - accuracy: 0.9118 - val_loss: 0.4083 - val_accuracy: 0.7966\n",
      "Epoch 2251/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1923 - accuracy: 0.9118 - val_loss: 0.4083 - val_accuracy: 0.7966\n",
      "Epoch 2252/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1923 - accuracy: 0.9118 - val_loss: 0.4083 - val_accuracy: 0.7966\n",
      "Epoch 2253/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1923 - accuracy: 0.9118 - val_loss: 0.4083 - val_accuracy: 0.7966\n",
      "Epoch 2254/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1922 - accuracy: 0.9118 - val_loss: 0.4083 - val_accuracy: 0.7966\n",
      "Epoch 2255/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1922 - accuracy: 0.9118 - val_loss: 0.4083 - val_accuracy: 0.7966\n",
      "Epoch 2256/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1922 - accuracy: 0.9118 - val_loss: 0.4083 - val_accuracy: 0.7966\n",
      "Epoch 2257/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1922 - accuracy: 0.9118 - val_loss: 0.4083 - val_accuracy: 0.7966\n",
      "Epoch 2258/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1922 - accuracy: 0.9118 - val_loss: 0.4084 - val_accuracy: 0.7966\n",
      "Epoch 2259/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1922 - accuracy: 0.9118 - val_loss: 0.4084 - val_accuracy: 0.7966\n",
      "Epoch 2260/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1921 - accuracy: 0.9118 - val_loss: 0.4084 - val_accuracy: 0.7966\n",
      "Epoch 2261/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1921 - accuracy: 0.9118 - val_loss: 0.4084 - val_accuracy: 0.7966\n",
      "Epoch 2262/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1921 - accuracy: 0.9118 - val_loss: 0.4084 - val_accuracy: 0.7966\n",
      "Epoch 2263/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1921 - accuracy: 0.9118 - val_loss: 0.4084 - val_accuracy: 0.7966\n",
      "Epoch 2264/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1921 - accuracy: 0.9118 - val_loss: 0.4084 - val_accuracy: 0.7966\n",
      "Epoch 2265/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1921 - accuracy: 0.9118 - val_loss: 0.4085 - val_accuracy: 0.7966\n",
      "Epoch 2266/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1921 - accuracy: 0.9118 - val_loss: 0.4085 - val_accuracy: 0.7966\n",
      "Epoch 2267/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1920 - accuracy: 0.9118 - val_loss: 0.4085 - val_accuracy: 0.7966\n",
      "Epoch 2268/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1920 - accuracy: 0.9118 - val_loss: 0.4085 - val_accuracy: 0.7966\n",
      "Epoch 2269/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1920 - accuracy: 0.9118 - val_loss: 0.4085 - val_accuracy: 0.7966\n",
      "Epoch 2270/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1920 - accuracy: 0.9118 - val_loss: 0.4085 - val_accuracy: 0.7966\n",
      "Epoch 2271/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1920 - accuracy: 0.9118 - val_loss: 0.4085 - val_accuracy: 0.7966\n",
      "Epoch 2272/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1920 - accuracy: 0.9118 - val_loss: 0.4086 - val_accuracy: 0.7966\n",
      "Epoch 2273/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1920 - accuracy: 0.9118 - val_loss: 0.4086 - val_accuracy: 0.7966\n",
      "Epoch 2274/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1919 - accuracy: 0.9118 - val_loss: 0.4086 - val_accuracy: 0.7966\n",
      "Epoch 2275/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1919 - accuracy: 0.9118 - val_loss: 0.4086 - val_accuracy: 0.7966\n",
      "Epoch 2276/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1919 - accuracy: 0.9118 - val_loss: 0.4086 - val_accuracy: 0.7966\n",
      "Epoch 2277/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1919 - accuracy: 0.9118 - val_loss: 0.4086 - val_accuracy: 0.7966\n",
      "Epoch 2278/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1919 - accuracy: 0.9118 - val_loss: 0.4086 - val_accuracy: 0.7966\n",
      "Epoch 2279/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1919 - accuracy: 0.9118 - val_loss: 0.4087 - val_accuracy: 0.7966\n",
      "Epoch 2280/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1919 - accuracy: 0.9118 - val_loss: 0.4087 - val_accuracy: 0.7966\n",
      "Epoch 2281/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1918 - accuracy: 0.9118 - val_loss: 0.4087 - val_accuracy: 0.7966\n",
      "Epoch 2282/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1918 - accuracy: 0.9118 - val_loss: 0.4087 - val_accuracy: 0.7966\n",
      "Epoch 2283/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1918 - accuracy: 0.9118 - val_loss: 0.4087 - val_accuracy: 0.7966\n",
      "Epoch 2284/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1918 - accuracy: 0.9118 - val_loss: 0.4087 - val_accuracy: 0.7966\n",
      "Epoch 2285/4000\n",
      "136/136 [==============================] - 0s 73us/step - loss: 0.1918 - accuracy: 0.9118 - val_loss: 0.4087 - val_accuracy: 0.7966\n",
      "Epoch 2286/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1918 - accuracy: 0.9118 - val_loss: 0.4088 - val_accuracy: 0.7966\n",
      "Epoch 2287/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1918 - accuracy: 0.9118 - val_loss: 0.4088 - val_accuracy: 0.7966\n",
      "Epoch 2288/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1917 - accuracy: 0.9118 - val_loss: 0.4088 - val_accuracy: 0.7966\n",
      "Epoch 2289/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1917 - accuracy: 0.9118 - val_loss: 0.4088 - val_accuracy: 0.7966\n",
      "Epoch 2290/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1917 - accuracy: 0.9191 - val_loss: 0.4088 - val_accuracy: 0.7966\n",
      "Epoch 2291/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1917 - accuracy: 0.9191 - val_loss: 0.4088 - val_accuracy: 0.7966\n",
      "Epoch 2292/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1917 - accuracy: 0.9191 - val_loss: 0.4088 - val_accuracy: 0.7966\n",
      "Epoch 2293/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1917 - accuracy: 0.9191 - val_loss: 0.4089 - val_accuracy: 0.7966\n",
      "Epoch 2294/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1917 - accuracy: 0.9191 - val_loss: 0.4089 - val_accuracy: 0.7966\n",
      "Epoch 2295/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1916 - accuracy: 0.9191 - val_loss: 0.4089 - val_accuracy: 0.7966\n",
      "Epoch 2296/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1916 - accuracy: 0.9191 - val_loss: 0.4089 - val_accuracy: 0.7966\n",
      "Epoch 2297/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1916 - accuracy: 0.9191 - val_loss: 0.4089 - val_accuracy: 0.7966\n",
      "Epoch 2298/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1916 - accuracy: 0.9191 - val_loss: 0.4089 - val_accuracy: 0.7966\n",
      "Epoch 2299/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1916 - accuracy: 0.9191 - val_loss: 0.4089 - val_accuracy: 0.7966\n",
      "Epoch 2300/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1916 - accuracy: 0.9191 - val_loss: 0.4090 - val_accuracy: 0.7966\n",
      "Epoch 2301/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1916 - accuracy: 0.9191 - val_loss: 0.4090 - val_accuracy: 0.7966\n",
      "Epoch 2302/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1915 - accuracy: 0.9191 - val_loss: 0.4090 - val_accuracy: 0.7966\n",
      "Epoch 2303/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1915 - accuracy: 0.9191 - val_loss: 0.4090 - val_accuracy: 0.7966\n",
      "Epoch 2304/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1915 - accuracy: 0.9191 - val_loss: 0.4090 - val_accuracy: 0.7966\n",
      "Epoch 2305/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1915 - accuracy: 0.9191 - val_loss: 0.4090 - val_accuracy: 0.7966\n",
      "Epoch 2306/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1915 - accuracy: 0.9191 - val_loss: 0.4090 - val_accuracy: 0.7966\n",
      "Epoch 2307/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1915 - accuracy: 0.9191 - val_loss: 0.4091 - val_accuracy: 0.7966\n",
      "Epoch 2308/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1915 - accuracy: 0.9191 - val_loss: 0.4091 - val_accuracy: 0.7966\n",
      "Epoch 2309/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1914 - accuracy: 0.9191 - val_loss: 0.4091 - val_accuracy: 0.7966\n",
      "Epoch 2310/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1914 - accuracy: 0.9191 - val_loss: 0.4091 - val_accuracy: 0.7966\n",
      "Epoch 2311/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1914 - accuracy: 0.9191 - val_loss: 0.4091 - val_accuracy: 0.7966\n",
      "Epoch 2312/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1914 - accuracy: 0.9191 - val_loss: 0.4091 - val_accuracy: 0.7966\n",
      "Epoch 2313/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1914 - accuracy: 0.9191 - val_loss: 0.4091 - val_accuracy: 0.7966\n",
      "Epoch 2314/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1914 - accuracy: 0.9191 - val_loss: 0.4092 - val_accuracy: 0.7966\n",
      "Epoch 2315/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1914 - accuracy: 0.9191 - val_loss: 0.4092 - val_accuracy: 0.7966\n",
      "Epoch 2316/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1913 - accuracy: 0.9191 - val_loss: 0.4092 - val_accuracy: 0.7966\n",
      "Epoch 2317/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1913 - accuracy: 0.9191 - val_loss: 0.4092 - val_accuracy: 0.7966\n",
      "Epoch 2318/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1913 - accuracy: 0.9191 - val_loss: 0.4092 - val_accuracy: 0.7966\n",
      "Epoch 2319/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1913 - accuracy: 0.9191 - val_loss: 0.4092 - val_accuracy: 0.7966\n",
      "Epoch 2320/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1913 - accuracy: 0.9191 - val_loss: 0.4092 - val_accuracy: 0.7966\n",
      "Epoch 2321/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1913 - accuracy: 0.9191 - val_loss: 0.4093 - val_accuracy: 0.7966\n",
      "Epoch 2322/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1913 - accuracy: 0.9191 - val_loss: 0.4093 - val_accuracy: 0.7966\n",
      "Epoch 2323/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1912 - accuracy: 0.9191 - val_loss: 0.4093 - val_accuracy: 0.7966\n",
      "Epoch 2324/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1912 - accuracy: 0.9191 - val_loss: 0.4093 - val_accuracy: 0.7966\n",
      "Epoch 2325/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1912 - accuracy: 0.9191 - val_loss: 0.4093 - val_accuracy: 0.7966\n",
      "Epoch 2326/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1912 - accuracy: 0.9191 - val_loss: 0.4093 - val_accuracy: 0.7966\n",
      "Epoch 2327/4000\n",
      "136/136 [==============================] - 0s 95us/step - loss: 0.1912 - accuracy: 0.9191 - val_loss: 0.4093 - val_accuracy: 0.7966\n",
      "Epoch 2328/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1912 - accuracy: 0.9191 - val_loss: 0.4094 - val_accuracy: 0.7966\n",
      "Epoch 2329/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1912 - accuracy: 0.9191 - val_loss: 0.4094 - val_accuracy: 0.7966\n",
      "Epoch 2330/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1911 - accuracy: 0.9191 - val_loss: 0.4094 - val_accuracy: 0.7966\n",
      "Epoch 2331/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1911 - accuracy: 0.9191 - val_loss: 0.4094 - val_accuracy: 0.7966\n",
      "Epoch 2332/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1911 - accuracy: 0.9191 - val_loss: 0.4094 - val_accuracy: 0.7966\n",
      "Epoch 2333/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1911 - accuracy: 0.9191 - val_loss: 0.4094 - val_accuracy: 0.7966\n",
      "Epoch 2334/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1911 - accuracy: 0.9191 - val_loss: 0.4094 - val_accuracy: 0.7966\n",
      "Epoch 2335/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1911 - accuracy: 0.9191 - val_loss: 0.4095 - val_accuracy: 0.7966\n",
      "Epoch 2336/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1911 - accuracy: 0.9191 - val_loss: 0.4095 - val_accuracy: 0.7966\n",
      "Epoch 2337/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1910 - accuracy: 0.9191 - val_loss: 0.4095 - val_accuracy: 0.7966\n",
      "Epoch 2338/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1910 - accuracy: 0.9191 - val_loss: 0.4095 - val_accuracy: 0.7966\n",
      "Epoch 2339/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1910 - accuracy: 0.9191 - val_loss: 0.4095 - val_accuracy: 0.7966\n",
      "Epoch 2340/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1910 - accuracy: 0.9191 - val_loss: 0.4095 - val_accuracy: 0.7966\n",
      "Epoch 2341/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1910 - accuracy: 0.9191 - val_loss: 0.4095 - val_accuracy: 0.7966\n",
      "Epoch 2342/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1910 - accuracy: 0.9191 - val_loss: 0.4095 - val_accuracy: 0.7966\n",
      "Epoch 2343/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1910 - accuracy: 0.9191 - val_loss: 0.4096 - val_accuracy: 0.7966\n",
      "Epoch 2344/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1909 - accuracy: 0.9191 - val_loss: 0.4096 - val_accuracy: 0.7966\n",
      "Epoch 2345/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1909 - accuracy: 0.9191 - val_loss: 0.4096 - val_accuracy: 0.7966\n",
      "Epoch 2346/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1909 - accuracy: 0.9191 - val_loss: 0.4096 - val_accuracy: 0.7966\n",
      "Epoch 2347/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1909 - accuracy: 0.9191 - val_loss: 0.4096 - val_accuracy: 0.7966\n",
      "Epoch 2348/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1909 - accuracy: 0.9191 - val_loss: 0.4096 - val_accuracy: 0.7966\n",
      "Epoch 2349/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1909 - accuracy: 0.9191 - val_loss: 0.4096 - val_accuracy: 0.7966\n",
      "Epoch 2350/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1909 - accuracy: 0.9191 - val_loss: 0.4097 - val_accuracy: 0.7966\n",
      "Epoch 2351/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1909 - accuracy: 0.9191 - val_loss: 0.4097 - val_accuracy: 0.7966\n",
      "Epoch 2352/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1908 - accuracy: 0.9191 - val_loss: 0.4097 - val_accuracy: 0.7966\n",
      "Epoch 2353/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1908 - accuracy: 0.9191 - val_loss: 0.4097 - val_accuracy: 0.7966\n",
      "Epoch 2354/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1908 - accuracy: 0.9191 - val_loss: 0.4097 - val_accuracy: 0.7966\n",
      "Epoch 2355/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1908 - accuracy: 0.9191 - val_loss: 0.4097 - val_accuracy: 0.7966\n",
      "Epoch 2356/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1908 - accuracy: 0.9191 - val_loss: 0.4097 - val_accuracy: 0.7966\n",
      "Epoch 2357/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1908 - accuracy: 0.9191 - val_loss: 0.4098 - val_accuracy: 0.7966\n",
      "Epoch 2358/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1908 - accuracy: 0.9191 - val_loss: 0.4098 - val_accuracy: 0.7966\n",
      "Epoch 2359/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1907 - accuracy: 0.9191 - val_loss: 0.4098 - val_accuracy: 0.7966\n",
      "Epoch 2360/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1907 - accuracy: 0.9191 - val_loss: 0.4098 - val_accuracy: 0.7966\n",
      "Epoch 2361/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1907 - accuracy: 0.9191 - val_loss: 0.4098 - val_accuracy: 0.7966\n",
      "Epoch 2362/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1907 - accuracy: 0.9191 - val_loss: 0.4098 - val_accuracy: 0.7966\n",
      "Epoch 2363/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1907 - accuracy: 0.9191 - val_loss: 0.4099 - val_accuracy: 0.7966\n",
      "Epoch 2364/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1907 - accuracy: 0.9191 - val_loss: 0.4099 - val_accuracy: 0.7966\n",
      "Epoch 2365/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1907 - accuracy: 0.9191 - val_loss: 0.4099 - val_accuracy: 0.7966\n",
      "Epoch 2366/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1906 - accuracy: 0.9191 - val_loss: 0.4099 - val_accuracy: 0.7966\n",
      "Epoch 2367/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1906 - accuracy: 0.9191 - val_loss: 0.4099 - val_accuracy: 0.7966\n",
      "Epoch 2368/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1906 - accuracy: 0.9191 - val_loss: 0.4099 - val_accuracy: 0.7966\n",
      "Epoch 2369/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1906 - accuracy: 0.9191 - val_loss: 0.4100 - val_accuracy: 0.7966\n",
      "Epoch 2370/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1906 - accuracy: 0.9191 - val_loss: 0.4100 - val_accuracy: 0.7966\n",
      "Epoch 2371/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1906 - accuracy: 0.9191 - val_loss: 0.4100 - val_accuracy: 0.7966\n",
      "Epoch 2372/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1906 - accuracy: 0.9191 - val_loss: 0.4100 - val_accuracy: 0.7966\n",
      "Epoch 2373/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1905 - accuracy: 0.9191 - val_loss: 0.4100 - val_accuracy: 0.7966\n",
      "Epoch 2374/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1905 - accuracy: 0.9191 - val_loss: 0.4100 - val_accuracy: 0.7966\n",
      "Epoch 2375/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1905 - accuracy: 0.9191 - val_loss: 0.4100 - val_accuracy: 0.7966\n",
      "Epoch 2376/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1905 - accuracy: 0.9191 - val_loss: 0.4101 - val_accuracy: 0.7966\n",
      "Epoch 2377/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1905 - accuracy: 0.9191 - val_loss: 0.4101 - val_accuracy: 0.7966\n",
      "Epoch 2378/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1905 - accuracy: 0.9191 - val_loss: 0.4101 - val_accuracy: 0.7966\n",
      "Epoch 2379/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1905 - accuracy: 0.9191 - val_loss: 0.4101 - val_accuracy: 0.7966\n",
      "Epoch 2380/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1904 - accuracy: 0.9191 - val_loss: 0.4101 - val_accuracy: 0.7966\n",
      "Epoch 2381/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1904 - accuracy: 0.9191 - val_loss: 0.4101 - val_accuracy: 0.7966\n",
      "Epoch 2382/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1904 - accuracy: 0.9191 - val_loss: 0.4102 - val_accuracy: 0.7966\n",
      "Epoch 2383/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1904 - accuracy: 0.9191 - val_loss: 0.4102 - val_accuracy: 0.7966\n",
      "Epoch 2384/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1904 - accuracy: 0.9191 - val_loss: 0.4102 - val_accuracy: 0.7966\n",
      "Epoch 2385/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1904 - accuracy: 0.9191 - val_loss: 0.4102 - val_accuracy: 0.7966\n",
      "Epoch 2386/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1904 - accuracy: 0.9191 - val_loss: 0.4102 - val_accuracy: 0.7966\n",
      "Epoch 2387/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1903 - accuracy: 0.9191 - val_loss: 0.4102 - val_accuracy: 0.7966\n",
      "Epoch 2388/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1903 - accuracy: 0.9191 - val_loss: 0.4102 - val_accuracy: 0.7966\n",
      "Epoch 2389/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1903 - accuracy: 0.9191 - val_loss: 0.4103 - val_accuracy: 0.7966\n",
      "Epoch 2390/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1903 - accuracy: 0.9191 - val_loss: 0.4103 - val_accuracy: 0.7966\n",
      "Epoch 2391/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1903 - accuracy: 0.9191 - val_loss: 0.4103 - val_accuracy: 0.7966\n",
      "Epoch 2392/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1903 - accuracy: 0.9191 - val_loss: 0.4103 - val_accuracy: 0.7966\n",
      "Epoch 2393/4000\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.1840 - accuracy: 0.93 - 0s 58us/step - loss: 0.1903 - accuracy: 0.9191 - val_loss: 0.4103 - val_accuracy: 0.7966\n",
      "Epoch 2394/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1902 - accuracy: 0.9191 - val_loss: 0.4103 - val_accuracy: 0.7966\n",
      "Epoch 2395/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1902 - accuracy: 0.9191 - val_loss: 0.4104 - val_accuracy: 0.7966\n",
      "Epoch 2396/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1902 - accuracy: 0.9191 - val_loss: 0.4104 - val_accuracy: 0.7966\n",
      "Epoch 2397/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1902 - accuracy: 0.9191 - val_loss: 0.4104 - val_accuracy: 0.7966\n",
      "Epoch 2398/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1902 - accuracy: 0.9191 - val_loss: 0.4104 - val_accuracy: 0.7966\n",
      "Epoch 2399/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1902 - accuracy: 0.9191 - val_loss: 0.4104 - val_accuracy: 0.7966\n",
      "Epoch 2400/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1902 - accuracy: 0.9191 - val_loss: 0.4104 - val_accuracy: 0.7966\n",
      "Epoch 2401/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1902 - accuracy: 0.9191 - val_loss: 0.4105 - val_accuracy: 0.7966\n",
      "Epoch 2402/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1901 - accuracy: 0.9191 - val_loss: 0.4105 - val_accuracy: 0.7966\n",
      "Epoch 2403/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1901 - accuracy: 0.9191 - val_loss: 0.4105 - val_accuracy: 0.7966\n",
      "Epoch 2404/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1901 - accuracy: 0.9191 - val_loss: 0.4105 - val_accuracy: 0.7966\n",
      "Epoch 2405/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1901 - accuracy: 0.9191 - val_loss: 0.4105 - val_accuracy: 0.7966\n",
      "Epoch 2406/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1901 - accuracy: 0.9191 - val_loss: 0.4105 - val_accuracy: 0.7966\n",
      "Epoch 2407/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1901 - accuracy: 0.9191 - val_loss: 0.4105 - val_accuracy: 0.7966\n",
      "Epoch 2408/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1901 - accuracy: 0.9191 - val_loss: 0.4106 - val_accuracy: 0.7966\n",
      "Epoch 2409/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1900 - accuracy: 0.9191 - val_loss: 0.4106 - val_accuracy: 0.7966\n",
      "Epoch 2410/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1900 - accuracy: 0.9191 - val_loss: 0.4106 - val_accuracy: 0.7966\n",
      "Epoch 2411/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1900 - accuracy: 0.9191 - val_loss: 0.4106 - val_accuracy: 0.7966\n",
      "Epoch 2412/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1900 - accuracy: 0.9191 - val_loss: 0.4106 - val_accuracy: 0.7966\n",
      "Epoch 2413/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1900 - accuracy: 0.9191 - val_loss: 0.4106 - val_accuracy: 0.7966\n",
      "Epoch 2414/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1900 - accuracy: 0.9191 - val_loss: 0.4107 - val_accuracy: 0.7966\n",
      "Epoch 2415/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1900 - accuracy: 0.9191 - val_loss: 0.4107 - val_accuracy: 0.7966\n",
      "Epoch 2416/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1899 - accuracy: 0.9191 - val_loss: 0.4107 - val_accuracy: 0.7966\n",
      "Epoch 2417/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1899 - accuracy: 0.9191 - val_loss: 0.4107 - val_accuracy: 0.7966\n",
      "Epoch 2418/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1899 - accuracy: 0.9191 - val_loss: 0.4107 - val_accuracy: 0.7966\n",
      "Epoch 2419/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1899 - accuracy: 0.9191 - val_loss: 0.4107 - val_accuracy: 0.7966\n",
      "Epoch 2420/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1899 - accuracy: 0.9191 - val_loss: 0.4107 - val_accuracy: 0.7966\n",
      "Epoch 2421/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1899 - accuracy: 0.9191 - val_loss: 0.4108 - val_accuracy: 0.7966\n",
      "Epoch 2422/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1899 - accuracy: 0.9191 - val_loss: 0.4108 - val_accuracy: 0.7966\n",
      "Epoch 2423/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1899 - accuracy: 0.9191 - val_loss: 0.4108 - val_accuracy: 0.7966\n",
      "Epoch 2424/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1898 - accuracy: 0.9191 - val_loss: 0.4108 - val_accuracy: 0.7966\n",
      "Epoch 2425/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1898 - accuracy: 0.9191 - val_loss: 0.4108 - val_accuracy: 0.7966\n",
      "Epoch 2426/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1898 - accuracy: 0.9191 - val_loss: 0.4108 - val_accuracy: 0.7966\n",
      "Epoch 2427/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1898 - accuracy: 0.9191 - val_loss: 0.4109 - val_accuracy: 0.7966\n",
      "Epoch 2428/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1898 - accuracy: 0.9191 - val_loss: 0.4109 - val_accuracy: 0.7966\n",
      "Epoch 2429/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1898 - accuracy: 0.9191 - val_loss: 0.4109 - val_accuracy: 0.7966\n",
      "Epoch 2430/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1898 - accuracy: 0.9191 - val_loss: 0.4109 - val_accuracy: 0.7966\n",
      "Epoch 2431/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1897 - accuracy: 0.9191 - val_loss: 0.4109 - val_accuracy: 0.7966\n",
      "Epoch 2432/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1897 - accuracy: 0.9191 - val_loss: 0.4109 - val_accuracy: 0.7966\n",
      "Epoch 2433/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1897 - accuracy: 0.9191 - val_loss: 0.4109 - val_accuracy: 0.7966\n",
      "Epoch 2434/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1897 - accuracy: 0.9191 - val_loss: 0.4110 - val_accuracy: 0.7966\n",
      "Epoch 2435/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1897 - accuracy: 0.9191 - val_loss: 0.4110 - val_accuracy: 0.7966\n",
      "Epoch 2436/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1897 - accuracy: 0.9191 - val_loss: 0.4110 - val_accuracy: 0.7966\n",
      "Epoch 2437/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1897 - accuracy: 0.9191 - val_loss: 0.4110 - val_accuracy: 0.7966\n",
      "Epoch 2438/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1896 - accuracy: 0.9191 - val_loss: 0.4110 - val_accuracy: 0.7966\n",
      "Epoch 2439/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1896 - accuracy: 0.9191 - val_loss: 0.4110 - val_accuracy: 0.7966\n",
      "Epoch 2440/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1896 - accuracy: 0.9191 - val_loss: 0.4110 - val_accuracy: 0.7966\n",
      "Epoch 2441/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1896 - accuracy: 0.9191 - val_loss: 0.4111 - val_accuracy: 0.7966\n",
      "Epoch 2442/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1896 - accuracy: 0.9191 - val_loss: 0.4111 - val_accuracy: 0.7966\n",
      "Epoch 2443/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1896 - accuracy: 0.9191 - val_loss: 0.4111 - val_accuracy: 0.7966\n",
      "Epoch 2444/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1896 - accuracy: 0.9191 - val_loss: 0.4111 - val_accuracy: 0.7966\n",
      "Epoch 2445/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1896 - accuracy: 0.9191 - val_loss: 0.4111 - val_accuracy: 0.7966\n",
      "Epoch 2446/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1895 - accuracy: 0.9191 - val_loss: 0.4111 - val_accuracy: 0.7966\n",
      "Epoch 2447/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1895 - accuracy: 0.9191 - val_loss: 0.4112 - val_accuracy: 0.7966\n",
      "Epoch 2448/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1895 - accuracy: 0.9191 - val_loss: 0.4112 - val_accuracy: 0.7966\n",
      "Epoch 2449/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1895 - accuracy: 0.9191 - val_loss: 0.4112 - val_accuracy: 0.7966\n",
      "Epoch 2450/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1895 - accuracy: 0.9191 - val_loss: 0.4112 - val_accuracy: 0.7966\n",
      "Epoch 2451/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1895 - accuracy: 0.9191 - val_loss: 0.4112 - val_accuracy: 0.7966\n",
      "Epoch 2452/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1895 - accuracy: 0.9191 - val_loss: 0.4112 - val_accuracy: 0.7966\n",
      "Epoch 2453/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1894 - accuracy: 0.9191 - val_loss: 0.4112 - val_accuracy: 0.7966\n",
      "Epoch 2454/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1894 - accuracy: 0.9191 - val_loss: 0.4113 - val_accuracy: 0.7966\n",
      "Epoch 2455/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1894 - accuracy: 0.9191 - val_loss: 0.4113 - val_accuracy: 0.7966\n",
      "Epoch 2456/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1894 - accuracy: 0.9191 - val_loss: 0.4113 - val_accuracy: 0.7966\n",
      "Epoch 2457/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1894 - accuracy: 0.9191 - val_loss: 0.4113 - val_accuracy: 0.7966\n",
      "Epoch 2458/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1894 - accuracy: 0.9191 - val_loss: 0.4113 - val_accuracy: 0.7966\n",
      "Epoch 2459/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1894 - accuracy: 0.9191 - val_loss: 0.4113 - val_accuracy: 0.7966\n",
      "Epoch 2460/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1894 - accuracy: 0.9191 - val_loss: 0.4113 - val_accuracy: 0.7966\n",
      "Epoch 2461/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1893 - accuracy: 0.9191 - val_loss: 0.4114 - val_accuracy: 0.7966\n",
      "Epoch 2462/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1893 - accuracy: 0.9191 - val_loss: 0.4114 - val_accuracy: 0.7966\n",
      "Epoch 2463/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1893 - accuracy: 0.9191 - val_loss: 0.4114 - val_accuracy: 0.7966\n",
      "Epoch 2464/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1893 - accuracy: 0.9191 - val_loss: 0.4114 - val_accuracy: 0.7966\n",
      "Epoch 2465/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1893 - accuracy: 0.9191 - val_loss: 0.4114 - val_accuracy: 0.7966\n",
      "Epoch 2466/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1893 - accuracy: 0.9191 - val_loss: 0.4114 - val_accuracy: 0.7966\n",
      "Epoch 2467/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1893 - accuracy: 0.9191 - val_loss: 0.4115 - val_accuracy: 0.7966\n",
      "Epoch 2468/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1892 - accuracy: 0.9191 - val_loss: 0.4115 - val_accuracy: 0.7966\n",
      "Epoch 2469/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1892 - accuracy: 0.9191 - val_loss: 0.4115 - val_accuracy: 0.7966\n",
      "Epoch 2470/4000\n",
      "136/136 [==============================] - 0s 73us/step - loss: 0.1892 - accuracy: 0.9191 - val_loss: 0.4115 - val_accuracy: 0.7966\n",
      "Epoch 2471/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1892 - accuracy: 0.9191 - val_loss: 0.4115 - val_accuracy: 0.7966\n",
      "Epoch 2472/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1892 - accuracy: 0.9191 - val_loss: 0.4115 - val_accuracy: 0.7966\n",
      "Epoch 2473/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1892 - accuracy: 0.9191 - val_loss: 0.4115 - val_accuracy: 0.7966\n",
      "Epoch 2474/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1892 - accuracy: 0.9191 - val_loss: 0.4116 - val_accuracy: 0.7966\n",
      "Epoch 2475/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1892 - accuracy: 0.9191 - val_loss: 0.4116 - val_accuracy: 0.7966\n",
      "Epoch 2476/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1891 - accuracy: 0.9191 - val_loss: 0.4116 - val_accuracy: 0.7966\n",
      "Epoch 2477/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1891 - accuracy: 0.9191 - val_loss: 0.4116 - val_accuracy: 0.7966\n",
      "Epoch 2478/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1891 - accuracy: 0.9191 - val_loss: 0.4116 - val_accuracy: 0.7966\n",
      "Epoch 2479/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1891 - accuracy: 0.9191 - val_loss: 0.4116 - val_accuracy: 0.7966\n",
      "Epoch 2480/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1891 - accuracy: 0.9191 - val_loss: 0.4116 - val_accuracy: 0.7966\n",
      "Epoch 2481/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1891 - accuracy: 0.9191 - val_loss: 0.4117 - val_accuracy: 0.7966\n",
      "Epoch 2482/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1891 - accuracy: 0.9191 - val_loss: 0.4117 - val_accuracy: 0.7966\n",
      "Epoch 2483/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1891 - accuracy: 0.9191 - val_loss: 0.4117 - val_accuracy: 0.7966\n",
      "Epoch 2484/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1890 - accuracy: 0.9191 - val_loss: 0.4117 - val_accuracy: 0.7966\n",
      "Epoch 2485/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1890 - accuracy: 0.9191 - val_loss: 0.4117 - val_accuracy: 0.7966\n",
      "Epoch 2486/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1890 - accuracy: 0.9191 - val_loss: 0.4117 - val_accuracy: 0.7966\n",
      "Epoch 2487/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1890 - accuracy: 0.9191 - val_loss: 0.4117 - val_accuracy: 0.7966\n",
      "Epoch 2488/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1890 - accuracy: 0.9191 - val_loss: 0.4118 - val_accuracy: 0.7966\n",
      "Epoch 2489/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1890 - accuracy: 0.9191 - val_loss: 0.4118 - val_accuracy: 0.7966\n",
      "Epoch 2490/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1890 - accuracy: 0.9191 - val_loss: 0.4118 - val_accuracy: 0.7966\n",
      "Epoch 2491/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1889 - accuracy: 0.9191 - val_loss: 0.4118 - val_accuracy: 0.7966\n",
      "Epoch 2492/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1889 - accuracy: 0.9191 - val_loss: 0.4118 - val_accuracy: 0.7966\n",
      "Epoch 2493/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1889 - accuracy: 0.9191 - val_loss: 0.4118 - val_accuracy: 0.7966\n",
      "Epoch 2494/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1889 - accuracy: 0.9191 - val_loss: 0.4118 - val_accuracy: 0.7966\n",
      "Epoch 2495/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1889 - accuracy: 0.9191 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 2496/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1889 - accuracy: 0.9191 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 2497/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1889 - accuracy: 0.9191 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 2498/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1889 - accuracy: 0.9191 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 2499/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1888 - accuracy: 0.9191 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 2500/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1888 - accuracy: 0.9191 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 2501/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1888 - accuracy: 0.9191 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 2502/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1888 - accuracy: 0.9191 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 2503/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1888 - accuracy: 0.9191 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 2504/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1888 - accuracy: 0.9191 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 2505/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1888 - accuracy: 0.9191 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 2506/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1888 - accuracy: 0.9191 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 2507/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1887 - accuracy: 0.9191 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 2508/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1887 - accuracy: 0.9191 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 2509/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1887 - accuracy: 0.9191 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 2510/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1887 - accuracy: 0.9191 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2511/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1887 - accuracy: 0.9191 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2512/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1887 - accuracy: 0.9191 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2513/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1887 - accuracy: 0.9191 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2514/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1886 - accuracy: 0.9191 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2515/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1886 - accuracy: 0.9191 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2516/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1886 - accuracy: 0.9191 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2517/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1886 - accuracy: 0.9191 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 2518/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1886 - accuracy: 0.9191 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 2519/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1886 - accuracy: 0.9191 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 2520/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1886 - accuracy: 0.9191 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 2521/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1886 - accuracy: 0.9191 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 2522/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1885 - accuracy: 0.9191 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 2523/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1885 - accuracy: 0.9191 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 2524/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1885 - accuracy: 0.9191 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 2525/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1885 - accuracy: 0.9191 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 2526/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1885 - accuracy: 0.9191 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 2527/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1885 - accuracy: 0.9191 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 2528/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1885 - accuracy: 0.9191 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 2529/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1885 - accuracy: 0.9191 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 2530/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1884 - accuracy: 0.9191 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 2531/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1884 - accuracy: 0.9191 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 2532/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1884 - accuracy: 0.9191 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 2533/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1884 - accuracy: 0.9191 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 2534/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1884 - accuracy: 0.9191 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 2535/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1884 - accuracy: 0.9191 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 2536/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1884 - accuracy: 0.9191 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 2537/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1884 - accuracy: 0.9191 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 2538/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1883 - accuracy: 0.9191 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 2539/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1883 - accuracy: 0.9191 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 2540/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1883 - accuracy: 0.9191 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 2541/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1883 - accuracy: 0.9191 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 2542/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1883 - accuracy: 0.9191 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 2543/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1883 - accuracy: 0.9191 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 2544/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1883 - accuracy: 0.9191 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 2545/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1882 - accuracy: 0.9191 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 2546/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1882 - accuracy: 0.9191 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 2547/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1882 - accuracy: 0.9191 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 2548/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1882 - accuracy: 0.9191 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 2549/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1882 - accuracy: 0.9191 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 2550/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1882 - accuracy: 0.9191 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 2551/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1882 - accuracy: 0.9191 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 2552/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1882 - accuracy: 0.9191 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 2553/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1881 - accuracy: 0.9191 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 2554/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1881 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 2555/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1881 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 2556/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1881 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 2557/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1881 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 2558/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1881 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 2559/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1881 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 2560/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1881 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 2561/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1880 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 2562/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1880 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 2563/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1880 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 2564/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1880 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 2565/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1880 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 2566/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1880 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 2567/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1880 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 2568/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1880 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 2569/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1879 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 2570/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1879 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 2571/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1879 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 2572/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1879 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 2573/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1879 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 2574/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1879 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 2575/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1879 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 2576/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1879 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 2577/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1878 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 2578/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1878 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 2579/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1878 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 2580/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1878 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 2581/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1878 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 2582/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1878 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 2583/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1878 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 2584/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1878 - accuracy: 0.9265 - val_loss: 0.4130 - val_accuracy: 0.7966\n",
      "Epoch 2585/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1877 - accuracy: 0.9265 - val_loss: 0.4130 - val_accuracy: 0.7966\n",
      "Epoch 2586/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1877 - accuracy: 0.9265 - val_loss: 0.4130 - val_accuracy: 0.7966\n",
      "Epoch 2587/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1877 - accuracy: 0.9265 - val_loss: 0.4130 - val_accuracy: 0.7966\n",
      "Epoch 2588/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1877 - accuracy: 0.9265 - val_loss: 0.4130 - val_accuracy: 0.7966\n",
      "Epoch 2589/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1877 - accuracy: 0.9265 - val_loss: 0.4130 - val_accuracy: 0.7966\n",
      "Epoch 2590/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1877 - accuracy: 0.9265 - val_loss: 0.4130 - val_accuracy: 0.7966\n",
      "Epoch 2591/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1877 - accuracy: 0.9265 - val_loss: 0.4130 - val_accuracy: 0.7966\n",
      "Epoch 2592/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1877 - accuracy: 0.9265 - val_loss: 0.4131 - val_accuracy: 0.7966\n",
      "Epoch 2593/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1876 - accuracy: 0.9265 - val_loss: 0.4131 - val_accuracy: 0.7966\n",
      "Epoch 2594/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1876 - accuracy: 0.9265 - val_loss: 0.4131 - val_accuracy: 0.7966\n",
      "Epoch 2595/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1876 - accuracy: 0.9265 - val_loss: 0.4131 - val_accuracy: 0.7966\n",
      "Epoch 2596/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1876 - accuracy: 0.9265 - val_loss: 0.4131 - val_accuracy: 0.7966\n",
      "Epoch 2597/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1876 - accuracy: 0.9265 - val_loss: 0.4131 - val_accuracy: 0.7966\n",
      "Epoch 2598/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1876 - accuracy: 0.9265 - val_loss: 0.4131 - val_accuracy: 0.7966\n",
      "Epoch 2599/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1876 - accuracy: 0.9265 - val_loss: 0.4131 - val_accuracy: 0.7966\n",
      "Epoch 2600/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1876 - accuracy: 0.9265 - val_loss: 0.4131 - val_accuracy: 0.7966\n",
      "Epoch 2601/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1875 - accuracy: 0.9265 - val_loss: 0.4131 - val_accuracy: 0.7966\n",
      "Epoch 2602/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1875 - accuracy: 0.9265 - val_loss: 0.4132 - val_accuracy: 0.7966\n",
      "Epoch 2603/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1875 - accuracy: 0.9265 - val_loss: 0.4132 - val_accuracy: 0.7966\n",
      "Epoch 2604/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1875 - accuracy: 0.9265 - val_loss: 0.4132 - val_accuracy: 0.7966\n",
      "Epoch 2605/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1875 - accuracy: 0.9265 - val_loss: 0.4132 - val_accuracy: 0.7966\n",
      "Epoch 2606/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1875 - accuracy: 0.9265 - val_loss: 0.4132 - val_accuracy: 0.7966\n",
      "Epoch 2607/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1875 - accuracy: 0.9265 - val_loss: 0.4132 - val_accuracy: 0.7966\n",
      "Epoch 2608/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1875 - accuracy: 0.9265 - val_loss: 0.4132 - val_accuracy: 0.7966\n",
      "Epoch 2609/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1874 - accuracy: 0.9265 - val_loss: 0.4132 - val_accuracy: 0.7966\n",
      "Epoch 2610/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1874 - accuracy: 0.9265 - val_loss: 0.4133 - val_accuracy: 0.7966\n",
      "Epoch 2611/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1874 - accuracy: 0.9265 - val_loss: 0.4133 - val_accuracy: 0.7966\n",
      "Epoch 2612/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1874 - accuracy: 0.9265 - val_loss: 0.4133 - val_accuracy: 0.7966\n",
      "Epoch 2613/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1874 - accuracy: 0.9265 - val_loss: 0.4133 - val_accuracy: 0.7966\n",
      "Epoch 2614/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1874 - accuracy: 0.9265 - val_loss: 0.4133 - val_accuracy: 0.7966\n",
      "Epoch 2615/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1874 - accuracy: 0.9265 - val_loss: 0.4133 - val_accuracy: 0.7966\n",
      "Epoch 2616/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1874 - accuracy: 0.9265 - val_loss: 0.4133 - val_accuracy: 0.7966\n",
      "Epoch 2617/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1873 - accuracy: 0.9265 - val_loss: 0.4133 - val_accuracy: 0.7966\n",
      "Epoch 2618/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1873 - accuracy: 0.9265 - val_loss: 0.4134 - val_accuracy: 0.7966\n",
      "Epoch 2619/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1873 - accuracy: 0.9265 - val_loss: 0.4134 - val_accuracy: 0.7966\n",
      "Epoch 2620/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1873 - accuracy: 0.9265 - val_loss: 0.4134 - val_accuracy: 0.7966\n",
      "Epoch 2621/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1873 - accuracy: 0.9265 - val_loss: 0.4134 - val_accuracy: 0.7966\n",
      "Epoch 2622/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1873 - accuracy: 0.9265 - val_loss: 0.4134 - val_accuracy: 0.7966\n",
      "Epoch 2623/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1873 - accuracy: 0.9265 - val_loss: 0.4134 - val_accuracy: 0.7966\n",
      "Epoch 2624/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1873 - accuracy: 0.9265 - val_loss: 0.4134 - val_accuracy: 0.7966\n",
      "Epoch 2625/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1872 - accuracy: 0.9265 - val_loss: 0.4134 - val_accuracy: 0.7966\n",
      "Epoch 2626/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1872 - accuracy: 0.9265 - val_loss: 0.4134 - val_accuracy: 0.7966\n",
      "Epoch 2627/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1872 - accuracy: 0.9265 - val_loss: 0.4134 - val_accuracy: 0.7966\n",
      "Epoch 2628/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1872 - accuracy: 0.9265 - val_loss: 0.4134 - val_accuracy: 0.7966\n",
      "Epoch 2629/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1872 - accuracy: 0.9265 - val_loss: 0.4134 - val_accuracy: 0.7966\n",
      "Epoch 2630/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1872 - accuracy: 0.9265 - val_loss: 0.4134 - val_accuracy: 0.7966\n",
      "Epoch 2631/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1872 - accuracy: 0.9265 - val_loss: 0.4134 - val_accuracy: 0.7966\n",
      "Epoch 2632/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1872 - accuracy: 0.9265 - val_loss: 0.4134 - val_accuracy: 0.7966\n",
      "Epoch 2633/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1872 - accuracy: 0.9265 - val_loss: 0.4134 - val_accuracy: 0.7966\n",
      "Epoch 2634/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1871 - accuracy: 0.9265 - val_loss: 0.4134 - val_accuracy: 0.7966\n",
      "Epoch 2635/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1871 - accuracy: 0.9265 - val_loss: 0.4134 - val_accuracy: 0.7966\n",
      "Epoch 2636/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1871 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2637/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1871 - accuracy: 0.9265 - val_loss: 0.4134 - val_accuracy: 0.7966\n",
      "Epoch 2638/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1871 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2639/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1871 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2640/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1871 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2641/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1871 - accuracy: 0.9265 - val_loss: 0.4134 - val_accuracy: 0.7966\n",
      "Epoch 2642/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1871 - accuracy: 0.9265 - val_loss: 0.4134 - val_accuracy: 0.7966\n",
      "Epoch 2643/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1870 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2644/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1870 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2645/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1870 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2646/4000\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.1807 - accuracy: 0.93 - 0s 51us/step - loss: 0.1870 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2647/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1870 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2648/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1870 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2649/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1870 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2650/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1870 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2651/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1869 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2652/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1869 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2653/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1869 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2654/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1869 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2655/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1869 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2656/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1869 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2657/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1869 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2658/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1869 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2659/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1869 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2660/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1868 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2661/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1868 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2662/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1868 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2663/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1868 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2664/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1868 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2665/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1868 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2666/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1868 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2667/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1868 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2668/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1867 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2669/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1867 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2670/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1867 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2671/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1867 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2672/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1867 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2673/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1867 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2674/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1867 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2675/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1867 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2676/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1867 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2677/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1866 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2678/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1866 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2679/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1866 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2680/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1866 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2681/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1866 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2682/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1866 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2683/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1866 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2684/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1866 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2685/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1866 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2686/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1865 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2687/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1865 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2688/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1865 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2689/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1865 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2690/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1865 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2691/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1865 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2692/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1865 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2693/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1865 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2694/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1865 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2695/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1864 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2696/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1864 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2697/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1864 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2698/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1864 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2699/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1864 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2700/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1864 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2701/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1864 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2702/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1864 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2703/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1864 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2704/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1863 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2705/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1863 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2706/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1863 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2707/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1863 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2708/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1863 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2709/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1863 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2710/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1863 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2711/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1863 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2712/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1863 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2713/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1862 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2714/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1862 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2715/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1862 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2716/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1862 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2717/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1862 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2718/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1862 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2719/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1862 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2720/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1862 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2721/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1861 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2722/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1861 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2723/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1861 - accuracy: 0.9265 - val_loss: 0.4135 - val_accuracy: 0.7966\n",
      "Epoch 2724/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1861 - accuracy: 0.9265 - val_loss: 0.4134 - val_accuracy: 0.7966\n",
      "Epoch 2725/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1861 - accuracy: 0.9265 - val_loss: 0.4134 - val_accuracy: 0.7966\n",
      "Epoch 2726/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1861 - accuracy: 0.9265 - val_loss: 0.4134 - val_accuracy: 0.7966\n",
      "Epoch 2727/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1861 - accuracy: 0.9265 - val_loss: 0.4134 - val_accuracy: 0.7966\n",
      "Epoch 2728/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1861 - accuracy: 0.9265 - val_loss: 0.4134 - val_accuracy: 0.7966\n",
      "Epoch 2729/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1860 - accuracy: 0.9265 - val_loss: 0.4134 - val_accuracy: 0.7966\n",
      "Epoch 2730/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1860 - accuracy: 0.9265 - val_loss: 0.4134 - val_accuracy: 0.7966\n",
      "Epoch 2731/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1860 - accuracy: 0.9265 - val_loss: 0.4134 - val_accuracy: 0.7966\n",
      "Epoch 2732/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1860 - accuracy: 0.9265 - val_loss: 0.4134 - val_accuracy: 0.7966\n",
      "Epoch 2733/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1860 - accuracy: 0.9265 - val_loss: 0.4134 - val_accuracy: 0.7966\n",
      "Epoch 2734/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1860 - accuracy: 0.9265 - val_loss: 0.4134 - val_accuracy: 0.7966\n",
      "Epoch 2735/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1860 - accuracy: 0.9265 - val_loss: 0.4134 - val_accuracy: 0.7966\n",
      "Epoch 2736/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1860 - accuracy: 0.9265 - val_loss: 0.4133 - val_accuracy: 0.7966\n",
      "Epoch 2737/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1860 - accuracy: 0.9265 - val_loss: 0.4133 - val_accuracy: 0.7966\n",
      "Epoch 2738/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1859 - accuracy: 0.9265 - val_loss: 0.4133 - val_accuracy: 0.7966\n",
      "Epoch 2739/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1859 - accuracy: 0.9265 - val_loss: 0.4133 - val_accuracy: 0.7966\n",
      "Epoch 2740/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1859 - accuracy: 0.9265 - val_loss: 0.4133 - val_accuracy: 0.7966\n",
      "Epoch 2741/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1859 - accuracy: 0.9265 - val_loss: 0.4133 - val_accuracy: 0.7966\n",
      "Epoch 2742/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1859 - accuracy: 0.9265 - val_loss: 0.4133 - val_accuracy: 0.7966\n",
      "Epoch 2743/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1859 - accuracy: 0.9265 - val_loss: 0.4133 - val_accuracy: 0.7966\n",
      "Epoch 2744/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1859 - accuracy: 0.9265 - val_loss: 0.4133 - val_accuracy: 0.7966\n",
      "Epoch 2745/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1859 - accuracy: 0.9265 - val_loss: 0.4133 - val_accuracy: 0.7966\n",
      "Epoch 2746/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1858 - accuracy: 0.9265 - val_loss: 0.4133 - val_accuracy: 0.7966\n",
      "Epoch 2747/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1858 - accuracy: 0.9265 - val_loss: 0.4132 - val_accuracy: 0.7966\n",
      "Epoch 2748/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1858 - accuracy: 0.9265 - val_loss: 0.4132 - val_accuracy: 0.7966\n",
      "Epoch 2749/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1858 - accuracy: 0.9265 - val_loss: 0.4132 - val_accuracy: 0.7966\n",
      "Epoch 2750/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1858 - accuracy: 0.9265 - val_loss: 0.4132 - val_accuracy: 0.7966\n",
      "Epoch 2751/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1858 - accuracy: 0.9265 - val_loss: 0.4132 - val_accuracy: 0.7966\n",
      "Epoch 2752/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1858 - accuracy: 0.9265 - val_loss: 0.4132 - val_accuracy: 0.7966\n",
      "Epoch 2753/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1858 - accuracy: 0.9265 - val_loss: 0.4132 - val_accuracy: 0.7966\n",
      "Epoch 2754/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1857 - accuracy: 0.9265 - val_loss: 0.4132 - val_accuracy: 0.7966\n",
      "Epoch 2755/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1857 - accuracy: 0.9265 - val_loss: 0.4132 - val_accuracy: 0.7966\n",
      "Epoch 2756/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1857 - accuracy: 0.9265 - val_loss: 0.4132 - val_accuracy: 0.7966\n",
      "Epoch 2757/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1857 - accuracy: 0.9265 - val_loss: 0.4132 - val_accuracy: 0.7966\n",
      "Epoch 2758/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1857 - accuracy: 0.9265 - val_loss: 0.4132 - val_accuracy: 0.7966\n",
      "Epoch 2759/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1857 - accuracy: 0.9265 - val_loss: 0.4132 - val_accuracy: 0.7966\n",
      "Epoch 2760/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1857 - accuracy: 0.9265 - val_loss: 0.4131 - val_accuracy: 0.7966\n",
      "Epoch 2761/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1857 - accuracy: 0.9265 - val_loss: 0.4131 - val_accuracy: 0.7966\n",
      "Epoch 2762/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1856 - accuracy: 0.9265 - val_loss: 0.4131 - val_accuracy: 0.7966\n",
      "Epoch 2763/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1856 - accuracy: 0.9265 - val_loss: 0.4131 - val_accuracy: 0.7966\n",
      "Epoch 2764/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1856 - accuracy: 0.9265 - val_loss: 0.4131 - val_accuracy: 0.7966\n",
      "Epoch 2765/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1856 - accuracy: 0.9265 - val_loss: 0.4131 - val_accuracy: 0.7966\n",
      "Epoch 2766/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1856 - accuracy: 0.9265 - val_loss: 0.4131 - val_accuracy: 0.7966\n",
      "Epoch 2767/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1856 - accuracy: 0.9265 - val_loss: 0.4131 - val_accuracy: 0.7966\n",
      "Epoch 2768/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1856 - accuracy: 0.9265 - val_loss: 0.4131 - val_accuracy: 0.7966\n",
      "Epoch 2769/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1856 - accuracy: 0.9265 - val_loss: 0.4131 - val_accuracy: 0.7966\n",
      "Epoch 2770/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1856 - accuracy: 0.9265 - val_loss: 0.4131 - val_accuracy: 0.7966\n",
      "Epoch 2771/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1855 - accuracy: 0.9265 - val_loss: 0.4131 - val_accuracy: 0.7966\n",
      "Epoch 2772/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1855 - accuracy: 0.9265 - val_loss: 0.4130 - val_accuracy: 0.7966\n",
      "Epoch 2773/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1855 - accuracy: 0.9265 - val_loss: 0.4130 - val_accuracy: 0.7966\n",
      "Epoch 2774/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1855 - accuracy: 0.9265 - val_loss: 0.4130 - val_accuracy: 0.7966\n",
      "Epoch 2775/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1855 - accuracy: 0.9265 - val_loss: 0.4130 - val_accuracy: 0.7966\n",
      "Epoch 2776/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1855 - accuracy: 0.9265 - val_loss: 0.4130 - val_accuracy: 0.7966\n",
      "Epoch 2777/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1855 - accuracy: 0.9265 - val_loss: 0.4130 - val_accuracy: 0.7966\n",
      "Epoch 2778/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1855 - accuracy: 0.9265 - val_loss: 0.4130 - val_accuracy: 0.7966\n",
      "Epoch 2779/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1854 - accuracy: 0.9265 - val_loss: 0.4130 - val_accuracy: 0.7966\n",
      "Epoch 2780/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1854 - accuracy: 0.9265 - val_loss: 0.4130 - val_accuracy: 0.7966\n",
      "Epoch 2781/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1854 - accuracy: 0.9265 - val_loss: 0.4130 - val_accuracy: 0.7966\n",
      "Epoch 2782/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1854 - accuracy: 0.9265 - val_loss: 0.4130 - val_accuracy: 0.7966\n",
      "Epoch 2783/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1854 - accuracy: 0.9265 - val_loss: 0.4130 - val_accuracy: 0.7966\n",
      "Epoch 2784/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1854 - accuracy: 0.9265 - val_loss: 0.4130 - val_accuracy: 0.7966\n",
      "Epoch 2785/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1854 - accuracy: 0.9265 - val_loss: 0.4130 - val_accuracy: 0.7966\n",
      "Epoch 2786/4000\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.1786 - accuracy: 0.93 - 0s 59us/step - loss: 0.1854 - accuracy: 0.9265 - val_loss: 0.4130 - val_accuracy: 0.7966\n",
      "Epoch 2787/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1854 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 2788/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1853 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 2789/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1853 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 2790/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1853 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 2791/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1853 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 2792/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1853 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 2793/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1853 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 2794/4000\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.1784 - accuracy: 0.93 - 0s 59us/step - loss: 0.1853 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 2795/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1853 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 2796/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1852 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 2797/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1852 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 2798/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1852 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 2799/4000\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.1784 - accuracy: 0.93 - 0s 51us/step - loss: 0.1852 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 2800/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1852 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 2801/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1852 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 2802/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1852 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 2803/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1852 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 2804/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1852 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 2805/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1851 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 2806/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1851 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 2807/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1851 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 2808/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1851 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 2809/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1851 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 2810/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1851 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 2811/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1851 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 2812/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1851 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 2813/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1850 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 2814/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1850 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 2815/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1850 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 2816/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1850 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 2817/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1850 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 2818/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1850 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 2819/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1850 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 2820/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1850 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 2821/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1850 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 2822/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1849 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 2823/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1849 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 2824/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1849 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 2825/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1849 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 2826/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1849 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 2827/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1849 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 2828/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1849 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 2829/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1849 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 2830/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1848 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 2831/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1848 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 2832/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1848 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 2833/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1848 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 2834/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1848 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 2835/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1848 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 2836/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1848 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 2837/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1848 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 2838/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1848 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 2839/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1847 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 2840/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1847 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 2841/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1847 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 2842/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1847 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 2843/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1847 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 2844/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1847 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 2845/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1847 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 2846/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1847 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 2847/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1847 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 2848/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1846 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 2849/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1846 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 2850/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1846 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 2851/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1846 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 2852/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1846 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 2853/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1846 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 2854/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1846 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 2855/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1846 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 2856/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1845 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 2857/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1845 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 2858/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1845 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 2859/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1845 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 2860/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1845 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 2861/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1845 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 2862/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1845 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 2863/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1845 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 2864/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1845 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 2865/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1844 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 2866/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1844 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 2867/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1844 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 2868/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1844 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 2869/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1844 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 2870/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1844 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 2871/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1844 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 2872/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1844 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 2873/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1844 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 2874/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1843 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 2875/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1843 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 2876/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1843 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 2877/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1843 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 2878/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1843 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 2879/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1843 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 2880/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1843 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 2881/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1843 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 2882/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1843 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 2883/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1842 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 2884/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1842 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 2885/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1842 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 2886/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1842 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 2887/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1842 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 2888/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1842 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 2889/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1842 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 2890/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1842 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 2891/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1842 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 2892/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1841 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 2893/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1841 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 2894/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1841 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 2895/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1841 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 2896/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1841 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 2897/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1841 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 2898/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1841 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 2899/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1841 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 2900/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1841 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 2901/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1840 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 2902/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1840 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 2903/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1840 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 2904/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1840 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 2905/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1840 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 2906/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1840 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 2907/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1840 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 2908/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1840 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 2909/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1839 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 2910/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1839 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 2911/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1839 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 2912/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1839 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 2913/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1839 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 2914/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1839 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 2915/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1839 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 2916/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1839 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 2917/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1839 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 2918/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1838 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 2919/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1838 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 2920/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1838 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 2921/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1838 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 2922/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1838 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 2923/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1838 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 2924/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1838 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 2925/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1838 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 2926/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1838 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 2927/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1837 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 2928/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1837 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 2929/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1837 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 2930/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1837 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 2931/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1837 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 2932/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1837 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 2933/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1837 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 2934/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1837 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 2935/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1837 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 2936/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1837 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 2937/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1836 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 2938/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1836 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 2939/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1836 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 2940/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1836 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 2941/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1836 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 2942/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1836 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 2943/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1836 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 2944/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1836 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 2945/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1836 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 2946/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1835 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 2947/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1835 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 2948/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1835 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 2949/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1835 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 2950/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1835 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2951/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1835 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2952/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1835 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2953/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1835 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2954/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1835 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2955/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1834 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2956/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1834 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2957/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1834 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2958/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1834 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2959/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1834 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2960/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1834 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2961/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1834 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2962/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1834 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2963/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1834 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2964/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1833 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2965/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1833 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2966/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1833 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2967/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1833 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2968/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1833 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2969/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1833 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2970/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1833 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2971/4000\n",
      "136/136 [==============================] - 0s 88us/step - loss: 0.1833 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2972/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1833 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2973/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1832 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2974/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1832 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2975/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1832 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2976/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1832 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2977/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1832 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2978/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1832 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2979/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1832 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2980/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1832 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2981/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1832 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2982/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1831 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2983/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1831 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2984/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1831 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2985/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1831 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2986/4000\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.1759 - accuracy: 0.93 - 0s 51us/step - loss: 0.1831 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2987/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1831 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2988/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1831 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2989/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1831 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 2990/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1831 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 2991/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1830 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2992/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1830 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 2993/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1830 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 2994/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1830 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 2995/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1830 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 2996/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1830 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 2997/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1830 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 2998/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1830 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 2999/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1830 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3000/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1830 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3001/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1829 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3002/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1829 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3003/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1829 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3004/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1829 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3005/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1829 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3006/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1829 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3007/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1829 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3008/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1829 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3009/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1829 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3010/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1828 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3011/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1828 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3012/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1828 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3013/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1828 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3014/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1828 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3015/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1828 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3016/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1828 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3017/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1828 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3018/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1828 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3019/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1827 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3020/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1827 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3021/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1827 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3022/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1827 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3023/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1827 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3024/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1827 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3025/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1827 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3026/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1827 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3027/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1827 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3028/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1827 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3029/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1826 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3030/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1826 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3031/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1826 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3032/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1826 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3033/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1826 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3034/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1826 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3035/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1826 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3036/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1826 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3037/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1826 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3038/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1825 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3039/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1825 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3040/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1825 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3041/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1825 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3042/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1825 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3043/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1825 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3044/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1825 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3045/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1825 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3046/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1825 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3047/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1825 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3048/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1824 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3049/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1824 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3050/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1824 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3051/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1824 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3052/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1824 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3053/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1824 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3054/4000\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.1751 - accuracy: 0.93 - 0s 44us/step - loss: 0.1824 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3055/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1824 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3056/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1824 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3057/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1823 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3058/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1823 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3059/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1823 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3060/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1823 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3061/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1823 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3062/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1823 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3063/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1823 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3064/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1823 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3065/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1823 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3066/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1823 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3067/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1822 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3068/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1822 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3069/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1822 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3070/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1822 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3071/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1822 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3072/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1822 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3073/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1822 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3074/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1822 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3075/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1822 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3076/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1821 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3077/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1821 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3078/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1821 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3079/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1821 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3080/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1821 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3081/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1821 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3082/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1821 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3083/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1821 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3084/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1821 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3085/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1821 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3086/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1820 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3087/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1820 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3088/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1820 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3089/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1820 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3090/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1820 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3091/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1820 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3092/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1820 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3093/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1820 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3094/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1820 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3095/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1819 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3096/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1819 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3097/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1819 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3098/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1819 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3099/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1819 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3100/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1819 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3101/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1819 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3102/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1819 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3103/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1819 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3104/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1819 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3105/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1818 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3106/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1818 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3107/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1818 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3108/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1818 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3109/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1818 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3110/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1818 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3111/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1818 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3112/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1818 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3113/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1818 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3114/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1818 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3115/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1817 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3116/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1817 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3117/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1817 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3118/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1817 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3119/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1817 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3120/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1817 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3121/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1817 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3122/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1817 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3123/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1817 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3124/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1816 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3125/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1816 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3126/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1816 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3127/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1816 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3128/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1816 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3129/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1816 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3130/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1816 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3131/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1816 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3132/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1816 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3133/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1816 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3134/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1815 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3135/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1815 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3136/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1815 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3137/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1815 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3138/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1815 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3139/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1815 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3140/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1815 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3141/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1815 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3142/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1815 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3143/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1815 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3144/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1814 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3145/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1814 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3146/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1814 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3147/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1814 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3148/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1814 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3149/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1814 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3150/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1814 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3151/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1814 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3152/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1814 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3153/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1814 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3154/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1813 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3155/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1813 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3156/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1813 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3157/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1813 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3158/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1813 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3159/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1813 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3160/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1813 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3161/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1813 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3162/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1813 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3163/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1812 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3164/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1812 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3165/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1812 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3166/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1812 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3167/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1812 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3168/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1812 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3169/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1812 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3170/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1812 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3171/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1812 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3172/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1812 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3173/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1811 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3174/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1811 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3175/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1811 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3176/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1811 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3177/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1811 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3178/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1811 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3179/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1811 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3180/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1811 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3181/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1811 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3182/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1811 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3183/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1810 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3184/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1810 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3185/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1810 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3186/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1810 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3187/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1810 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3188/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1810 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3189/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1810 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3190/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1810 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3191/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1810 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3192/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1810 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3193/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1809 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3194/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1809 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3195/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1809 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3196/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1809 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3197/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1809 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3198/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1809 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3199/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1809 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3200/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1809 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3201/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1809 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3202/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1809 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3203/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1808 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3204/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1808 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3205/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1808 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3206/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1808 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3207/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1808 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3208/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1808 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3209/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1808 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3210/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1808 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3211/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1808 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3212/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1808 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3213/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1807 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3214/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1807 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3215/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1807 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3216/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1807 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3217/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1807 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3218/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1807 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3219/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1807 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3220/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1807 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3221/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1807 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3222/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1807 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3223/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1806 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3224/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1806 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3225/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1806 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3226/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1806 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3227/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1806 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3228/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1806 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3229/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1806 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3230/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1806 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3231/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1806 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3232/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1806 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3233/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1805 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3234/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1805 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3235/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1805 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3236/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1805 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3237/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1805 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3238/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1805 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3239/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1805 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3240/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1805 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3241/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1805 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3242/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1805 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3243/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1805 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3244/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1804 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3245/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1804 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3246/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1804 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3247/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1804 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3248/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1804 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3249/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1804 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3250/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1804 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3251/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1804 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3252/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1804 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3253/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1804 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3254/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1803 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3255/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1803 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3256/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1803 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3257/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1803 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3258/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1803 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3259/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1803 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3260/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1803 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3261/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1803 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3262/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1803 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3263/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1803 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3264/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1803 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3265/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1802 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3266/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1802 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3267/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1802 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3268/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1802 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3269/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1802 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3270/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1802 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3271/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1802 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3272/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1802 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3273/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1802 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3274/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1802 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3275/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1801 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3276/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1801 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3277/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1801 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3278/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1801 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3279/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1801 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3280/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1801 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3281/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1801 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3282/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1801 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3283/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1801 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3284/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1801 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3285/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1801 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3286/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1800 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3287/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1800 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3288/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1800 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3289/4000\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.1724 - accuracy: 0.93 - 0s 44us/step - loss: 0.1800 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3290/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1800 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3291/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1800 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3292/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1800 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3293/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1800 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3294/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1800 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3295/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1800 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3296/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1800 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3297/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1799 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3298/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1799 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3299/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1799 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3300/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1799 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3301/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1799 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3302/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1799 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3303/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1799 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3304/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1799 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3305/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1799 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3306/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1799 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3307/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1798 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3308/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1798 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3309/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1798 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3310/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1798 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3311/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1798 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3312/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1798 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3313/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1798 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3314/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1798 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3315/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1798 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3316/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1798 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3317/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1798 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3318/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1797 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3319/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1797 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3320/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1797 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3321/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1797 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3322/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1797 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3323/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1797 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3324/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1797 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3325/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1797 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3326/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1797 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3327/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1797 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3328/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1797 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3329/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1796 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3330/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1796 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3331/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1796 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3332/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1796 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3333/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1796 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3334/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1796 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3335/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1796 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3336/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1796 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3337/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1796 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3338/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1796 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3339/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1796 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3340/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1795 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3341/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1795 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3342/4000\n",
      "136/136 [==============================] - 0s 73us/step - loss: 0.1795 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3343/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1795 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3344/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1795 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3345/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1795 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3346/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1795 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3347/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1795 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3348/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1795 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3349/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1795 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3350/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1795 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3351/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1794 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3352/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1794 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3353/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1794 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3354/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1794 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3355/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1794 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3356/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1794 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3357/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1794 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3358/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1794 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3359/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1794 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3360/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1794 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3361/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1794 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3362/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1793 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3363/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1793 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3364/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1793 - accuracy: 0.9338 - val_loss: 0.4119 - val_accuracy: 0.7966\n",
      "Epoch 3365/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1793 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3366/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1793 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3367/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1793 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3368/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1793 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3369/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1793 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3370/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1793 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3371/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1793 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3372/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1793 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3373/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1792 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3374/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1792 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3375/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1792 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3376/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1792 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3377/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1792 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3378/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1792 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3379/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1792 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3380/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1792 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3381/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1792 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3382/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1792 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3383/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1792 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3384/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1791 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3385/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1791 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3386/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1791 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3387/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1791 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3388/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1791 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3389/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1791 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3390/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1791 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3391/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1791 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3392/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1791 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3393/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1791 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3394/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1791 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3395/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1790 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3396/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1790 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3397/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1790 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3398/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1790 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3399/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1790 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3400/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1790 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3401/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1790 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3402/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1790 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3403/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1790 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3404/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1790 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3405/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1790 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3406/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1789 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3407/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1789 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3408/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1789 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3409/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1789 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3410/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1789 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3411/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1789 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3412/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1789 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3413/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1789 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3414/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1789 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3415/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1789 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3416/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1789 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3417/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1788 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3418/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1788 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3419/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1788 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3420/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1788 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3421/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1788 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3422/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1788 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3423/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1788 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3424/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1788 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3425/4000\n",
      "136/136 [==============================] - 0s 73us/step - loss: 0.1788 - accuracy: 0.9338 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3426/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1788 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3427/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1788 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3428/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1787 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3429/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1787 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3430/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1787 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3431/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1787 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3432/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1787 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3433/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1787 - accuracy: 0.9265 - val_loss: 0.4120 - val_accuracy: 0.7966\n",
      "Epoch 3434/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1787 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3435/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1787 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3436/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1787 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3437/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1787 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3438/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1787 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3439/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1787 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3440/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1786 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3441/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1786 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3442/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1786 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3443/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1786 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3444/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1786 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3445/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1786 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3446/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1786 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3447/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1786 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3448/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1786 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3449/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1786 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3450/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1786 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3451/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1785 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3452/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1785 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3453/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1785 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3454/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1785 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3455/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1785 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3456/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1785 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3457/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1785 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3458/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1785 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3459/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1785 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3460/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1785 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3461/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1785 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3462/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1784 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3463/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1784 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3464/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1784 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3465/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1784 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3466/4000\n",
      "136/136 [==============================] - 0s 73us/step - loss: 0.1784 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3467/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1784 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3468/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1784 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3469/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1784 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3470/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1784 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3471/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1784 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3472/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1784 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3473/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1784 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3474/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1783 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3475/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1783 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3476/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1783 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3477/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1783 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3478/4000\n",
      "136/136 [==============================] - 0s 53us/step - loss: 0.1783 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3479/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1783 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3480/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1783 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3481/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1783 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3482/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1783 - accuracy: 0.9265 - val_loss: 0.4121 - val_accuracy: 0.7966\n",
      "Epoch 3483/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1783 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3484/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1783 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3485/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1782 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3486/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1782 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3487/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1782 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3488/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1782 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3489/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1782 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3490/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1782 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3491/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1782 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3492/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1782 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3493/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1782 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3494/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1782 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3495/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1782 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3496/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1782 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3497/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1781 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3498/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1781 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3499/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1781 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3500/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1781 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3501/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1781 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3502/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1781 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3503/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1781 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3504/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1781 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3505/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1781 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3506/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1781 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3507/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1781 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3508/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1780 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3509/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1780 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3510/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1780 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3511/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1780 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3512/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1780 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3513/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1780 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3514/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1780 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3515/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1780 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3516/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1780 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3517/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1780 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3518/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1780 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3519/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1780 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3520/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1779 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3521/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1779 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3522/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1779 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3523/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1779 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3524/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1779 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3525/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1779 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3526/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1779 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3527/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1779 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3528/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1779 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3529/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1779 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3530/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1779 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3531/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1778 - accuracy: 0.9265 - val_loss: 0.4122 - val_accuracy: 0.7966\n",
      "Epoch 3532/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1778 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 3533/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1778 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 3534/4000\n",
      "136/136 [==============================] - 0s 73us/step - loss: 0.1778 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 3535/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1778 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 3536/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1778 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 3537/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1778 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 3538/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1778 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 3539/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1778 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 3540/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1778 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 3541/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1778 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 3542/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1778 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 3543/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1777 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 3544/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1777 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 3545/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1777 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 3546/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1777 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 3547/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1777 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 3548/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1777 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 3549/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1777 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 3550/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1777 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 3551/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1777 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 3552/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1777 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 3553/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1777 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 3554/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1776 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 3555/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1776 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 3556/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1776 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 3557/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1776 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 3558/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1776 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 3559/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1776 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 3560/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1776 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 3561/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1776 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 3562/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1776 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 3563/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1776 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 3564/4000\n",
      "136/136 [==============================] - 0s 32us/step - loss: 0.1776 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 3565/4000\n",
      "136/136 [==============================] - 0s 90us/step - loss: 0.1776 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 3566/4000\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.1694 - accuracy: 0.93 - 0s 52us/step - loss: 0.1775 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 3567/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1775 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 3568/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1775 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 3569/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1775 - accuracy: 0.9265 - val_loss: 0.4123 - val_accuracy: 0.7966\n",
      "Epoch 3570/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1775 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3571/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1775 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3572/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1775 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3573/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1775 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3574/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1775 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3575/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1775 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3576/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1775 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3577/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1775 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3578/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1774 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3579/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1774 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3580/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1774 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3581/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1774 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3582/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1774 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3583/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1774 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3584/4000\n",
      "136/136 [==============================] - 0s 110us/step - loss: 0.1774 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3585/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1774 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3586/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1774 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3587/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1774 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3588/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1774 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3589/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1774 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3590/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1773 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3591/4000\n",
      "136/136 [==============================] - 0s 73us/step - loss: 0.1773 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3592/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1773 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3593/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1773 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3594/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1773 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3595/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1773 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3596/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1773 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3597/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1773 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3598/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1773 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3599/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1773 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3600/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1773 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3601/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1773 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3602/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1772 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3603/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1772 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3604/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1772 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3605/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1772 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3606/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1772 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3607/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1772 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3608/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1772 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3609/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1772 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3610/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1772 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3611/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1772 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3612/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1772 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3613/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1772 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3614/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1771 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3615/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1771 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3616/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1771 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3617/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1771 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3618/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1771 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3619/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1771 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3620/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1771 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3621/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1771 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3622/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1771 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3623/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1771 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3624/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1771 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3625/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1771 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3626/4000\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.1687 - accuracy: 0.93 - 0s 58us/step - loss: 0.1770 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3627/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1770 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3628/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1770 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3629/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1770 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3630/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1770 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3631/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1770 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3632/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1770 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3633/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1770 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3634/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1770 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3635/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1770 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3636/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1770 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3637/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1770 - accuracy: 0.9265 - val_loss: 0.4124 - val_accuracy: 0.7966\n",
      "Epoch 3638/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1769 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3639/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1769 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3640/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1769 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3641/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1769 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3642/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1769 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3643/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1769 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3644/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1769 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3645/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1769 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3646/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1769 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3647/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1769 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3648/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1769 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3649/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1769 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3650/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1769 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3651/4000\n",
      "136/136 [==============================] - 0s 55us/step - loss: 0.1768 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3652/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1768 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3653/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1768 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3654/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1768 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3655/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1768 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3656/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1768 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3657/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1768 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3658/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1768 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3659/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1768 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3660/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1768 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3661/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1768 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3662/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1768 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3663/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1767 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3664/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1767 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3665/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1767 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3666/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1767 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3667/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1767 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3668/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1767 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3669/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1767 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3670/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1767 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3671/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1767 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3672/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1767 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3673/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1767 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3674/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1767 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3675/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1766 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3676/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1766 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3677/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1766 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3678/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1766 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3679/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1766 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3680/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1766 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3681/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1766 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3682/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1766 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3683/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1766 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3684/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1766 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3685/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1766 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3686/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1766 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3687/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1766 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3688/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1765 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3689/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1765 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3690/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1765 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3691/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1765 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3692/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1765 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3693/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1765 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3694/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1765 - accuracy: 0.9265 - val_loss: 0.4125 - val_accuracy: 0.7966\n",
      "Epoch 3695/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1765 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3696/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1765 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3697/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1765 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3698/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1765 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3699/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1765 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3700/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1764 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3701/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1764 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3702/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1764 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3703/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1764 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3704/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1764 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3705/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1764 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3706/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1764 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3707/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1764 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3708/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1764 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3709/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1764 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3710/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1764 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3711/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1764 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3712/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1764 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3713/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1763 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3714/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1763 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3715/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1763 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3716/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1763 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3717/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1763 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3718/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1763 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3719/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1763 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3720/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1763 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3721/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1763 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3722/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1763 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3723/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1763 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3724/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1763 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3725/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1762 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3726/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1762 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3727/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1762 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3728/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1762 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3729/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1762 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3730/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1762 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3731/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1762 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3732/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1762 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3733/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1762 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3734/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1762 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3735/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1762 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3736/4000\n",
      "136/136 [==============================] - 0s 37us/step - loss: 0.1762 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3737/4000\n",
      "136/136 [==============================] - 0s 82us/step - loss: 0.1762 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3738/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1761 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3739/4000\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.1674 - accuracy: 0.93 - 0s 59us/step - loss: 0.1761 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3740/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1761 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3741/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1761 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3742/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1761 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3743/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1761 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3744/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1761 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3745/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1761 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3746/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1761 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3747/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1761 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3748/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1761 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3749/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1761 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3750/4000\n",
      "136/136 [==============================] - 0s 31us/step - loss: 0.1761 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3751/4000\n",
      "136/136 [==============================] - 0s 84us/step - loss: 0.1760 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3752/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1760 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3753/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1760 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3754/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1760 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3755/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1760 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3756/4000\n",
      "136/136 [==============================] - 0s 64us/step - loss: 0.1760 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3757/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1760 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3758/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1760 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3759/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1760 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3760/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1760 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3761/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1760 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3762/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1760 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3763/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1760 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3764/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1759 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3765/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1759 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3766/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1759 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3767/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1759 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3768/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1759 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3769/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1759 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3770/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1759 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3771/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1759 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3772/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1759 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3773/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1759 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3774/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1759 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3775/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1759 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3776/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1759 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3777/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1758 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3778/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1758 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3779/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1758 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3780/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1758 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3781/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1758 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3782/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1758 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3783/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1758 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3784/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1758 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3785/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1758 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3786/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1758 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3787/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1758 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3788/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1758 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3789/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1758 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3790/4000\n",
      "136/136 [==============================] - 0s 73us/step - loss: 0.1757 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3791/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1757 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3792/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1757 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3793/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1757 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3794/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1757 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3795/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1757 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3796/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1757 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3797/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1757 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3798/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1757 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3799/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1757 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3800/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1757 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3801/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1757 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3802/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1757 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3803/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1756 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3804/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1756 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3805/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1756 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3806/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1756 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3807/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1756 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3808/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1756 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3809/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1756 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3810/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1756 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3811/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1756 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3812/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1756 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3813/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1756 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3814/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1756 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3815/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1756 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3816/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1755 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3817/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1755 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3818/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1755 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3819/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1755 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3820/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1755 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3821/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1755 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3822/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1755 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3823/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1755 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3824/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1755 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3825/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1755 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3826/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1755 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3827/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1755 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3828/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1755 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3829/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1754 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3830/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1754 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3831/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1754 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3832/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1754 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3833/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1754 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3834/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1754 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3835/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1754 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3836/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1754 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3837/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1754 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3838/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1754 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3839/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1754 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3840/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1754 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3841/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1754 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3842/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1753 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3843/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1753 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3844/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1753 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3845/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1753 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3846/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1753 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3847/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1753 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3848/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1753 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3849/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1753 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3850/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1753 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3851/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1753 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3852/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1753 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3853/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1753 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3854/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1753 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3855/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1752 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3856/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1752 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3857/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1752 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3858/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1752 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3859/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1752 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3860/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1752 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3861/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1752 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3862/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1752 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3863/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1752 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3864/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1752 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3865/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1752 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3866/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1752 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3867/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1752 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3868/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1751 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3869/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1751 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3870/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1751 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3871/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1751 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3872/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1751 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3873/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1751 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3874/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1751 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3875/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1751 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3876/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1751 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3877/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1751 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3878/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1751 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3879/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1751 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3880/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1751 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3881/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1751 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3882/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1750 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3883/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1750 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3884/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1750 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3885/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1750 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3886/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1750 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3887/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1750 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3888/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1750 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3889/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1750 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3890/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1750 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3891/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1750 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3892/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1750 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3893/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1750 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3894/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1750 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3895/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1749 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3896/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1749 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3897/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1749 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3898/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1749 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3899/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1749 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3900/4000\n",
      "136/136 [==============================] - 0s 73us/step - loss: 0.1749 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3901/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1749 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3902/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1749 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3903/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1749 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3904/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1749 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3905/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1749 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3906/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1749 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3907/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1749 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3908/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1749 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3909/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1748 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3910/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1748 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3911/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1748 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3912/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1748 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3913/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1748 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3914/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1748 - accuracy: 0.9265 - val_loss: 0.4129 - val_accuracy: 0.7966\n",
      "Epoch 3915/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1748 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3916/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1748 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3917/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1748 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3918/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1748 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3919/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1748 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3920/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1748 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3921/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1748 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3922/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1748 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3923/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1747 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3924/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1747 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3925/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1747 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3926/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1747 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3927/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1747 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3928/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1747 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3929/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1747 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3930/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1747 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3931/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1747 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3932/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1747 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3933/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1747 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3934/4000\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.1654 - accuracy: 0.93 - 0s 66us/step - loss: 0.1747 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3935/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1747 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3936/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1747 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3937/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1746 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3938/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1746 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3939/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1746 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3940/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1746 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3941/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1746 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3942/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1746 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3943/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1746 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3944/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1746 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3945/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1746 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3946/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1746 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3947/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1746 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3948/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1746 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3949/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1746 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3950/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1746 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3951/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1745 - accuracy: 0.9265 - val_loss: 0.4128 - val_accuracy: 0.7966\n",
      "Epoch 3952/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1745 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3953/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1745 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3954/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1745 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3955/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1745 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3956/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1745 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3957/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1745 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3958/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1745 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3959/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1745 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3960/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1745 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3961/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1745 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3962/4000\n",
      "136/136 [==============================] - 0s 44us/step - loss: 0.1745 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3963/4000\n",
      "136/136 [==============================] - 0s 73us/step - loss: 0.1745 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3964/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1745 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3965/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1745 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3966/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1744 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3967/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1744 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3968/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1744 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3969/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1744 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3970/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1744 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3971/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1744 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3972/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1744 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3973/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1744 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3974/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1744 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3975/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1744 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3976/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1744 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3977/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1744 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3978/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1744 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3979/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1744 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3980/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1743 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3981/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1743 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3982/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1743 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3983/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1743 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3984/4000\n",
      "136/136 [==============================] - 0s 52us/step - loss: 0.1743 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3985/4000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 0.1743 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3986/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1743 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3987/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1743 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3988/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1743 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3989/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1743 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3990/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1743 - accuracy: 0.9265 - val_loss: 0.4127 - val_accuracy: 0.7966\n",
      "Epoch 3991/4000\n",
      "136/136 [==============================] - 0s 58us/step - loss: 0.1743 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3992/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1743 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3993/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1743 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3994/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1743 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3995/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1742 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3996/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1742 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3997/4000\n",
      "136/136 [==============================] - 0s 59us/step - loss: 0.1742 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3998/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1742 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 3999/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1742 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Epoch 4000/4000\n",
      "136/136 [==============================] - 0s 51us/step - loss: 0.1742 - accuracy: 0.9265 - val_loss: 0.4126 - val_accuracy: 0.7966\n",
      "Training neural network...\n",
      "\n",
      "Accuracy over training data is  0.9264705882352942\n",
      "Accuracy over testing data is  0.7966101694915254\n",
      "[[ 6  9]\n",
      " [ 3 41]]\n"
     ]
    }
   ],
   "source": [
    "neural_model.compile(SGD(lr = .003), \"binary_crossentropy\", \\\n",
    "                     metrics=[\"accuracy\"])\n",
    "\n",
    "np.random.seed(0)\n",
    "run_hist_1 = neural_model.fit(data_train, target_train, epochs=4000,\\\n",
    "                              validation_data=(data_test, target_test), \\\n",
    "                              verbose=True, shuffle=False)\n",
    "\n",
    "print(\"Training neural network...\\n\")\n",
    "\n",
    "print('Accuracy over training data is ', \\\n",
    "      accuracy_score(target_train, neural_model.predict_classes(data_train)))\n",
    "\n",
    "print('Accuracy over testing data is ', \\\n",
    "      accuracy_score(target_test, neural_model.predict_classes(data_test)))\n",
    "\n",
    "conf_matrix = confusion_matrix(target_test, neural_model.predict_classes(data_test))\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#run_hist_1.history.keys()\n",
    "\n",
    "plt.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "plt.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "plt.title(\"Train loss and validation error\")\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch'), plt.ylabel('Error')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can be oberved form the plot? Why would we might be interested in having longer training phase?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student task 1: \n",
    "- Learn more about [Dense](https://keras.io/layers/core/) layer, available [activation function](https://keras.io/activations/) and [optimizers](https://keras.io/optimizers/),\n",
    "- Build neural network with more then 4 layers having different activation function in each layer. Train it and visual the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build neural network with Keras using Sequential model with Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 2)                 46        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model with dropouts\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "neural_network_d = Sequential()\n",
    "neural_network_d.add(Dense(2, activation='relu', input_shape=(22,)))\n",
    "# neural_network_d.add(Dropout(0.1))\n",
    "neural_network_d.add(Dense(2, activation='selu'))\n",
    "# neural_network_d.add(Dropout(0.1))\n",
    "neural_network_d.add(Dense(2, activation='linear'))\n",
    "# neural_network_d.add(Dropout(0.1))\n",
    "neural_network_d.add(Dense(1, activation='sigmoid'))\n",
    "# neural_network_d.add(Dropout(0.1))\n",
    "\n",
    "neural_network_d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training neural network w dropouts..\n",
      "\n",
      "Accuracy over training data is  0.9632352941176471\n",
      "Accuracy over testing data is  0.8305084745762712\n"
     ]
    }
   ],
   "source": [
    "neural_network_d.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "run_hist_2 = neural_network_d.fit(data_train, target_train, epochs=4000, \\\n",
    "                                  validation_data=(data_test, target_test), \\\n",
    "                                  verbose=False, shuffle=False)\n",
    "\n",
    "print(\"Training neural network w dropouts..\\n\")\n",
    "\n",
    "print('Accuracy over training data is ', accuracy_score(target_train, \\\n",
    "                                                        neural_network_d.predict_classes(data_train)))\n",
    "\n",
    "print('Accuracy over testing data is ', accuracy_score(target_test, \\\n",
    "                                                       neural_network_d.predict_classes(data_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXxV5bXw8d9KyCAkgARFFDV4q1eZZCqYq8UgvKg4tdZWuGKrleJQ2+tUod6+rVpr1VbltbUO5dahUNBqba2F4hUTh5qKgIoIWqhCG0GGgJAwhSTr/WM/CTsnZ86Zs76fz/lkT+fZ6+yzs86zn/3svUVVMcYYk/3y0h2AMcaYxLCEbowxOcISujHG5AhL6MYYkyMsoRtjTI6whG6MMTnCEnoCiUi+iDSIyDFxvPdzIpKVfUhF5A4ReTwJ5c4VkVvdcKWIvB/NsnGsJ+7vLZeIyP8VkYfDzJ8uItWdKD/u78hEp0sndPdP3PpqEZG9vvFLYi1PVZtVtURV/5mMeLsyVa1W1cGJKEtEXheRy3xl2/cGqOqPVPUqyO4KRqySVSFJh27pDiCdVLWkdVhE1gPTVfWlUMuLSDdVbUpFbKbrCbZ/xbrPZes+mq1xZ5ouXUOPxP1yPyUi80WkHpgmIhUi8jcR+UxENonIAyJS4JbvJiIqIuVufK6bv0hE6kWkRkQGRrnuASLygohsF5G1IvIN37xTRGSFiOwSkc0i8lM3vbuI/FZE6lx8S0Wkb4jyvy8iH7m43heR833zpovIKyJyvyvnIxGZ5Jt/nIi85t67GCgL8znWishZvvFC95mGiUieiDwjIp+69VSLyEkhypnofnRbx0eJyDsuhvlAkW9emYgsFJGtIrJDRP4kIke5eXcDFcDD7khsdpDvrbf77raKyHoR+Z6ISDTbJkjcA0TkOVfWxyLyLd+8YPtXsGnFbj/aJCKfiMh9IlLo3y4icouIfAr8KkgMtSJyshu+zH3WE9z4VSLyjC+ex93bXnXTWo9YP3+wuKg/e7jvKGjcLp51bh/+g4j0d9Nbv6Nvu+24TUTuEpE8Nz9PRH4gIhtEZIuIPC4iPYPtO75tUiki5wI3A5e4z7nczb/CxVfvPueUUJ8zo6iqvbzbH6wHJgZMuwNoBM7D+/E7BPg8MBbv6OY44O/AtW75boAC5W58LrANGA0UAE8Bc0Os/3Pe19E2/lfg50AxMNKVc7qb9xYw1Q2XAmPd8LeAP7g48916S0Ks76tAf/e5/hNoAPq5edOBA8A3XDnfBv7le+9S4Kd4/6Dj3XsfD7Ge24EnfOMXAKvccB5wmfsMxcAvgGW+ZecCt7rhicB6N1wE1ALfcdt1iou3ddnDgC+57dAT+D3wjK/c14HLfOOB39tv3XtK3Xe8Dvh6NNsm4LPnA+8AtwCF7jteD0wIs38Fm3Yn8Ib7XIcDbwI/9G2XJrdMIXBIkDh+C/yXG/418A/gm7553/bF83iw/TGOzx7pO+oQNzAJ2AIMd/vDL4GXA76jl4BDgXL3vVzm5s/A+18c6L63PwKPBe47vvhqgcrAz+3GewI7gePdeH9gULpzVFR5LN0BZMqL0An95Qjvuwn4XcBOV+7G5wIP+5Y9H5fMgpTT9g/kdsoDQA/f/J8Cc9zwG8APgLKAMmbgJauhcXz+VcA5bng68IFvXk/3ufriJbhGoLtv/tOETugnun+OYjf+FHBLiGX7uvX08G2/W92wP6GfAfwLEN97l7YuG6Tc0cBW33jIhI6XfJqAE3zzvwW8FGnbBFnvqcBHAdP+L/CrUPtXiGkbgEm+8XOAdb7tsg8oDPPdXgn83g2vdZ9hrhv/BBjmW/fjgfujr5xYPnvY7yhY3MATwJ0B5TcDA3zf0UTf/O8Ai93wK8AM37zBwH68H8V4EvpneJWC4lj/l9L5siaXyP7lHxGRE0Xkz66ZYBdeDTRos4bzqW94D1ASakGfI4FtqrrbN20DcJQbvhwYBHwoXrPKZDf9cbwazNPu0PwuEQl6nsQder/rDp0/w0u8/s8RGDcu9iOBOlXd45u/IdQHUdUP8GqE54hICXAuXq2wtXfJPe6QdhdejQvCb09cDLXq/vsCYxCRHiIyR0T+6cp9OYoyWx2OV/v0fyb/tofQ2ybQscAxrdvYbeebgSN8y/wryPsCp/WPEM9mVW0MUk6rV4BxrtmpCXgG+IKIfA6vJvxemPcGivazh/2OQsR9pH8ZVd0F7KD9Z/Vvmw3uPR3e64YL8Y5qYuLWOxXvh/xT8Zo+T4i1nHSwhB5Z4Jn+R/Bqs59T1Z54NWVJ8Do3An1FpIdv2jF4tSlU9UNVnYKXfO4FnhWRYlVtVNVbVfUk4DS8GkaH3joichzwEHA1Xi2/N/BBlJ9jE1AmIocExBbOfLx/kC8B76jqejf9a8BkvNpcL7xaIVHEsQmv1ubnj+FmvKOcMe47OiNg2XC9N7bg1QqPDSj7kwgxBfMvYK2q9va9SlX1vAixBE7bFCGesL1R3I9qE16CekVVPwO24zWdvBaQdKMqMwqRvqNg69iI73OKSCle84r/sx4dUN7GYO918xqBrcBuoLuv3G60P+/T4bOq6iJVnYj3Y7oO7/8+41lCj10pXhPCbvFO4F2Z6BWo6sfAMuBOESkSkeF4tfJ5ACJyqYj0VdUWF4sCLSJyhogMcSeKduE12zQHWUWJe89WrziZjldDjya2fwArgVvFO8E5Dq8JIJz5wNl4TUK/9U0vxTssrsP7h/txNDHgNZnkici17mTZV/DOM/jL3QPsEJEyvB9dv814TUcdqOoBvBrsnSJSIt5J7Ovxmn9iVQM0isiN7sRmvogMFZFRMZYzH/iBiPQVkcPwmm1ijedV4Fq82jpAdcB4oC2Auh//eET6joKZD1wh3gnzIuAneD84tb5lbhbvpPUxeE0uT/nee4OIlLsfgh8D893/yAdAqYicKV4Hhh/iNa212gyUi7Sd+O4vIueJSHe8H4XdBP8/yjiW0GN3I/B1oB7vV/up8IvH7WLgeLxD3Gfw2p2r3LzJwBrxekH8DLjYHboeiXcybxfwPl7zy/zAglV1JfAAXpvmJrxk/mYMsU3Bax/eDvw38JtwC7t/yGXAKXjt7a0ew6tZbXTxvhHNylV1P15t/5t4h+QX4p0MbnUfXo2/zpW5KKCI2cBU1wxyX5BVXIP3j/wxXsJ7AngymtgC4mzC+67G4J2j2Ya3z/SMsajbgHfxmkZW4n1XP4mxjFfwfuheDTHejqrWu3W86bbT6FhWFsV3FOw9f8FrwnwOb788ho5HmH/CO9H8tlvucTf9V3j/i68BH+H9f/6XK3cH3gncJ/Bq+9tp33T0FF7zzHYRWYrX5PZdF0Md8B94P34ZT4IfbRljTOZwzSQHgIG+JjsTwGroxhiTIyyhG2NMjrAmF2OMyRFWQzfGmByRtptz9e3bV8vLy+N67+7du+nRo0fkBVMsU+OCzI3N4oqNxRWbXIxr+fLl21Q1+AVT6bpEddSoURqvqqqquN+bTJkal2rmxmZxxcbiik0uxoXvfkeBL2tyMcaYHGEJ3RhjcoQldGOMyRFd+olFxnQFBw4coLa2ln379iVtHb169WLNmjVJKz9e2RxXcXExAwYMoKCgIOxyfpbQjclxtbW1lJaWUl5ejrv/VMLV19dTWlqalLI7I1vjUlXq6uqora1l4MCoHnIGWJOLMTlv3759lJWVJS2Zm8QTEcrKymI+qsq+hF5TwzHz5kFNTbojMSZrWDLPPvF8Z9mV0Gtq4IwzGDhnDpxxhiV1Y4zxya6EXl0NjY3e42wOHPDGjTEZq66ujuHDhzN8+HCOOOIIjjrqqLbxxsZwT8076PLLL+fDDz+Mep1z5szhuuuuizfkrBbxpKiI/BrvOZBbVHVIkPmXADPdaANwtaq+m9AoW1VWQrdu0Njo/a2sTMpqjDGJUVZWxjvvvAPArbfeSklJCTfddFO7ZdqucswLXr987LHHkh5nroimhv44cFaY+R8Dp6vqMOBHwKMJiCu4igq47TZv+OGHvXFjTOLV1MBPfpK0Zs1169YxZMgQrrrqKkaOHMmmTZuYMWMGo0ePZvDgwdx+++1ty5522mm88847NDU10bt3b2bNmsXJJ59MRUUFW7ZsiXqdc+fOZejQoQwZMoRbbrkFgKamJi699NK26Q888AAA999/P4MGDeLkk09m2rRpif3wSRSxhq6qr4pIeZj5/seG/Y2OD4ZNrMGDvb9DhyZ1NcbkpOuuA1djDmnnTli5ElpaIC8Phg2DXr1CLz98OPzoRzGHsnr1ah577DEefvhhAO666y769OlDU1MT48eP56KLLmLQoEEBoe3k9NNP56677uKGG27g17/+NbNmzYq4rtraWr7//e+zbNkyevXqxcSJE3nhhRc47LDD2LZtG++99x4An332GQD33HMPGzZsoLCwsG1aNkh0P/Qr6Pj8xjYiMgPvQcH069eP6jjawPusWsUwYPnSpdTX18cZZnI0NDTE9ZlSIVNjs7hiE09cvXr1avtfKWpsJK85/POOZccO8lpaEEBbWmjZsQMtKQm5fEtjI83NzRH/H/fv309BQQH19fU0NDQwcOBATjzxxLb3PfbYY/zmN7+hqamJTZs2sXz5co4++miam5vZvXs39fX1HHLIIZx22mnU19czaNAgampqOqx33759NDY2Ul9f3xZXdXU1X/jCFygqKmLfvn1ceOGFvPTSS1x33XV88MEHXH311UyaNIkJEyZQX1/PiSeeyJQpU5g8eTLnnntuwnNNNNur9bPE8n0nLKGLyHi8hH5aqGVU9VFck8zo0aO1Mp42cNcvc9Tw4RnX5FJdXU1cnykFMjU2iys28cS1Zs2agxex/PKXkd9QUwMTJngdEAoLyZ8/P+L/2v4oLuApKiqiqKiI0tJSSkpKKC0tbXvP2rVreeSRR1i6dCm9e/dm2rRpiAilpaXk5+fTo0cPSktLKSwsbHtPSUlJ2zJ+xcXFbcu1XsBTXFxMQUFB27Kty5SXl/Pee++xaNEi5syZw6JFi3j00Ud56aWXeOWVV/jjH//Ivffey6pVq8jPz4+87aIU7QVPxcXFjBgxIupyE9LLRUSGAXOAC1S1LhFlhtS6UVtakroaY7qsigpYssRrRlmyJCUVp127dlFaWkrPnj3ZtGkTixcvTmj5p5xyClVVVdTV1dHU1MSCBQs4/fTT2bp1K6rKV77yFW677TZWrFhBc3MztbW1nHHGGfz0pz9l69at7NmzJ6HxJEuna+gicgzwe+BSVf1750OKoPVMeITDRmNMJ1RUpPQIeOTIkQwaNIghQ4Zw3HHHceqpp3aqvP/5n//hmWeeQVUREZYtW8btt99OZWUlqsp5553HOeecw4oVK7jiiivalrv77rtpamriP//zP6mvr6elpYWZM2dm5O0Dggp1o/TWFzAf2AQcAGrxmlWuAq5y8+cAO4B33Cvkzdc1EQ+4+MUvVMH7m2Ey9Wb6qpkbm8UVm3jiWr16deIDCbBr166kryMe2R5XsO8uXI6NppfL1AjzpwPT4/9JiUFNDdx4ozd8440wcmTGtaMbY0y6ZN+VogcOeMN2pagxxrSTXQm9shJa7w1cUGBXihpjjE92JfSKCnjwQW/4jjusucUYY3yyK6GDd1UawL//e3rjMMaYDJN9Cd26LRpjTFDZl9BbLyyyhG5MxqusrOxwkdDs2bO55pprwr6vxN1qYOPGjVx00UUhy162bFnYch588MF2FwVNnjw5IfdmufXWW/nZz37W6XISLXsT+rPP2gMujMlwU6dOZcGCBe2mLViwgKlTw/aGbnPkkUfyzDPPxL3+hx56qF1CX7hwIb179467vEyXfQl95Urv71NPefebsKRuTMIl6u65F110ES+88AL79+8HYP369WzcuJHTTjuNhoYGJkyYwMiRIxk6dCh//OMfO7x//fr1DBniPYZh7969TJkyhWHDhnHxxRezd+/etuWuvvrqtlvv/vCHPwTggQceYNOmTYwfP57x48cDUF5ezrZt2wC47777GDJkCEOGDGH27Nlt6zvppJP45je/yeDBg5k0aVK79UQSrMzdu3dzzjnncPLJJzNkyBCeeuopAGbNmsWgQYMYNmxYh3vExyvRd1tMvtZDrJYW70EX1dXW28WYKKX67rllZWWMGTOGv/zlL1xwwQUsWLCAiy++GBGhuLiY5557jp49e7Jt2zZOOeUUzj///JDP0nzooYfo3r07K1euZOXKlYwcObJt3o9//GP69OlDc3MzEyZMYOXKlXznO9/h3nvvpaqqir59+7Yra/ny5Tz22GO8+eabqCpjx47l9NNP59BDD2Xt2rXMnz+fX/3qV3z1q1/l2Wefjeqe6KHK/OijjzjyyCP585//7LbvTrZv385zzz3HBx98gIgk7Ba92VdDP+UU729eHhQWWl90YxJs586D975rafHGO8Pf7OJvblFVbrnlFoYNG8bEiRP55JNP2Lx5c8hyXn311bbEOmzYMIYNG9Y27+mnn2bkyJGMGDGC999/n9WrV4eN6fXXX+dLX/oSPXr0oKSkhAsvvJDXXnsNgIEDBzLc9aYbNWoU69evj+pzhipz6NChvPTSS8ycOZPXXnuNXr160bNnT4qLi5k+fTq///3v6d69e1TriCT7auijR3t/v/Ql7/J/q50bEzXXChCW7+65FBbCvHmR/83C3dr7i1/8IjfccAMrVqxg7969bTXrefPmsXXrVpYvX05BQQHl5eXsc7fHDiVY7f3jjz/mZz/7GW+99RaHHnool112WcRyvFuiBFdUVNQ2nJ+fH3WTS6gyTzjhBJYvX87ChQv53ve+x6RJk7j++utZunQpS5YsYcGCBfziF7/g5Zdfjmo94WRfDb31pOjkyZbMjUmCRN89t6SkhMrKSr7xjW+0Oxm6c+dODj/8cAoKCqiqqmLDhg1hyxk3bhzz5s0DYNWqVax059N27dpFjx496NWrF5s3b2bRooPP2CkpKQn6IIlx48bxhz/8gT179rB7926ee+45vvCFL3Tqc4Yqc+PGjXTv3p1p06Zx0003sWLFChoaGti5cyeTJ09m9uzZbc9d7azsq6FbP3Rjki7Rd8+dOnUqF154YbseL5dccgnnnXceo0ePZvjw4Zx44olhy7j66qu5/PLLGTZsGMOHD2fMmDEAnHzyyYwYMYLBgwd3uPXuZZddxtlnn03//v2pqqpqmz5y5Eguu+yytjKmT5/OiBEjom5eAbjjjjvaTnyC95i7YGUuXryY7373u+Tl5VFQUMBDDz1EQ0MDl1xyCfv27UNVuf/++6Neb1ihbsOY7Ffct8/duNG7fe5DD8X3/iTK1FuuqmZubBZXbOz2ubHJ9rhivX1u9ja5LFpkXRaNMcYn+xL68uXe3z/9yfqhG2OMT9Yl9Jrf1fITZlGjYw/2QzfGhKVhenWYzBTPd5ZVJ0VraqDyN1fQiFDMPl7OP5sK64duTFjFxcXU1dVRVlYW8qIdk1lUlbq6OoqLi2N6X1Yl9OpqaGoRQDhAIdXfeIKKimPTHZYxGW3AgAHU1taydevWpK1j3759MSefVMjmuIqLixkwYEBM5WZVQq+shG7dvJaWbt2Uyq9ZMjcmkoKCAgYOHJjUdVRXVzNixIikriMeXS2urGpDr6iAO271+p//8rxFdl2RMcb4ZFVCBxgy1GsDHFz7ovVwMcYYn6xL6PlrPwCg6a23rduiMcb4ZF1C//DlTwB4l6HWbdEYY3yyKqHX1MB3F08E4Abupyb/NLt9rjHGOFmV0Kur4UCzF/IBCqj+xhN2x0VjjHGyKqFXVkJBgTfcLd+6LRpjjF/EhC4ivxaRLSKyKsR8EZEHRGSdiKwUkZHBlkuEigp48EFv+MenWrdFY4zxi6aG/jhwVpj5ZwPHu9cM4KHOhxVa62MEP7f5r9bDxRhjfCImdFV9FdgeZpELgCfdrXr/BvQWkf6JCjBQ/qp3Afjdh0OpqfyeJXVjjHEkmjt6iUg58IKqDgky7wXgLlV93Y0vAWaq6rIgy87Aq8XTr1+/Uf6nl0Tr7dvWckP1N8mjmSL28+R5/4++N2RG20tDQwMlJSXpDiOoTI3N4oqNxRWbXIxr/Pjxy1V1dNCZoZ584X8B5cCqEPP+DJzmG18CjIpUZrxPLLr+4k8UvIcW5dOod161Pq5ykiFTn3KjmrmxWVyxsbhik4txkeQnFtUCR/vGBwAbE1BuUBVfPhKAPJopLMqzni7GGOMkIqE/D3zN9XY5BdipqpsSUG5Qn/+89/dLvatZ8sBq6+lijDFONN0W5wM1wL+LSK2IXCEiV4nIVW6RhcBHwDrgV8A1SYsW6Pau9wi6sz6bT8V1Y+2kqDHGOBHvh66qUyPMV+BbCYsogvy//RUYxQucw+D9H1BRXW1XixpjDFl2pSjA2329e7k8z/lMaHmRmrJz0xyRMcZkhqxL6DWfDQJAyacx7xCq64amOSJjjMkMWZfQTz/d+ys0U1jQYjdbNMYYJ+sSekXemwCcyYss0QlUYCdFjTEGsjChd/vrKwCM41Uqml+3B1wYY4yTdQk9v/ILALzMGfaAC2OM8cm6hL403+uiuIQJTJAl1GBdFo0xBrIwob/yCoCi5NF4IM9aXIwxxsm6hF5Z9h7germ07G0bN8aYri7rEnpF3Qt0o5Fj+Sez5Xoq6l5Id0jGGJMRsi6h15SdSxOFbOBYrtP77UpRY4xxsi6ht14ZquTRmFdsV4oaY4yTdQn9YBt6C4Ut+6wN3RhjnKxL6BV1L3Ao2xnNWyzJm2Rt6MYY42RdQqeyknyaUfIgL88uLDLGGCfrEnrNeyXU0ZdljGJC01+oeS/zHgBrjDHpkHUJvfrZOhQB8mikgOpn69IdkjHGZISsS+iVXy4DFGghn2Y3bowxJusSOkOHIgAI0q0bDLVui8YYA1mY0Kuf3OCaXISmJqX6yQ3pDskYYzJC1iX0Sl4hjxaghUIOUMkr6Q7JGGMyQtYl9IqvHc8JfEhvdjI7/0YqvnZ8ukMyxpiMkHUJvea9Ev7Ov/MZvbmu+V7rtmiMMU7WJfTqZ+tocW3o1m3RGGMOyrqEXvnlMvJpAdRrQ7dui8YYA2RhQq8Y2sBIlnEIe7w29KEN6Q7JGGMyQtYl9Jon17KC0eylu9eG/uTadIdkjDEZIaqELiJniciHIrJORGYFmX+MiFSJyNsislJEJic+VE81p9NCHm1t6JyerFUZY0xWiZjQRSQfeBA4GxgETBWRQQGLfR94WlVHAFOAXyY60FaVI3a5fujqXfo/YleyVmWMMVklmhr6GGCdqn6kqo3AAuCCgGUU6OmGewEbExdigLffbhsUgEWLkrYqY4zJJqKq4RcQuQg4S1Wnu/FLgbGqeq1vmf7Ai8ChQA9goqouD1LWDGAGQL9+/UYtWLAg5oCfua+IX/5pLEoe+Rzg9rzbOOuB/uwaPDjmshKtoaGBkpLM7BefqbFZXLGxuGKTi3GNHz9+uaqODjpTVcO+gK8Ac3zjlwI/D1jmBuBGN1wBrAbywpU7atQojccbb6jmc0BBtZC9+ob8h+qdd8ZVVqJVVVWlO4SQMjU2iys2FldscjEuYJmGyKvRNLnUAkf7xgfQsUnlCuBp9wNRAxQDfaMoOz7Ser9FQFugzPqiG2NMNAn9LeB4ERkoIoV4Jz2fD1jmn8AEABE5CS+hb01koK2qq6FZvYR+gG5UMx7q7GpRY4yJmNBVtQm4FlgMrMHrzfK+iNwuIue7xW4Eviki7wLzgcvcoUHCeZVxL6G3kE8ZW62GbowxQLdoFlLVhcDCgGk/8A2vBk5NbGjB1dWBoChCHs3UcZjV0I0xhiy8UrSyEvKkBYBuNFNJldXQjTGGLEzoAOKaXFrHrIZujDFZmNCrq6HJnRRtIt+79N9q6MYYE10beibpeFJ0G7z9WVpjMsaYTJB1NfTWk6Lg/X2bkWmOyBhjMkPWJfTKSsjP806KKsJjXE5NzzPTG5QxxmSArEvoFRVw5rEr3Jh4Fxe90zutMRljTCbIuoQOcMKRW9yQeu3oh0nY5Y0xpivIyoTevHm3GxKEZurW7khrPMYYkwmyMqEf0VzrhhQln7LG5N1+3RhjskVWJvTPig5zQ66GXnhkWuMxxphMkJUJvceAYryHJLka+vGHpjskY4xJu6xM6Htr97kha0M3xphWWZnQ+zZuckOuhr5jbVrjMcaYTJCVCf3d5qFuyOuu+PbaEqipSV9AxhiTAbIyoe85+uiOE598MvWBGGNMBsnKhH7smEI35N3TZQQr4NNP0xeQMcZkgKxM6GvXlrgh1+RiN+gyxpjsTOjbtxe2G/+UfmmKxBhjMkdWJnRjjDEdZWVC79Onsd34EWxOUyTGGJM5sjKhH398Q7vxEayA7dvTFI0xxmSGrEzoB0+Ket5mJGzdmqZojDEmM2RlQg88Kbqak6CoKE3RGGNMZsjKhB7Yhv46p1Hzz6PSFI0xxmSGrEzoZ565mTxa3JjQQj5Pbj8HHn00rXEZY0w6ZWVCHzx4F2OH7G437VP6wezZaYrIGGPSL6qELiJniciHIrJORGaFWOarIrJaRN4Xkd8mNsyODv+3nrRe+t9mh91G1xjTdXWLtICI5AMPAv8HqAXeEpHnVXW1b5njge8Bp6rqDhE5PFkBtwrM3dvpk+xVGmNMRoumhj4GWKeqH6lqI7AAuCBgmW8CD6rqDgBV3ZLYMDsK7KW4lb7Q2Bh8YWOM6QIi1tCBo4B/+cZrgbEBy5wAICJ/BfKBW1X1L4EFicgMYAZAv379qK6ujiNkaGhooKBgB9C7bdphbKNp1y5ej7PMRGhoaIj7MyVbpsZmccXG4opNl4tLVcO+gK8Ac3zjlwI/D1jmBeA5oAAYiJf0e4crd9SoURqvqqoqHTdOFVoUvL/jqFIF1UceibvczqqqqkrbuiPJ1NgsrthYXLHJxbiAZRoir0bT5FIL+J8oMQDYGGSZP6rqAVX9GPgQOD7eH5loBG1yAbjzzmSu1hhjMlY0Cf0t4HgRGSgihcAU4PmAZf4AjAcQkb54TTAfJTLQQN6FodI2Xk+pN2C3ADDGdFERE7qqNgHXAouBNcDTqvq+iNwuIue7xRYDdSKyGuWrlJcAABIDSURBVKgCvquqdckKGqCw/dX/1HIMjzIdmpqSuVpjjMlYUfVDV9WFqnqCqv6bqv7YTfuBqj7vhlVVb1DVQao6VFUXJDNogCuu8I95NfXZ/Bc0Nyd71cYYk5Gy8kpRgBkzoHt38F9ctJnDvYQ+c2ba4jLGmHTJ2oQezD66ewOPPJLeQIwxJg2yOqF7zeUHT4zuw91Cd+/etMRjjDHplNUJvXv39uMtdGMm1m3RGNM1ZXVCnzHDP+bV1B9hhncLgJqatMRkjDHpktUJ/e67IS8P/CdG97a2oz/5ZFpiMsaYdMnqhA6tCf2gRgq8gdWrOy5sjDE5LOsTerdu4D8xCvlM4wm7YtQY0+VkfUL/8pdbh5TWxD6fKXDYYekKyRhj0iLrE/rcuR2ntVBADRWpD8YYY9Io6xM6tDa7tPJq6bNWXZKWWIwxJl1yIqFffHHr0MHeLit3HZuWWIwxJl1yIqHPnQvFee0fP1ecfyBN0RhjTHrkREIHOLGktt34EUWfpSkSY4xJj5xJ6DsO9Ag7bowxuS5nEvr+pvx249v3dQ+xpDHG5KacSejFsr/deL2W8ujMf6QpGmNMLjvzTBCJ/zV+/DimTUt8XDmT0Ief5D8p6nVdvPMXVks3xgTXv3/8CfnFFzu7dmHePBKe1HMmod/80HF43RYPdl3cuqdn2uIxxqTetGkda8KhkvKnn6YzUq/SuWhRYkvNmYReUQH5tH9A9J7WB14YY7Leo49GrjnPmxf4LglWVAbwKp5nn53YUnMmoQPk+2rnrVPCHdJEs4PE2i42dmxSP6IxOStSE8iVV8ZTauYm9EsuCX7rks7IqYR+UsFa35j3RXb8xfYUFsa7g4QjLF0afGccNCjR6zImsxUXx1YhSk4TSGAlL7GOPRZUY39VVb2a8GQOOZbQHyqdRWA7OkB5+cHhsWO9nedAUi4kDV0bWLOm4w585pnJiMGY5Ah3RBusrXr//shlJl/khH7JJfElZVVYvz75nyAWOZXQK3q+TwGBvV2UDRsO7mRLl6Yruo5efDF8jcUSvkmFaJsewx/RZlbTxhFHHKwJR0rKyagpp0tOJXSGD+d67ncjrb/MqdzREnt4Fynh+488jIkkVBt1YpoeU/d/Vloauea8aVPKwskouZXQb76Zu7mFUna4CdEl2O7d4z/kan2ddFL060sU/5GH/1VcnNIwTIrF2jadmm56idv3IzWB7NqVsFXlnNxK6BUV0L07uygDmt3E8DvaG2/A7t2dX/Xq1cEP78aM6XzZsdq/P3QbZ1lZ6uMxwZWXx9eTKjPapgMF/z8rKoq9cpRLTSCpFlVCF5GzRORDEVknIrPCLHeRiKiIjE5ciDHK9+7pohTQh62E2tFOOsnbeSqS/GCjN9/suMMem5ZbtXuHxNu3H0wOPez+ZQkTT3LesCGeNaW/DhbsiDZUW/W+femOtmuJuHeISD7wIHA2MAiYKiIdOuGJSCnwHeDNRAcZk4KCtsE6+qHko2/UdNjRVq9OX4jr14evoSQn4Xds49yzp2OSmTkzGevOXDNnRt9rI/HJObNE0zatmpgjWpMc0fzcjwHWqepHqtoILAAuCLLcj4B7gPT+Jh9xRMdps0IeVGSkSAk/vmac6No477kndNJKxs2E4tWzZ3ztyIGve+4JtYbM6rVxUOfbqkO1UVvbdPYT1fA7iIhcBJylqtPd+KXAWFW91rfMCOD7qvplEakGblLVZUHKmgHMAOjXr9+oBQsWxBV0Q0MDJSUlQef1/9OfOOG++7z14e3+TYccwl8XLoxrXYmKK1UmTjyN5uZgv9OBCSpUwoqUMFJ74je0eBNushN1vNsntvcVFLTw4ouvx7muxMuEfT+YXIxr/Pjxy1U1eLO2qoZ9AV8B5vjGLwV+7hvPA6qBcjdeDYyOVO6oUaM0XlVVVeEXyM9vX/koLIx7XQmNK42mTFnfyX48yXq1ZEAM6Y1r0qTov8dM3ccsrth0Ji5gmYbIq9E0udQCR/vGBwAbfeOlwBCgWkTWA6cAz2fCidE2TU3Bl+tCrrzy47YU8sYbHTdR+uRW08aYMbGn9MWLExy66bKiSehvAceLyEARKQSmAM+3zlTVnaraV1XLVbUc+BtwvgZpckmZ7gH3QW9p6Xpn+8KoqPB+4/xJpbQ0XdHElzgTrU+f9tsjmisMg73eTG+XANPFRUzoqtoEXAssBtYAT6vq+yJyu4icn+wA4zJjRsdpDz6Y+jiyyK5doZNUsPPMidO5hH7zzYlp+KirS9DHMSaNukWzkKouBBYGTPtBiGUrOx9WJ919d8fuC3v3pieWHJDMy6irq1+lsrIyeSswpgtJ/1UKydIt4LeqpQVqatITizHGpEDuJvRgXYKuuSb1cRhjTIrkbkIP1o7+7rupj8MYY1IkdxP63Xd3nKZqzS7GmJyVuwkd4JBDOk77+tdTH4cxxqRAbif0b3+747S1aztOM8aYHJDbCT1YswvYs92MMTkptxM6wIABHae9+GLq4zDGmCTL/YT+9NPBp1st3RiTY3I/oVdUtHvoRRurpRtjckzuJ3SA668PPj3walJjjMliXSOh33138NsJNjd7j74xxpgc0DUSOoR+vlZ9vSV1Y0xO6DoJHbyHKQZTXw+FhamNxRhjEqxrJfS5c0M/yeHAAe+pwXZrAGNMlupaCR28ppdwz1/7j/+A4uLUxWOMMQnS9RI6eM9fC5fU9+/3ausi1l/dGJM1umZCBy+pBz57NJgXXzyY3KdNS35cxhgTp66b0AF274ZJk6Jfft68g8k9Lw8efTR5sRljTIy6dkIHWLzYu096sKtJw1GFK688mOBFGDd+vHWBNMakjSX0Vo2N8MYb4dvWIxDwukD6krzV5o0xqWIJ3a+iwmtbV4Vjj4357RJqRpDaPD16dCpUY4wJZAk9lPXrvUSsCn36JL78PXs61uRFYObMxK/LGNMlWEKPRl3dweSuGvLiJE3Euu65p32CLy9PRKnGmC7AEno8du1qn+BV4ZFHaE7GujZs6FiLHzQoGWsyxmQ5S+iJMmMGr1dVdUz0oW410Blr1nRM8nYBlDFdniX0ZAuszXeyJ01I/gugROxmY8Z0QVEldBE5S0Q+FJF1IjIryPwbRGS1iKwUkSUiEnsXka7C35PG/0r0idfWm435+8hbzxpjclrEhC4i+cCDwNnAIGCqiAQ24r4NjFbVYcAzwD2JDjTnBZ54HTMmocULBO9ZYyddjckZ0dTQxwDrVPUjVW0EFgAX+BdQ1SpV3eNG/wYMSGyYXdCbb3asxXciyYfsIx/spKvdt8aYrCSq4TvbichFwFmqOt2NXwqMVdVrQyz/C+BTVb0jyLwZwAyAfv36jVqwYEFcQTc0NFBSUhLXe5MpHXF9fupUDvn003bTgiXvkAmd0N0tQ03/15QpfHzllVFEF5l9l7GxuGKTi3GNHz9+uaqODjpTVcO+gK8Ac3zjlwI/D7HsNLwaelGkckeNGqXxqqqqivu9yZQxcRUVBdbttaVjfT85r6KimELNmG0WwOKKjcUVm87EBSzTEHk1miaXWuBo3/gAYGPgQiIyEfhv4HxV3R/tr41Jgn37OvSsac5LUYcm/73kQ73KylITizFdTDT/5W8Bx4vIQBEpBKYAz/sXEJERwCN4yXxL4sM0nVJRwetLlrRP8rHcNjjRtm9v3/smVOLv3z99MRqThSImdFVtAq4FFgNrgKdV9X0RuV1EzneL/RQoAX4nIu+IyPMhijOZovW2wYGvI45IaRjh2vb59NPItf3Wlz020Bi6RbOQqi4EFgZM+4FveGKC4zLpsmlT6HllZV7tOoHCJvRYtDb1xOqkk2D16kRFYUxaRZXQjQG8vvLhFBd7iTUGSgKTejxab6MQYFy07+/TJ/J2MSZF7NJ/kziBJ2MDXzff3OEtCblDZRJE/SPjOx+QkJfdeM10giV0kzp3390hyb8a7IZml1yS7kjTd9QQ7MZrgbdwiOeHwnoWdQmW0E3mmTs3tt7vRUUJDyHrjxwCJfpIIuA15LvfTeTHNHGyhG6yX6SmnmCvCLdRyLmEnmRly5Yl9QfDjjaiYwnddE3B7pUTqSkowvmAVLAfGmI62oi7iSqaVwZeJ2EJ3Zh4BDkf0KlXlDdey9SEnqmS+kMTy3USwX5oknADPEvoxmSCCEcMUR85pOlIIlN/aDK1iUoA5s1LeFK3hG5MLkv0kUTg69hjgcxN6JkaV9sPzaJFCS3XEroxJn7r18d35BDPK46jjUxN6G1xnX12Qsu1hG6MyQ5xHG0k5YcmAddJKHjlzJ3b6bL8LKEbY0wsYr1OItQPTYKTOVhCN8aYnGEJ3RhjcoQldGOMyRGW0I0xJkdYQjfGmBxhCd0YY3KEqKan672IbAU2xPn2vsC2BIaTKJkaF2RubBZXbCyu2ORiXMeq6mHBZqQtoXeGiCxT1dHpjiNQpsYFmRubxRUbiys2XS0ua3IxxpgcYQndGGNyRLYm9EfTHUAImRoXZG5sFldsLK7YdKm4srIN3RhjTEfZWkM3xhgTwBK6McbkiKxL6CJyloh8KCLrRGRWGta/XkTeE5F3RGSZm9ZHRP5XRNa6v4e66SIiD7hYV4rIyATG8WsR2SIiq3zTYo5DRL7ull8rIl9PUly3isgnbpu9IyKTffO+5+L6UETO9E1P6PcsIkeLSJWIrBGR90Xkv9z0tG6zMHGldZuJSLGILBWRd11ct7npA0XkTffZnxKRQje9yI2vc/PLI8Wb4LgeF5GPfdtruJuesn3flZkvIm+LyAtuPLXbS1Wz5gXkA/8AjgMKgXeBQSmOYT3QN2DaPcAsNzwLuNsNTwYW4T1x6hTgzQTGMQ4YCayKNw6gD/CR+3uoGz40CXHdCtwUZNlB7jssAga67zY/Gd8z0B8Y6YZLgb+79ad1m4WJK63bzH3uEjdcALzptsPTwBQ3/WHgajd8DfCwG54CPBUu3iTE9ThwUZDlU7bvu3JvAH4LvODGU7q9sq2GPgZYp6ofqWojsAC4IM0xgRfDE274CeCLvulPqudvQG8R6Z+IFarqq8D2TsZxJvC/qrpdVXcA/wuclYS4QrkAWKCq+1X1Y2Ad3nec8O9ZVTep6go3XA+sAY4izdssTFyhpGSbuc/d4EYL3EuBM4Bn3PTA7dW6HZ8BJoiIhIk30XGFkrJ9X0QGAOcAc9y4kOLtlW0J/SjgX77xWsLv/MmgwIsislxEZrhp/VR1E3j/oMDhbnqq4401jlTGd6075P11a7NGuuJyh7cj8Gp3GbPNAuKCNG8z13zwDrAFL+H9A/hMVZuCrKNt/W7+TqAsFXGpauv2+rHbXveLSFFgXAHrT8b3OBu4GWhx42WkeHtlW0KXINNS3e/yVFUdCZwNfEtExoVZNhPihdBxpCq+h4B/A4YDm4B70xWXiJQAzwLXqequcIumMrYgcaV9m6lqs6oOBwbg1RJPCrOOtMUlIkOA7wEnAp/Ha0aZmcq4RORcYIuqLvdPDrOOpMSVbQm9FjjaNz4A2JjKAFR1o/u7BXgOb0ff3NqU4v5ucYunOt5Y40hJfKq62f0TtgC/4uAhZErjEpECvKQ5T1V/7yanfZsFiytTtpmL5TOgGq8NureIdAuyjrb1u/m98JreUhHXWa7pSlV1P/AYqd9epwLni8h6vOauM/Bq7KndXp09CZDKF9AN7+TFQA6e+BmcwvX3AEp9w2/gtbv9lPYn1u5xw+fQ/oTM0gTHU077k48xxYFXk/kY76TQoW64TxLi6u8bvh6vjRBgMO1PAH2Ed3Iv4d+z++xPArMDpqd1m4WJK63bDDgM6O2GDwFeA84Ffkf7k3zXuOFv0f4k39Ph4k1CXP1923M2cFc69n1XdiUHT4qmdHslLLmk6oV31vrveO15/53idR/nNva7wPut68dr+1oCrHV/+/h2rgddrO8BoxMYy3y8Q/EDeL/qV8QTB/ANvBMv64DLkxTXb9x6VwLP0z5Z/beL60Pg7GR9z8BpeIeuK4F33GtyurdZmLjSus2AYcDbbv2rgB/4/geWus/+O6DITS924+vc/OMixZvguF5222sVMJeDPWFStu/7yq3kYEJP6fayS/+NMSZHZFsbujHGmBAsoRtjTI6whG6MMTnCEroxxuQIS+jGGJMjLKEbY0yOsIRujDE54v8Dk0229cmBjywAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(run_hist_2.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "plt.plot(run_hist_2.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "plt.title(\"Train loss and validation error with dropouts\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the benefits of using dropouts?  zapobiegaj optymaizowaniu wag dla wszystkich neuronow jednoczenie. \n",
    "\n",
    "### Student task 2\n",
    "- Add dropouts to neural network from task 1 and compere the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training neural network w dropouts..\n",
      "\n",
      "Accuracy over training data is  0.9632352941176471\n",
      "Accuracy over testing data is  0.847457627118644\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model with dropouts\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "neural_network_d = Sequential()\n",
    "neural_network_d.add(Dense(2, activation='relu', input_shape=(22,)))\n",
    "neural_network_d.add(Dropout(0.1))\n",
    "neural_network_d.add(Dense(2, activation='selu'))\n",
    "neural_network_d.add(Dropout(0.1))\n",
    "neural_network_d.add(Dense(2, activation='linear'))\n",
    "neural_network_d.add(Dropout(0.1))\n",
    "neural_network_d.add(Dense(1, activation='sigmoid'))\n",
    "neural_network_d.add(Dropout(0.1))\n",
    "\n",
    "# neural_network_d.summary()\n",
    "\n",
    "neural_network_d.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "run_hist_2 = neural_network_d.fit(data_train, target_train, epochs=4000, \\\n",
    "                                  validation_data=(data_test, target_test), \\\n",
    "                                  verbose=False, shuffle=False)\n",
    "\n",
    "print(\"Training neural network w dropouts..\\n\")\n",
    "\n",
    "print('Accuracy over training data is ', accuracy_score(target_train, \\\n",
    "                                                        neural_network_d.predict_classes(data_train)))\n",
    "\n",
    "print('Accuracy over testing data is ', accuracy_score(target_test, \\\n",
    "                                                       neural_network_d.predict_classes(data_test)))\n",
    "\n",
    "plt.plot(run_hist_2.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "plt.plot(run_hist_2.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "plt.title(\"Train loss and validation error with dropouts\")\n",
    "plt.legend()\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network for multiclass classification on mnist data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train =  []\n",
    "for image_train in x_train:\n",
    "    images_train.append(image_train.flatten())\n",
    "\n",
    "images_test = []\n",
    "\n",
    "for image_test in x_test:\n",
    "    images_test.append(image_test.flatten())\n",
    "\n",
    "images_train = np.array(images_train)\n",
    "images_test = np.array(images_test)\n",
    "\n",
    "from keras.utils import normalize\n",
    "images_train = normalize(images_train)\n",
    "images_test = normalize(images_test)\n",
    "\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "y_test_categorical = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 39,760\n",
      "Trainable params: 39,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.4026 - accuracy: 0.8804 - val_loss: 0.2729 - val_accuracy: 0.9113\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1998 - accuracy: 0.9400 - val_loss: 0.1871 - val_accuracy: 0.9413\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1515 - accuracy: 0.9547 - val_loss: 0.1754 - val_accuracy: 0.9452\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1261 - accuracy: 0.9620 - val_loss: 0.1717 - val_accuracy: 0.9442\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1097 - accuracy: 0.9672 - val_loss: 0.1739 - val_accuracy: 0.9440\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.0977 - accuracy: 0.9703 - val_loss: 0.1571 - val_accuracy: 0.9491\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.0877 - accuracy: 0.9734 - val_loss: 0.1450 - val_accuracy: 0.9539\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.0799 - accuracy: 0.9754 - val_loss: 0.1388 - val_accuracy: 0.9566\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.0736 - accuracy: 0.9774 - val_loss: 0.1475 - val_accuracy: 0.9535\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.0680 - accuracy: 0.9793 - val_loss: 0.1450 - val_accuracy: 0.9559\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.0630 - accuracy: 0.9808 - val_loss: 0.1483 - val_accuracy: 0.9559\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.0582 - accuracy: 0.9826 - val_loss: 0.1465 - val_accuracy: 0.9562\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.0543 - accuracy: 0.9838 - val_loss: 0.1558 - val_accuracy: 0.9543\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.0507 - accuracy: 0.9850 - val_loss: 0.1602 - val_accuracy: 0.9537\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.0474 - accuracy: 0.9858 - val_loss: 0.1492 - val_accuracy: 0.9570\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0449 - accuracy: 0.9869 - val_loss: 0.1518 - val_accuracy: 0.9585\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.0420 - accuracy: 0.9880 - val_loss: 0.1520 - val_accuracy: 0.9588\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.0392 - accuracy: 0.9890 - val_loss: 0.1566 - val_accuracy: 0.9572\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.0367 - accuracy: 0.9896 - val_loss: 0.1534 - val_accuracy: 0.9593\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.0350 - accuracy: 0.9898 - val_loss: 0.1459 - val_accuracy: 0.9624\n"
     ]
    }
   ],
   "source": [
    "neural_network_mnist = Sequential()\n",
    "neural_network_mnist.add(Dense(50, activation='relu', input_shape=(784,)))\n",
    "#neural_network_mnist.add(Dense(20, activation='relu'))\n",
    "#neural_network_mnist.add(Dropout(0.01))\n",
    "neural_network_mnist.add(Dense(10, activation='softmax'))\n",
    "\n",
    "neural_network_mnist.summary()\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9)\n",
    "neural_network_mnist.compile(optimizer=sgd, loss=\"categorical_crossentropy\", \\\n",
    "                             metrics=[\"accuracy\"])\n",
    "\n",
    "run_hist_3 = neural_network_mnist.fit(images_train, y_train_categorical, epochs=20, \\\n",
    "                                  validation_data=(images_test, y_test_categorical), \\\n",
    "                                  verbose=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save neural model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network_mnist.save('mnist-model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(run_hist_3.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "plt.plot(run_hist_3.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "plt.title(\"Train loss and validation error with dropouts\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load trained neural model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('mnist-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 28us/step\n",
      "Model evaluation [loss, accu]:  [0.14590955777896453, 0.9624000191688538]\n"
     ]
    }
   ],
   "source": [
    "print(\"Model evaluation [loss, accu]: \", model.evaluate(images_test, y_test_categorical))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage of a trained neural model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural netowrk predicts:\n",
      "[[1.06152154e-16 1.96889623e-11 2.71920797e-09 9.99744356e-01\n",
      "  9.96778007e-12 2.55621067e-04 2.96643474e-14 1.05009603e-11\n",
      "  5.04864950e-09 5.72477872e-12]]\n",
      "\n",
      "Neural network recognized image as: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "id = 5000\n",
    "\n",
    "print(\"Neural netowrk predicts:\")\n",
    "print(model.predict(images_test[id,:].reshape(-1,784)))\n",
    "\n",
    "plt.imshow(images_test[id,:].reshape(28,28), cmap=plt.get_cmap(\"gray\"))\n",
    "plt.title('Image to recognize')\n",
    "\n",
    "print(\"\\nNeural network recognized image as:\", np.argmax(model.predict(images_test[id,:].reshape(-1,784))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build __two__ neural network based regression model to predict \"Boston housing\" price. One without dropouts and one with droputs. Remember to use aprioprate loss function and activation in output layer. Evaluate model and visual learning process. Experiments with different network architecture and optimization parameters. Use data from Keras library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import boston_housing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from keras.layers import Dropout\n",
    "from numpy.random import seed\n",
    "import random as rn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 404 samples, validate on 102 samples\n",
      "Epoch 1/50\n",
      "404/404 [==============================] - 0s 839us/step - loss: 21.1440 - mae: 21.1440 - val_loss: 19.7972 - val_mae: 19.7972\n",
      "Epoch 2/50\n",
      "404/404 [==============================] - 0s 64us/step - loss: 16.3231 - mae: 16.3231 - val_loss: 13.6018 - val_mae: 13.6018\n",
      "Epoch 3/50\n",
      "404/404 [==============================] - 0s 64us/step - loss: 9.5321 - mae: 9.5321 - val_loss: 7.5505 - val_mae: 7.5505\n",
      "Epoch 4/50\n",
      "404/404 [==============================] - 0s 64us/step - loss: 5.7942 - mae: 5.7942 - val_loss: 5.5779 - val_mae: 5.5779\n",
      "Epoch 5/50\n",
      "404/404 [==============================] - 0s 67us/step - loss: 4.6119 - mae: 4.6119 - val_loss: 4.7015 - val_mae: 4.7015\n",
      "Epoch 6/50\n",
      "404/404 [==============================] - 0s 64us/step - loss: 3.9756 - mae: 3.9756 - val_loss: 4.2057 - val_mae: 4.2057\n",
      "Epoch 7/50\n",
      "404/404 [==============================] - 0s 67us/step - loss: 3.6268 - mae: 3.6268 - val_loss: 3.8815 - val_mae: 3.8815\n",
      "Epoch 8/50\n",
      "404/404 [==============================] - 0s 67us/step - loss: 3.4011 - mae: 3.4011 - val_loss: 3.8265 - val_mae: 3.8265\n",
      "Epoch 9/50\n",
      "404/404 [==============================] - 0s 69us/step - loss: 3.2154 - mae: 3.2154 - val_loss: 3.5154 - val_mae: 3.5154\n",
      "Epoch 10/50\n",
      "404/404 [==============================] - 0s 62us/step - loss: 3.1209 - mae: 3.1209 - val_loss: 3.3347 - val_mae: 3.3347\n",
      "Epoch 11/50\n",
      "404/404 [==============================] - 0s 57us/step - loss: 2.9181 - mae: 2.9181 - val_loss: 3.7301 - val_mae: 3.7301\n",
      "Epoch 12/50\n",
      "404/404 [==============================] - 0s 64us/step - loss: 2.8058 - mae: 2.8058 - val_loss: 3.0246 - val_mae: 3.0246\n",
      "Epoch 13/50\n",
      "404/404 [==============================] - 0s 59us/step - loss: 2.7162 - mae: 2.7162 - val_loss: 3.0026 - val_mae: 3.0026\n",
      "Epoch 14/50\n",
      "404/404 [==============================] - 0s 62us/step - loss: 2.6212 - mae: 2.6212 - val_loss: 3.2194 - val_mae: 3.2194\n",
      "Epoch 15/50\n",
      "404/404 [==============================] - 0s 64us/step - loss: 2.5994 - mae: 2.5994 - val_loss: 2.8999 - val_mae: 2.8999\n",
      "Epoch 16/50\n",
      "404/404 [==============================] - 0s 62us/step - loss: 2.5063 - mae: 2.5063 - val_loss: 3.1155 - val_mae: 3.1155\n",
      "Epoch 17/50\n",
      "404/404 [==============================] - 0s 64us/step - loss: 2.4499 - mae: 2.4499 - val_loss: 2.9345 - val_mae: 2.9345\n",
      "Epoch 18/50\n",
      "404/404 [==============================] - 0s 67us/step - loss: 2.4202 - mae: 2.4202 - val_loss: 2.9750 - val_mae: 2.9750\n",
      "Epoch 19/50\n",
      "404/404 [==============================] - 0s 59us/step - loss: 2.4679 - mae: 2.4679 - val_loss: 2.9593 - val_mae: 2.9593\n",
      "Epoch 20/50\n",
      "404/404 [==============================] - 0s 62us/step - loss: 2.3259 - mae: 2.3259 - val_loss: 2.8482 - val_mae: 2.8482\n",
      "Epoch 21/50\n",
      "404/404 [==============================] - 0s 64us/step - loss: 2.3202 - mae: 2.3202 - val_loss: 2.9172 - val_mae: 2.9172\n",
      "Epoch 22/50\n",
      "404/404 [==============================] - 0s 62us/step - loss: 2.3280 - mae: 2.3280 - val_loss: 2.9296 - val_mae: 2.9296\n",
      "Epoch 23/50\n",
      "404/404 [==============================] - 0s 67us/step - loss: 2.2872 - mae: 2.2872 - val_loss: 2.8974 - val_mae: 2.8974\n",
      "Epoch 24/50\n",
      "404/404 [==============================] - 0s 59us/step - loss: 2.3429 - mae: 2.3429 - val_loss: 2.9198 - val_mae: 2.9198\n",
      "Epoch 25/50\n",
      "404/404 [==============================] - 0s 62us/step - loss: 2.2218 - mae: 2.2218 - val_loss: 3.2837 - val_mae: 3.2837\n",
      "Epoch 26/50\n",
      "404/404 [==============================] - 0s 64us/step - loss: 2.2167 - mae: 2.2167 - val_loss: 3.0348 - val_mae: 3.0348\n",
      "Epoch 27/50\n",
      "404/404 [==============================] - 0s 62us/step - loss: 2.2691 - mae: 2.2691 - val_loss: 3.1002 - val_mae: 3.1002\n",
      "Epoch 28/50\n",
      "404/404 [==============================] - 0s 62us/step - loss: 2.2401 - mae: 2.2401 - val_loss: 3.2180 - val_mae: 3.2180\n",
      "Epoch 29/50\n",
      "404/404 [==============================] - 0s 74us/step - loss: 2.1864 - mae: 2.1864 - val_loss: 2.8056 - val_mae: 2.8056\n",
      "Epoch 30/50\n",
      "404/404 [==============================] - 0s 72us/step - loss: 2.1441 - mae: 2.1441 - val_loss: 2.8586 - val_mae: 2.8586\n",
      "Epoch 31/50\n",
      "404/404 [==============================] - 0s 72us/step - loss: 2.1526 - mae: 2.1526 - val_loss: 2.8547 - val_mae: 2.8547\n",
      "Epoch 32/50\n",
      "404/404 [==============================] - 0s 81us/step - loss: 2.1668 - mae: 2.1668 - val_loss: 3.0656 - val_mae: 3.0656\n",
      "Epoch 33/50\n",
      "404/404 [==============================] - 0s 72us/step - loss: 2.1419 - mae: 2.1419 - val_loss: 2.8232 - val_mae: 2.8232\n",
      "Epoch 34/50\n",
      "404/404 [==============================] - 0s 74us/step - loss: 2.1360 - mae: 2.1360 - val_loss: 2.8600 - val_mae: 2.8600\n",
      "Epoch 35/50\n",
      "404/404 [==============================] - 0s 86us/step - loss: 2.1228 - mae: 2.1228 - val_loss: 3.2716 - val_mae: 3.2716\n",
      "Epoch 36/50\n",
      "404/404 [==============================] - 0s 69us/step - loss: 2.0438 - mae: 2.0438 - val_loss: 2.8678 - val_mae: 2.8678\n",
      "Epoch 37/50\n",
      "404/404 [==============================] - 0s 62us/step - loss: 2.1591 - mae: 2.1591 - val_loss: 2.8243 - val_mae: 2.8243\n",
      "Epoch 38/50\n",
      "404/404 [==============================] - 0s 67us/step - loss: 2.0527 - mae: 2.0527 - val_loss: 2.8242 - val_mae: 2.8242\n",
      "Epoch 39/50\n",
      "404/404 [==============================] - 0s 64us/step - loss: 2.0652 - mae: 2.0652 - val_loss: 2.9335 - val_mae: 2.9335\n",
      "Epoch 40/50\n",
      "404/404 [==============================] - 0s 62us/step - loss: 2.0496 - mae: 2.0496 - val_loss: 2.9308 - val_mae: 2.9308\n",
      "Epoch 41/50\n",
      "404/404 [==============================] - 0s 62us/step - loss: 2.1220 - mae: 2.1220 - val_loss: 2.8641 - val_mae: 2.8641\n",
      "Epoch 42/50\n",
      "404/404 [==============================] - 0s 62us/step - loss: 2.0453 - mae: 2.0453 - val_loss: 3.3292 - val_mae: 3.3292\n",
      "Epoch 43/50\n",
      "404/404 [==============================] - 0s 64us/step - loss: 2.0108 - mae: 2.0108 - val_loss: 2.7787 - val_mae: 2.7787\n",
      "Epoch 44/50\n",
      "404/404 [==============================] - 0s 72us/step - loss: 2.0200 - mae: 2.0200 - val_loss: 2.7907 - val_mae: 2.7907\n",
      "Epoch 45/50\n",
      "404/404 [==============================] - 0s 67us/step - loss: 2.0499 - mae: 2.0499 - val_loss: 2.7144 - val_mae: 2.7144\n",
      "Epoch 46/50\n",
      "404/404 [==============================] - 0s 72us/step - loss: 1.9589 - mae: 1.9589 - val_loss: 2.7999 - val_mae: 2.7999\n",
      "Epoch 47/50\n",
      "404/404 [==============================] - 0s 72us/step - loss: 1.9626 - mae: 1.9626 - val_loss: 2.7587 - val_mae: 2.7587\n",
      "Epoch 48/50\n",
      "404/404 [==============================] - 0s 69us/step - loss: 2.0148 - mae: 2.0148 - val_loss: 2.7402 - val_mae: 2.7402\n",
      "Epoch 49/50\n",
      "404/404 [==============================] - 0s 62us/step - loss: 2.0269 - mae: 2.0269 - val_loss: 2.7226 - val_mae: 2.7226\n",
      "Epoch 50/50\n",
      "404/404 [==============================] - 0s 64us/step - loss: 1.9655 - mae: 1.9655 - val_loss: 2.8945 - val_mae: 2.8945\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 39us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.894497319763782, 2.8944973945617676]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "neural_network_boston = Sequential()\n",
    "\n",
    "neural_network_boston.add(Dense(50, activation='relu', input_shape=[x_train.shape[1]]))\n",
    "neural_network_boston.add(Dense(100, activation='relu'))\n",
    "neural_network_boston.add(Dense(50, activation='relu'))\n",
    "neural_network_boston.add(Dense(1))\n",
    "\n",
    "# neural_network_boston.compile(loss='mean_squared_error', optimizer='adam')\n",
    "neural_network_boston.compile(loss='mean_absolute_error', optimizer='rmsprop', metrics=['mae'])\n",
    "\n",
    "\n",
    "run_hist_model1= neural_network_boston.fit(x_train_scaled, y_train, epochs=50, verbose=1, validation_data=(x_test_scaled, y_test))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# neural_network_boston.summary()\n",
    "\n",
    "# sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9)\n",
    "# neural_network_mnist.compile(optimizer=sgd, loss=\"categorical_crossentropy\", \\\n",
    "#                              metrics=[\"accuracy\"])\n",
    "# neural_network_boston.compile(SGD(lr = .003), loss=\"mean_absolute_error\", \\\n",
    "#                      metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(run_hist_model1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "plt.plot(run_hist_model1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "plt.title(\"Train loss and validation error without dropouts\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.xlim(0, 10)\n",
    "plt.plot(run_hist_model1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "plt.plot(run_hist_model1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "plt.title(\"Train loss and validation error without dropouts\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "neural_network_boston.evaluate(x_test_scaled, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network_boston.save('boston-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 404 samples, validate on 102 samples\n",
      "Epoch 1/50\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 21.8867 - mae: 21.8867 - val_loss: 21.8266 - val_mae: 21.8266\n",
      "Epoch 2/50\n",
      "404/404 [==============================] - 0s 98us/step - loss: 20.2177 - mae: 20.2177 - val_loss: 19.4587 - val_mae: 19.4587\n",
      "Epoch 3/50\n",
      "404/404 [==============================] - 0s 81us/step - loss: 16.9825 - mae: 16.9825 - val_loss: 14.6600 - val_mae: 14.6600\n",
      "Epoch 4/50\n",
      "404/404 [==============================] - 0s 86us/step - loss: 11.1552 - mae: 11.1552 - val_loss: 7.6538 - val_mae: 7.6538\n",
      "Epoch 5/50\n",
      "404/404 [==============================] - 0s 81us/step - loss: 6.6628 - mae: 6.6628 - val_loss: 6.0340 - val_mae: 6.0340\n",
      "Epoch 6/50\n",
      "404/404 [==============================] - 0s 77us/step - loss: 5.3757 - mae: 5.3757 - val_loss: 4.9309 - val_mae: 4.9309\n",
      "Epoch 7/50\n",
      "404/404 [==============================] - 0s 79us/step - loss: 4.2378 - mae: 4.2378 - val_loss: 4.1454 - val_mae: 4.1454\n",
      "Epoch 8/50\n",
      "404/404 [==============================] - 0s 81us/step - loss: 3.9253 - mae: 3.9253 - val_loss: 3.8685 - val_mae: 3.8685\n",
      "Epoch 9/50\n",
      "404/404 [==============================] - 0s 81us/step - loss: 3.6493 - mae: 3.6493 - val_loss: 3.6836 - val_mae: 3.6836\n",
      "Epoch 10/50\n",
      "404/404 [==============================] - 0s 81us/step - loss: 3.4367 - mae: 3.4367 - val_loss: 3.4222 - val_mae: 3.4222\n",
      "Epoch 11/50\n",
      "404/404 [==============================] - 0s 81us/step - loss: 3.0592 - mae: 3.0592 - val_loss: 3.4163 - val_mae: 3.4163\n",
      "Epoch 12/50\n",
      "404/404 [==============================] - 0s 84us/step - loss: 3.0667 - mae: 3.0667 - val_loss: 3.1946 - val_mae: 3.1946\n",
      "Epoch 13/50\n",
      "404/404 [==============================] - 0s 84us/step - loss: 3.0459 - mae: 3.0459 - val_loss: 3.2444 - val_mae: 3.2444\n",
      "Epoch 14/50\n",
      "404/404 [==============================] - 0s 79us/step - loss: 3.0350 - mae: 3.0350 - val_loss: 3.2452 - val_mae: 3.2452\n",
      "Epoch 15/50\n",
      "404/404 [==============================] - 0s 81us/step - loss: 2.7526 - mae: 2.7526 - val_loss: 3.0494 - val_mae: 3.0494\n",
      "Epoch 16/50\n",
      "404/404 [==============================] - 0s 81us/step - loss: 2.9199 - mae: 2.9199 - val_loss: 3.1148 - val_mae: 3.1148\n",
      "Epoch 17/50\n",
      "404/404 [==============================] - 0s 84us/step - loss: 2.6765 - mae: 2.6765 - val_loss: 3.0760 - val_mae: 3.0760\n",
      "Epoch 18/50\n",
      "404/404 [==============================] - ETA: 0s - loss: 2.1324 - mae: 2.132 - 0s 84us/step - loss: 2.7092 - mae: 2.7092 - val_loss: 3.0031 - val_mae: 3.0031\n",
      "Epoch 19/50\n",
      "404/404 [==============================] - 0s 84us/step - loss: 2.7911 - mae: 2.7911 - val_loss: 3.2049 - val_mae: 3.2049\n",
      "Epoch 20/50\n",
      "404/404 [==============================] - 0s 84us/step - loss: 2.8522 - mae: 2.8522 - val_loss: 3.0050 - val_mae: 3.0050\n",
      "Epoch 21/50\n",
      "404/404 [==============================] - 0s 81us/step - loss: 2.5576 - mae: 2.5576 - val_loss: 3.0234 - val_mae: 3.0234\n",
      "Epoch 22/50\n",
      "404/404 [==============================] - 0s 81us/step - loss: 2.5728 - mae: 2.5728 - val_loss: 2.9488 - val_mae: 2.9488\n",
      "Epoch 23/50\n",
      "404/404 [==============================] - 0s 84us/step - loss: 2.5478 - mae: 2.5478 - val_loss: 3.0908 - val_mae: 3.0908\n",
      "Epoch 24/50\n",
      "404/404 [==============================] - 0s 84us/step - loss: 2.4610 - mae: 2.4610 - val_loss: 2.9105 - val_mae: 2.9105\n",
      "Epoch 25/50\n",
      "404/404 [==============================] - 0s 81us/step - loss: 2.8160 - mae: 2.8160 - val_loss: 2.9361 - val_mae: 2.9361\n",
      "Epoch 26/50\n",
      "404/404 [==============================] - 0s 84us/step - loss: 2.4108 - mae: 2.4108 - val_loss: 2.8656 - val_mae: 2.8656\n",
      "Epoch 27/50\n",
      "404/404 [==============================] - 0s 81us/step - loss: 2.5846 - mae: 2.5846 - val_loss: 2.9536 - val_mae: 2.9536\n",
      "Epoch 28/50\n",
      "404/404 [==============================] - 0s 84us/step - loss: 2.4738 - mae: 2.4738 - val_loss: 2.9594 - val_mae: 2.9594\n",
      "Epoch 29/50\n",
      "404/404 [==============================] - ETA: 0s - loss: 1.8036 - mae: 1.803 - 0s 81us/step - loss: 2.2572 - mae: 2.2572 - val_loss: 2.8908 - val_mae: 2.8908\n",
      "Epoch 30/50\n",
      "404/404 [==============================] - 0s 84us/step - loss: 2.4836 - mae: 2.4836 - val_loss: 2.8283 - val_mae: 2.8283\n",
      "Epoch 31/50\n",
      "404/404 [==============================] - 0s 84us/step - loss: 2.4161 - mae: 2.4161 - val_loss: 2.8420 - val_mae: 2.8420\n",
      "Epoch 32/50\n",
      "404/404 [==============================] - 0s 81us/step - loss: 2.4013 - mae: 2.4013 - val_loss: 2.9290 - val_mae: 2.9290\n",
      "Epoch 33/50\n",
      "404/404 [==============================] - 0s 86us/step - loss: 2.3289 - mae: 2.3289 - val_loss: 3.0297 - val_mae: 3.0297\n",
      "Epoch 34/50\n",
      "404/404 [==============================] - 0s 84us/step - loss: 2.5307 - mae: 2.5307 - val_loss: 2.8981 - val_mae: 2.8981\n",
      "Epoch 35/50\n",
      "404/404 [==============================] - 0s 86us/step - loss: 2.1848 - mae: 2.1848 - val_loss: 2.8187 - val_mae: 2.8187\n",
      "Epoch 36/50\n",
      "404/404 [==============================] - 0s 81us/step - loss: 2.3670 - mae: 2.3670 - val_loss: 2.8307 - val_mae: 2.8307\n",
      "Epoch 37/50\n",
      "404/404 [==============================] - 0s 84us/step - loss: 2.3356 - mae: 2.3356 - val_loss: 2.9073 - val_mae: 2.9073\n",
      "Epoch 38/50\n",
      "404/404 [==============================] - 0s 84us/step - loss: 2.3556 - mae: 2.3556 - val_loss: 2.8987 - val_mae: 2.8987\n",
      "Epoch 39/50\n",
      "404/404 [==============================] - 0s 81us/step - loss: 2.2860 - mae: 2.2860 - val_loss: 2.7661 - val_mae: 2.7661\n",
      "Epoch 40/50\n",
      "404/404 [==============================] - 0s 84us/step - loss: 2.3635 - mae: 2.3635 - val_loss: 2.8294 - val_mae: 2.8294\n",
      "Epoch 41/50\n",
      "404/404 [==============================] - 0s 81us/step - loss: 2.1853 - mae: 2.1853 - val_loss: 2.8490 - val_mae: 2.8490\n",
      "Epoch 42/50\n",
      "404/404 [==============================] - 0s 84us/step - loss: 2.2778 - mae: 2.2778 - val_loss: 2.8832 - val_mae: 2.8832\n",
      "Epoch 43/50\n",
      "404/404 [==============================] - 0s 79us/step - loss: 2.1512 - mae: 2.1512 - val_loss: 2.9796 - val_mae: 2.9796\n",
      "Epoch 44/50\n",
      "404/404 [==============================] - 0s 86us/step - loss: 2.1026 - mae: 2.1026 - val_loss: 2.8275 - val_mae: 2.8275\n",
      "Epoch 45/50\n",
      "404/404 [==============================] - 0s 79us/step - loss: 2.2088 - mae: 2.2088 - val_loss: 2.9039 - val_mae: 2.9039\n",
      "Epoch 46/50\n",
      "404/404 [==============================] - 0s 81us/step - loss: 2.2514 - mae: 2.2514 - val_loss: 2.8809 - val_mae: 2.8809\n",
      "Epoch 47/50\n",
      "404/404 [==============================] - 0s 81us/step - loss: 2.1795 - mae: 2.1795 - val_loss: 2.9602 - val_mae: 2.9602\n",
      "Epoch 48/50\n",
      "404/404 [==============================] - 0s 84us/step - loss: 2.1123 - mae: 2.1123 - val_loss: 2.8788 - val_mae: 2.8788\n",
      "Epoch 49/50\n",
      "404/404 [==============================] - 0s 81us/step - loss: 2.2446 - mae: 2.2446 - val_loss: 2.8465 - val_mae: 2.8465\n",
      "Epoch 50/50\n",
      "404/404 [==============================] - 0s 81us/step - loss: 2.3719 - mae: 2.3719 - val_loss: 2.8685 - val_mae: 2.8685\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 49us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.8685236912147674, 2.868523597717285]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "\n",
    "neural_network_boston = Sequential()\n",
    "neural_network_boston.add(Dense(50, activation='relu', input_shape=[x_train.shape[1]]))\n",
    "neural_network_boston.add(Dropout(0.01))\n",
    "neural_network_boston.add(Dense(100, activation='relu'))\n",
    "neural_network_boston.add(Dropout(0.01))\n",
    "neural_network_boston.add(Dense(50, activation='relu'))\n",
    "neural_network_boston.add(Dropout(0.01))\n",
    "neural_network_boston.add(Dense(1))\n",
    "neural_network_boston.add(Dropout(0.01))\n",
    "\n",
    "\n",
    "# neural_network_boston.compile(loss='mean_squared_error', optimizer='adam')\n",
    "neural_network_boston.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "\n",
    "run_hist_model2= neural_network_boston.fit(x_train_scaled, y_train, epochs=50, verbose=1, validation_data=(x_test_scaled, y_test))\n",
    "\n",
    "\n",
    "plt.plot(run_hist_model2.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "plt.plot(run_hist_model2.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "plt.title(\"Train loss and validation error with dropouts\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.xlim(0, 10)\n",
    "plt.plot(run_hist_model2.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "plt.plot(run_hist_model2.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "plt.title(\"Train loss and validation error with dropouts\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "neural_network_boston.evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network_boston.save('boston-model-dropout.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
